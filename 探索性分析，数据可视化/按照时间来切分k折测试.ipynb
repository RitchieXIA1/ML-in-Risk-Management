{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de11e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This module provides a class to split time-series data for back-testing and evaluation.\n",
    "The aim was to extend the current sklearn implementation and extend it's uses.\n",
    "\n",
    "Might be useful for some ;)\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection._split import _BaseKFold\n",
    "from sklearn.utils import indexable\n",
    "from sklearn.utils.validation import _num_samples\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TimeSeriesSplit(_BaseKFold):  # pylint: disable=abstract-method\n",
    "    \"\"\"Time Series cross-validator\n",
    "\n",
    "    Provides train/test indices to split time series data samples that are observed at fixed time intervals,\n",
    "    in train/test sets. In each split, test indices must be higher than before, and thus shuffling in cross validator is\n",
    "    inappropriate.\n",
    "\n",
    "    This cross_validation object is a variation of :class:`TimeSeriesSplit` from the popular scikit-learn package.\n",
    "    It extends its base functionality to allow for expanding windows, and rolling windows with configurable train and\n",
    "    test sizes and delays between each. i.e. train on weeks 1-8, skip week 9, predict week 10-11.\n",
    "\n",
    "    In this implementation we specifically force the test size to be equal across all splits.\n",
    "\n",
    "    Expanding Window:\n",
    "\n",
    "            Idx / Time  0..............................................n\n",
    "            1           |  train  | delay |  test  |                   |\n",
    "            2           |       train     | delay  |  test  |          |\n",
    "            ...         |                                              |\n",
    "            last        |            train            | delay |  test  |\n",
    "\n",
    "    Rolling Windows:\n",
    "            Idx / Time  0..............................................n\n",
    "            1           | train   | delay |  test  |                   |\n",
    "            2           | step |  train  | delay |  test  |            |\n",
    "            ...         |                                              |\n",
    "            last        | step | ... | step |  train  | delay |  test  |\n",
    "\n",
    "    Parameters:\n",
    "        n_splits : int, default=5\n",
    "            Number of splits. Must be at least 4.\n",
    "\n",
    "        train_size : int, optional\n",
    "            Size for a single training set.\n",
    "\n",
    "        test_size : int, optional, must be positive\n",
    "            Size of a single testing set\n",
    "\n",
    "        delay : int, default=0, must be positive\n",
    "            Number of index shifts to make between train and test sets\n",
    "            e.g,\n",
    "            delay=0\n",
    "                TRAIN: [0 1 2 3] TEST: [4]\n",
    "            delay=1\n",
    "                TRAIN: [0 1 2 3] TEST: [5]\n",
    "            delay=2\n",
    "                TRAIN: [0 1 2 3] TEST: [6]\n",
    "\n",
    "        force_step_size : int, optional\n",
    "            Ignore split logic and force the training data to shift by the step size forward for n_splits\n",
    "            e.g\n",
    "            TRAIN: [ 0  1  2  3] TEST: [4]\n",
    "            TRAIN: [ 0  1  2  3  4] TEST: [5]\n",
    "            TRAIN: [ 0  1  2  3  4  5] TEST: [6]\n",
    "            TRAIN: [ 0  1  2  3  4  5  6] TEST: [7]\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "    >>> y = np.array([1, 2, 3, 4, 5, 6])\n",
    "    >>> tscv = TimeSeriesSplit(n_splits=5)\n",
    "    >>> print(tscv)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    TimeSeriesSplit(train_size=None, n_splits=5)\n",
    "    >>> for train_index, test_index in tscv.split(X):\n",
    "    ...    print('TRAIN:', train_index, 'TEST:', test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0] TEST: [1]\n",
    "    TRAIN: [0 1] TEST: [2]\n",
    "    TRAIN: [0 1 2] TEST: [3]\n",
    "    TRAIN: [0 1 2 3] TEST: [4]\n",
    "    TRAIN: [0 1 2 3 4] TEST: [5]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_splits: Optional[int] = 5,\n",
    "                 train_size: Optional[int] = None,\n",
    "                 test_size: Optional[int] = None,\n",
    "                 delay: int = 0,\n",
    "                 force_step_size: Optional[int] = None):\n",
    "\n",
    "        if n_splits and n_splits < 5:\n",
    "            raise ValueError(f'Cannot have n_splits less than 5 (n_splits={n_splits})')\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "\n",
    "        self.train_size = train_size\n",
    "\n",
    "        if test_size and test_size < 0:\n",
    "            raise ValueError(f'Cannot have negative values of test_size (test_size={test_size})')\n",
    "        self.test_size = test_size\n",
    "\n",
    "        if delay < 0:\n",
    "            raise ValueError(f'Cannot have negative values of delay (delay={delay})')\n",
    "        self.delay = delay\n",
    "\n",
    "        if force_step_size and force_step_size < 1:\n",
    "            raise ValueError(f'Cannot have zero or negative values of force_step_size '\n",
    "                             f'(force_step_size={force_step_size}).')\n",
    "\n",
    "        self.force_step_size = force_step_size\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "\n",
    "        Parameters:\n",
    "            X : array-like, shape (n_samples, n_features)\n",
    "                Training data, where n_samples is the number of samples  and n_features is the number of features.\n",
    "\n",
    "            y : array-like, shape (n_samples,)\n",
    "                Always ignored, exists for compatibility.\n",
    "\n",
    "            groups : array-like, with shape (n_samples,), optional\n",
    "                Always ignored, exists for compatibility.\n",
    "\n",
    "        Yields:\n",
    "            train : ndarray\n",
    "                The training set indices for that split.\n",
    "\n",
    "            test : ndarray\n",
    "                The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        X, y, groups = indexable(X, y, groups)  # pylint: disable=unbalanced-tuple-unpacking\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        n_folds = n_splits + 1\n",
    "        delay = self.delay\n",
    "\n",
    "        if n_folds > n_samples:\n",
    "            raise ValueError(f'Cannot have number of folds={n_folds} greater than the number of samples: {n_samples}.')\n",
    "\n",
    "        indices = np.arange(n_samples)\n",
    "        split_size = n_samples // n_folds\n",
    "\n",
    "        train_size = self.train_size or split_size * self.n_splits\n",
    "        test_size = self.test_size or n_samples // n_folds\n",
    "        full_test = test_size + delay\n",
    "\n",
    "        if full_test + n_splits > n_samples:\n",
    "            raise ValueError(f'test_size\\\\({test_size}\\\\) + delay\\\\({delay}\\\\) = {test_size + delay} + '\n",
    "                             f'n_splits={n_splits} \\n'\n",
    "                             f' greater than the number of samples: {n_samples}. Cannot create fold logic.')\n",
    "\n",
    "        # Generate logic for splits.\n",
    "        # Overwrite fold test_starts ranges if force_step_size is specified.\n",
    "        if self.force_step_size:\n",
    "            step_size = self.force_step_size\n",
    "            final_fold_start = n_samples - (train_size + full_test)\n",
    "            range_start = (final_fold_start % step_size) + train_size\n",
    "\n",
    "            test_starts = range(range_start, n_samples, step_size)\n",
    "\n",
    "        else:\n",
    "            if not self.train_size:\n",
    "                step_size = split_size\n",
    "                range_start = (split_size - full_test) + split_size + (n_samples % n_folds)\n",
    "            else:\n",
    "                step_size = (n_samples - (train_size + full_test)) // n_folds\n",
    "                final_fold_start = n_samples - (train_size + full_test)\n",
    "                range_start = (final_fold_start - (step_size * (n_splits - 1))) + train_size\n",
    "\n",
    "            test_starts = range(range_start, n_samples, step_size)\n",
    "\n",
    "        # Generate data splits.\n",
    "        for test_start in test_starts:\n",
    "            idx_start = test_start - train_size if self.train_size is not None else 0\n",
    "            # Ensure we always return a test set of the same size\n",
    "            if indices[test_start:test_start + full_test].size < full_test:\n",
    "                continue\n",
    "            yield (indices[idx_start:test_start],\n",
    "                   indices[test_start + delay:test_start + full_test])\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "    y = np.array([1, 2, 3, 4, 5, 6])\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    print(tscv)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        print('TRAIN:', train_index, 'TEST:', test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    print(\"---------------------------------------------\")\n",
    "    LARGE_IDX = np.arange(0, 30)\n",
    "    rolling_window = TimeSeriesSplit(train_size=10, test_size=5, delay=3)\n",
    "    print(rolling_window)\n",
    "    for train_index, test_index in rolling_window.split(LARGE_IDX):\n",
    "        print('TRAIN:', train_index, 'TEST:', test_index)\n",
    "        X_train, X_test = LARGE_IDX[train_index], LARGE_IDX[test_index]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
