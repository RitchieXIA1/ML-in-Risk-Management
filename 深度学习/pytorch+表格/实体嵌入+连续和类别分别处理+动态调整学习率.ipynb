{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import riiideducation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T07:53:20.677523Z",
     "start_time": "2022-01-25T07:53:17.635965Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "import dask.dataframe as dd\n",
    "import  pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read required Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T07:54:15.019326Z",
     "start_time": "2022-01-25T07:53:33.702367Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train= pd.read_csv('train.csv',\n",
    "                usecols=[1, 2, 3,4,7,8,9], dtype={'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16','content_type_id': 'int8','answered_correctly':'int8',\n",
    "                                                  'prior_question_elapsed_time': 'float32','prior_question_had_explanation': 'object'}\n",
    "  \n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T07:55:14.686843Z",
     "start_time": "2022-01-25T07:54:43.076375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84775752</th>\n",
       "      <td>1805962620</td>\n",
       "      <td>5547</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94914466</th>\n",
       "      <td>2015251289</td>\n",
       "      <td>4024</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  content_id  answered_correctly  \\\n",
       "0                115        5692                   1   \n",
       "84775752  1805962620        5547                   0   \n",
       "94914466  2015251289        4024                   1   \n",
       "\n",
       "          prior_question_elapsed_time prior_question_had_explanation  \n",
       "0                                 NaN                            NaN  \n",
       "84775752                          NaN                            NaN  \n",
       "94914466                          NaN                            NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = train[train.content_type_id == False]\n",
    "train = train.sort_values(['timestamp'], ascending=True)\n",
    "\n",
    "train.drop(['timestamp','content_type_id'], axis=1,   inplace=True)\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T07:57:42.144058Z",
     "start_time": "2022-01-25T07:56:30.157145Z"
    }
   },
   "outputs": [],
   "source": [
    "results_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean','std','sum','skew'])\n",
    "results_c.columns = [\"content_mean\",\"content_std\",\"content_sum\",\"content_skew\"]\n",
    "\n",
    "results_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum','std','skew'])\n",
    "results_u.columns = [\"user_mean\", 'user_sum','user_std','user_skew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:09:08.583741Z",
     "start_time": "2022-01-25T08:09:08.572645Z"
    }
   },
   "outputs": [],
   "source": [
    "#reading in question df\n",
    "questions_df = pd.read_csv('questions.csv',\n",
    "                            usecols=[0,1, 3,4],\n",
    "                            dtype={'question_id': 'int16',\n",
    "                              'part': 'int8','bundle_id': 'int8','tags': 'str'}\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:09:09.185963Z",
     "start_time": "2022-01-25T08:09:09.025899Z"
    }
   },
   "outputs": [],
   "source": [
    "#如何把一串字符或数字的列切分开\n",
    "tag = questions_df[\"tags\"].str.split(\" \", n = 5, expand = True) #转化为字符串，并用空格来切分，切成6份，并且转化为DF格式\n",
    "tag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n",
    "questions_df =  pd.concat([questions_df,tag],axis=1).drop(['tags'],axis=1)\n",
    "questions_df['tags1'] = pd.to_numeric(questions_df['tags1'], errors='coerce',downcast='integer').fillna(-1)\n",
    "questions_df['tags2'] = pd.to_numeric(questions_df['tags2'], errors='coerce',downcast='integer').fillna(-1)\n",
    "questions_df['tags3'] = pd.to_numeric(questions_df['tags3'], errors='coerce',downcast='integer').fillna(-1)\n",
    "#如果有需要把后面4-6tags也drop掉\n",
    "#questions_df['tags4'] = pd.to_numeric(questions_df['tags4'], errors='coerce',downcast='integer').fillna(-1)\n",
    "#questions_df['tags5'] = pd.to_numeric(questions_df['tags5'], errors='coerce',downcast='integer')\n",
    "#questions_df['tags6'] = pd.to_numeric(questions_df['tags6'], errors='coerce',downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:10:56.333833Z",
     "start_time": "2022-01-25T08:10:56.322735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>tags1</th>\n",
       "      <th>tags2</th>\n",
       "      <th>tags3</th>\n",
       "      <th>tags4</th>\n",
       "      <th>tags5</th>\n",
       "      <th>tags6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>92</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  bundle_id  part  tags1  tags2  tags3 tags4 tags5 tags6\n",
       "0            0          0     1   51.0  131.0  162.0    38  None  None\n",
       "1            1          1     1  131.0   36.0   81.0  None  None  None\n",
       "2            2          2     1  131.0  101.0  162.0    92  None  None"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:11:01.686991Z",
     "start_time": "2022-01-25T08:11:01.672988Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_columns = ['prior_question_had_explanation','bundle_id','part','tags1','tags2','tags3']\n",
    "\n",
    "cont_columns = ['prior_question_elapsed_time', \"content_mean\",\"content_std\",\"content_sum\",\"content_skew\",\n",
    "                \"user_mean\", 'user_sum','user_std','user_skew']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:11:23.720015Z",
     "start_time": "2022-01-25T08:11:03.837249Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X=train.iloc[88000000:,:]\n",
    "X = pd.merge(X, results_u, on=['user_id'], how=\"left\")\n",
    "X = pd.merge(X, results_c, on=['content_id'], how=\"left\")\n",
    "X = pd.merge(X, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "\n",
    "X=X[X.answered_correctly!= -1 ]\n",
    "X=X.sort_values(['user_id'])\n",
    "X['prior_question_had_explanation']=X['prior_question_had_explanation'].fillna('False').map({\"True\":True,\"False\":False})\n",
    "X['prior_question_elapsed_time'].fillna(0,inplace=True)\n",
    "\n",
    "for col in cont_columns:\n",
    "    X[col].fillna(X[col].mode(),inplace=True)\n",
    "\n",
    "Y = X[[\"answered_correctly\"]]\n",
    "X = X.drop([\"answered_correctly\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- label encoding\n",
    "- Robust scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:12:02.084788Z",
     "start_time": "2022-01-25T08:11:56.077963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_question_had_explanation\n",
      "bundle_id\n",
      "part\n",
      "tags1\n",
      "tags2\n",
      "tags3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features=cat_columns+cont_columns\n",
    "\n",
    "def encode(df,cols):\n",
    "    enc =  {}\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        lbencoder = LabelEncoder()\n",
    "        lb = lbencoder.fit(df[col].values)\n",
    "        df[col]=lb.transform(df[col].values)\n",
    "        enc[col]=lb\n",
    "        \n",
    "    return df,enc\n",
    "\n",
    "X,enc_dict = encode(X,cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:36:56.373752Z",
     "start_time": "2022-01-25T08:36:51.663947Z"
    }
   },
   "outputs": [],
   "source": [
    "scale_dict={}\n",
    "fix_missing={}\n",
    "for col in cont_columns:\n",
    "    scaler = RobustScaler()\n",
    "    scale_dict[col]=scaler.fit(X[col].values.reshape(-1,1))\n",
    "    X[col] = scale_dict[col].transform(X[col].values.reshape(-1,1))\n",
    "    fix_missing[col] = X[col].mode().values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:36:58.721757Z",
     "start_time": "2022-01-25T08:36:58.420540Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_dims = [X[col].nunique() for col in cat_columns]\n",
    "cat_embs = [(dim, min(50,(dim+1)//2)) for dim in cat_dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:37:22.044400Z",
     "start_time": "2022-01-25T08:37:22.034398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1), (256, 50), (7, 4), (117, 50), (87, 44), (54, 27)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:37:27.521181Z",
     "start_time": "2022-01-25T08:37:27.506497Z"
    }
   },
   "outputs": [],
   "source": [
    "class RidDataset(Dataset):\n",
    "    def __init__(self, df,targets,cat_features,cont_features,mode='train'):\n",
    "        self.mode = mode\n",
    "        self.data_cont = df[cont_features].values\n",
    "        self.data_cat = df[cat_features].values\n",
    "        if mode=='train':\n",
    "            self.targets = targets.values \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_cont)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return torch.FloatTensor(self.data_cont[idx]),torch.LongTensor(self.data_cat[idx]),torch.FloatTensor(self.targets[idx])\n",
    "        elif self.mode == 'test':\n",
    "            return torch.FloatTensor(self.data_cont[idx]), torch.LongTensor(self.data_cat[idx]),0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:37:34.605262Z",
     "start_time": "2022-01-25T08:37:34.590630Z"
    }
   },
   "outputs": [],
   "source": [
    "class RidModel(nn.Module):\n",
    "    def __init__(self,emb_dims,no_of_cont):\n",
    "        super(RidModel, self).__init__()\n",
    "        \n",
    "        self.emb = nn.ModuleList([nn.Embedding(x,y) for x,y in emb_dims])\n",
    "        \n",
    "        no_of_embs = sum([y for x, y in emb_dims])\n",
    "        self.no_of_embs = no_of_embs\n",
    "        self.no_of_cont = no_of_cont\n",
    "        \n",
    "        \n",
    "        self.batch_norm1 = nn.BatchNorm1d(self.no_of_cont)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(no_of_cont, 128))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(128+no_of_embs)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(128+no_of_embs, 32))\n",
    "         \n",
    "        self.batch_norm3 = nn.BatchNorm1d(32)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(32, 16))\n",
    "        \n",
    "        self.batch_norm4 = nn.BatchNorm1d(16)\n",
    "        self.dense4 = nn.utils.weight_norm(nn.Linear(16, 1))\n",
    "        \n",
    "       \n",
    "    def forward(self, cont,cat):\n",
    "         \n",
    "        ## cat data part\n",
    "        x_cat = [emb_layer(cat[:,i]) for i,emb_layer in enumerate(self.emb)]\n",
    "        x_cat = torch.cat(x_cat,1)#把所有类别变量的emb按行合并\n",
    "        x_cat = self.dropout1(x_cat)\n",
    "        ##cont data\n",
    "        x = self.batch_norm1(cont)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        ##concat\n",
    "        x = torch.cat([x,x_cat],1)#残差结构，把经过FC层的全部变量结果和类别变量embedding之后的结构合并\n",
    "        \n",
    "        ##rest of NN\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(self.dense3(x))\n",
    "        \n",
    "        \n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.sigmoid(self.dense4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:37:41.884745Z",
     "start_time": "2022-01-25T08:37:36.494994Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid = train_test_split(X[features],Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:37:44.194537Z",
     "start_time": "2022-01-25T08:37:43.673789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76301"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X,Y,train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T08:37:44.920272Z",
     "start_time": "2022-01-25T08:37:44.908270Z"
    }
   },
   "outputs": [],
   "source": [
    "assert X_train.shape[0]==y_train.shape[0]\n",
    "assert X_valid.shape[0]==y_valid.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T09:13:48.509512Z",
     "start_time": "2022-01-25T08:37:48.049618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5   - loss: 0.56193   - val_loss: 0.53608 -- AUC 0.7519 --val AUC 0.7654\n",
      "Epoch 2/5   - loss: 0.53575   - val_loss: 0.53475 -- AUC 0.7567 --val AUC 0.7733\n",
      "Epoch 3/5   - loss: 0.53492   - val_loss: 0.53466 -- AUC 0.7614 --val AUC 0.7666\n",
      "Epoch 4/5   - loss: 0.53452   - val_loss: 0.53488 -- AUC 0.7555 --val AUC 0.7779\n",
      "Epoch 5/5   - loss: 0.53423   - val_loss: 0.53440 -- AUC 0.7526 --val AUC 0.7721\n"
     ]
    }
   ],
   "source": [
    "nepochs=5\n",
    "train_set = RidDataset(X_train,y_train,cat_columns,cont_columns,mode=\"train\")\n",
    "valid_set = RidDataset(X_valid,y_valid,cat_columns,cont_columns,mode=\"train\")\n",
    "val_auc=[]\n",
    "dataloaders = {'train':DataLoader(train_set,batch_size=2**15,shuffle=True),\n",
    "              \"val\":DataLoader(valid_set,batch_size=2**15,shuffle=True)}\n",
    "\n",
    "model = RidModel(cat_embs,len(cont_columns)).to(DEVICE)\n",
    "checkpoint_path = 'rid_model.pt'\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "#如果几次内没有下降loss，自动减少学习率\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, eps=1e-4, verbose=True) \n",
    "criterion = nn.BCELoss()\n",
    "best_loss = {'train':np.inf,'val':np.inf}\n",
    "auc_score = {'train':0,'val':0.0}\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "            epoch_loss = {'train': 0.0, 'val': 0.0}\n",
    "            \n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                auc=0.0\n",
    "                \n",
    "                for i,(x,y,z) in enumerate(dataloaders[phase]):\n",
    "                    x, y, z = x.to(DEVICE), y.to(DEVICE),z.to(DEVICE)\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.set_grad_enabled(phase=='train'):\n",
    "                        preds = model(x,y)\n",
    "                        loss = criterion(preds, z)\n",
    "                        auc = roc_auc_score(z.detach().cpu().numpy(),preds.detach().cpu().numpy())\n",
    "                        \n",
    "                        if phase=='train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    \n",
    "                    running_loss += loss.item() / len(dataloaders[phase])\n",
    "                    auc += auc/len(dataloaders[phase])\n",
    "                \n",
    "                epoch_loss[phase] = running_loss\n",
    "                auc_score[phase]=auc\n",
    "                \n",
    "            print(\"Epoch {}/{}   - loss: {:5.5f}   - val_loss: {:5.5f} -- AUC {:5.4f} --val AUC {:5.4f}\".format(epoch+1,\n",
    "                    nepochs, epoch_loss['train'], epoch_loss['val'],auc_score['train'],auc_score['val']))\n",
    "            val_auc.append(auc_score['val'])\n",
    "            scheduler.step(epoch_loss['val'])\n",
    "            \n",
    "            if epoch_loss['val'] < best_loss['val']:\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(model.state_dict(), checkpoint_path)\n",
    "                \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T09:14:28.660377Z",
     "start_time": "2022-01-25T09:14:28.645483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation AUC Score 0.7711\n"
     ]
    }
   ],
   "source": [
    "print(f'Final validation AUC Score {np.mean(val_auc):5.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
