{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015763,
     "end_time": "2020-12-11T07:41:17.676040",
     "exception": false,
     "start_time": "2020-12-11T07:41:17.660277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A self-Attentive model for Knowledge Tracing\n",
    "\n",
    "\n",
    "## update:\n",
    "\n",
    "### 2020-12-11: auc -> 0.765\n",
    "\n",
    "- add state for test dataset\n",
    "\n",
    "thanks for HDKIM wordk: https://www.kaggle.com/leadbest/sakt-with-state-updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T05:09:31.338769Z",
     "start_time": "2022-02-15T05:09:31.083701Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-11T07:41:17.719286Z",
     "iopub.status.busy": "2020-12-11T07:41:17.718033Z",
     "iopub.status.idle": "2020-12-11T07:41:17.726975Z",
     "shell.execute_reply": "2020-12-11T07:41:17.727699Z"
    },
    "papermill": {
     "duration": 0.03741,
     "end_time": "2020-12-11T07:41:17.727887",
     "exception": false,
     "start_time": "2020-12-11T07:41:17.690477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T05:09:33.725963Z",
     "start_time": "2022-02-15T05:09:31.831071Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-11T07:41:17.785370Z",
     "iopub.status.busy": "2020-12-11T07:41:17.784458Z",
     "iopub.status.idle": "2020-12-11T07:41:20.237253Z",
     "shell.execute_reply": "2020-12-11T07:41:20.236002Z"
    },
    "papermill": {
     "duration": 2.486188,
     "end_time": "2020-12-11T07:41:20.237382",
     "exception": false,
     "start_time": "2020-12-11T07:41:17.751194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015185,
     "end_time": "2020-12-11T07:41:20.268747",
     "exception": false,
     "start_time": "2020-12-11T07:41:20.253562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T05:10:10.572699Z",
     "start_time": "2022-02-15T05:09:34.450459Z"
    },
    "execution": {
     "iopub.execute_input": "2020-12-11T07:41:20.308425Z",
     "iopub.status.busy": "2020-12-11T07:41:20.307725Z",
     "iopub.status.idle": "2020-12-11T07:43:26.016332Z",
     "shell.execute_reply": "2020-12-11T07:43:26.015724Z"
    },
    "papermill": {
     "duration": 125.732079,
     "end_time": "2020-12-11T07:43:26.016444",
     "exception": false,
     "start_time": "2020-12-11T07:41:20.284365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  answered_correctly\n",
       "0          0      115        5692                0                   1\n",
       "1      56943      115        5716                0                   1\n",
       "2     118363      115         128                0                   1\n",
       "3     131167      115        7860                0                   1\n",
       "4     137965      115        7922                0                   1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dtype = {'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16','content_type_id': 'int8','answered_correctly':'int8'}\n",
    "\n",
    "train_df = pd.read_csv('train.csv', usecols=[1, 2, 3,4,7], dtype=dtype)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T05:10:32.057869Z",
     "start_time": "2022-02-15T05:10:10.621709Z"
    },
    "execution": {
     "iopub.execute_input": "2020-12-11T07:43:26.054391Z",
     "iopub.status.busy": "2020-12-11T07:43:26.053784Z",
     "iopub.status.idle": "2020-12-11T07:43:49.839937Z",
     "shell.execute_reply": "2020-12-11T07:43:49.840624Z"
    },
    "papermill": {
     "duration": 23.808073,
     "end_time": "2020-12-11T07:43:49.840808",
     "exception": false,
     "start_time": "2020-12-11T07:43:26.032735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df.content_type_id == False]\n",
    "\n",
    "#arrange by timestamp\n",
    "train_df = train_df.sort_values(['timestamp'], ascending=True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01796,
     "end_time": "2020-12-11T07:43:49.876790",
     "exception": false,
     "start_time": "2020-12-11T07:43:49.858830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T05:13:04.391174Z",
     "start_time": "2022-02-15T05:13:03.607737Z"
    },
    "execution": {
     "iopub.execute_input": "2020-12-11T07:43:49.916939Z",
     "iopub.status.busy": "2020-12-11T07:43:49.915681Z",
     "iopub.status.idle": "2020-12-11T07:43:50.692792Z",
     "shell.execute_reply": "2020-12-11T07:43:50.692126Z"
    },
    "papermill": {
     "duration": 0.799004,
     "end_time": "2020-12-11T07:43:50.692911",
     "exception": false,
     "start_time": "2020-12-11T07:43:49.893907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number skills 13523\n"
     ]
    }
   ],
   "source": [
    "skills = train_df[\"content_id\"].unique()\n",
    "n_skill = len(skills)\n",
    "print(\"number skills\", len(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T05:13:33.615697Z",
     "start_time": "2022-02-15T05:13:07.925201Z"
    },
    "execution": {
     "iopub.execute_input": "2020-12-11T07:43:51.447389Z",
     "iopub.status.busy": "2020-12-11T07:43:51.393910Z",
     "iopub.status.idle": "2020-12-11T07:44:35.582924Z",
     "shell.execute_reply": "2020-12-11T07:44:35.581737Z"
    },
    "papermill": {
     "duration": 44.870265,
     "end_time": "2020-12-11T07:44:35.583066",
     "exception": false,
     "start_time": "2020-12-11T07:43:50.712801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#直接生成了操作和对应的序列\n",
    "group = train_df[['user_id', 'content_id', 'answered_correctly']].groupby('user_id').apply(lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values))\n",
    "\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T02:07:47.172681Z",
     "start_time": "2022-02-15T02:07:47.152738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "115           ([5692, 5716, 128, 7860, 7922, 156, 51, 50, 78...\n",
       "124           ([7900, 7876, 175, 1278, 2065, 2063, 2064, 336...\n",
       "2746          ([5273, 758, 5976, 236, 404, 382, 405, 873, 53...\n",
       "5382          ([5000, 3944, 217, 5844, 5965, 4990, 5235, 605...\n",
       "8623          ([3915, 4750, 6456, 3968, 6104, 5738, 6435, 54...\n",
       "                                    ...                        \n",
       "2147470770    ([7900, 7876, 175, 1278, 2064, 2063, 2065, 336...\n",
       "2147470777    ([7900, 7876, 175, 1278, 2065, 2063, 2064, 336...\n",
       "2147481750    ([4137, 1270, 9261, 8201, 367, 378, 214, 6071,...\n",
       "2147482216    ([3748, 4765, 5474, 9261, 4665, 5987, 6666, 56...\n",
       "2147482888    ([6147, 4792, 5738, 6102, 4748, 7956, 6435, 92...\n",
       "Length: 393656, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T05:13:48.007064Z",
     "start_time": "2022-02-15T05:13:47.998063Z"
    },
    "execution": {
     "iopub.execute_input": "2020-12-11T07:44:35.636052Z",
     "iopub.status.busy": "2020-12-11T07:44:35.632830Z",
     "iopub.status.idle": "2020-12-11T07:44:35.638694Z",
     "shell.execute_reply": "2020-12-11T07:44:35.638211Z"
    },
    "papermill": {
     "duration": 0.037412,
     "end_time": "2020-12-11T07:44:35.638797",
     "exception": false,
     "start_time": "2020-12-11T07:44:35.601385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SAKTDataset(Dataset):\n",
    "    def __init__(self, group, n_skill, max_seq=100):\n",
    "        super(SAKTDataset, self).__init__()\n",
    "        #最大问题长度100以内\n",
    "        self.max_seq = max_seq\n",
    "        #question个数\n",
    "        self.n_skill = n_skill\n",
    "        self.samples = group\n",
    "        \n",
    "#         self.user_ids = [x for x in group.index]\n",
    "        self.user_ids = []\n",
    "        #把之前问题小于十个的用户剔除\n",
    "        for user_id in group.index:\n",
    "            q, qa = group[user_id]\n",
    "            if len(q) < 10:\n",
    "                #如果没有十个就结束当前循环，也就是不放入列表\n",
    "                continue\n",
    "            self.user_ids.append(user_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #在序列模型里很常见的一个情况就是要对数据长度进行处理\n",
    "        user_id = self.user_ids[index]\n",
    "        q_, qa_ = self.samples[user_id]\n",
    "        seq_len = len(q_)\n",
    "        #这里按照最大长度（100）来设置0\n",
    "        q = np.zeros(self.max_seq, dtype=int)\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "        if seq_len >= self.max_seq:\n",
    "            #大于最大长度，按最大长度进行截断\n",
    "            q[:] = q_[-self.max_seq:]\n",
    "            qa[:] = qa_[-self.max_seq:]\n",
    "        else:\n",
    "            #小于最大长度把序列长度以前的位置设为0\n",
    "            q[-seq_len:] = q_\n",
    "            qa[-seq_len:] = qa_\n",
    "        #往右边移动一个单位，因为目前的question和answer都不能包含当前T时刻的结构，所以移动为t\n",
    "        target_id = q[1:]\n",
    "        label = qa[1:]\n",
    "        #x仍然是历史的答题情况，用历史去预测未来 ，所以是1到 t-1\n",
    "        x = np.zeros(self.max_seq-1, dtype=int)\n",
    "        x = q[:-1].copy()\n",
    "        x += (qa[:-1] == 1) * self.n_skill\n",
    "\n",
    "        return x, target_id, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T05:14:16.209417Z",
     "start_time": "2022-02-15T05:14:16.199414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0, 21423,  7876,   175,  1278, 15587,  2065,  2063,\n",
       "        3364,  3365, 16886,  2948,  2946,  2947, 16118,  2593, 16117,\n",
       "       18015,  4120, 18219, 19639,  6173, 19893,  6878,  6877,  6880,\n",
       "        6879,  7216,  7217,  7218,  7219, 18191,  4253, 19747,  9050])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#在前面补0，并且可以看出x比label和targetid要少一位，也就是即将要预测的那一位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:03:39.969035Z",
     "start_time": "2022-02-15T03:03:39.961590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T05:13:53.722943Z",
     "start_time": "2022-02-15T05:13:52.370971Z"
    },
    "execution": {
     "iopub.execute_input": "2020-12-11T07:44:35.683232Z",
     "iopub.status.busy": "2020-12-11T07:44:35.682458Z",
     "iopub.status.idle": "2020-12-11T07:44:39.079807Z",
     "shell.execute_reply": "2020-12-11T07:44:39.079188Z"
    },
    "papermill": {
     "duration": 3.423434,
     "end_time": "2020-12-11T07:44:39.079919",
     "exception": false,
     "start_time": "2020-12-11T07:44:35.656485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(group, test_size=0.2)\n",
    "\n",
    "train_dataset = SAKTDataset(train, n_skill)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2048, shuffle=True, num_workers=8)\n",
    "del train\n",
    "\n",
    "val_dataset = SAKTDataset(val, n_skill)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2048, shuffle=True, num_workers=8)\n",
    "del val\n",
    "# print(item[0])\n",
    "# print(item[1])\n",
    "# print(item[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017887,
     "end_time": "2020-12-11T07:44:39.115921",
     "exception": false,
     "start_time": "2020-12-11T07:44:39.098034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:21:33.275795Z",
     "start_time": "2022-02-15T03:21:33.226307Z"
    },
    "execution": {
     "iopub.execute_input": "2020-12-11T07:44:39.182189Z",
     "iopub.status.busy": "2020-12-11T07:44:39.180184Z",
     "iopub.status.idle": "2020-12-11T07:44:39.182865Z",
     "shell.execute_reply": "2020-12-11T07:44:39.183328Z"
    },
    "papermill": {
     "duration": 0.049063,
     "end_time": "2020-12-11T07:44:39.183448",
     "exception": false,
     "start_time": "2020-12-11T07:44:39.134385",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, state_size=200):\n",
    "        super(FFN, self).__init__()\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.lr1 = nn.Linear(state_size, state_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lr2 = nn.Linear(state_size, state_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.lr1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr2(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "def future_mask(seq_length):\n",
    "    future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype('bool')\n",
    "    return torch.from_numpy(future_mask)\n",
    "\n",
    "\n",
    "class SAKTModel(nn.Module):\n",
    "    def __init__(self, n_skill, max_seq=100, embed_dim=128):\n",
    "        super(SAKTModel, self).__init__()\n",
    "        self.n_skill = n_skill\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(2*n_skill+1, embed_dim)\n",
    "        #位置编码的词袋大小就是序列个数99\n",
    "        self.pos_embedding = nn.Embedding(max_seq-1, embed_dim)\n",
    "        self.e_embedding = nn.Embedding(n_skill+1, embed_dim)\n",
    "\n",
    "        self.multi_att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=8, dropout=0.2)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.layer_normal = nn.LayerNorm(embed_dim) \n",
    "\n",
    "        self.ffn = FFN(embed_dim)\n",
    "        self.pred = nn.Linear(embed_dim, 1)\n",
    "    \n",
    "    def forward(self, x, question_ids):\n",
    "        device = x.device        \n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        #这个是0-99的顺序，因为一共99维的序列，按照顺序进行编码\n",
    "        pos_id = torch.arange(x.size(1)).unsqueeze(0).to(device)\n",
    "        pos_x = self.pos_embedding(pos_id)\n",
    "        #把原始编码和顺序编码合并\n",
    "        x = x + pos_x\n",
    "        #对问题id进行编码\n",
    "        e = self.e_embedding(question_ids)\n",
    "        #换位置以便做muti_att\n",
    "        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        e = e.permute(1, 0, 2)\n",
    "        att_mask = future_mask(x.size(0)).to(device)\n",
    "        #这是用个上三角来挡住，避免出现用x2,x3,x4来预测x1的情况出现，即X2只能用X1，X3只能用X2,X1\n",
    "        att_output, att_weight = self.multi_att(e, x, x, attn_mask=att_mask)\n",
    "        att_output = self.layer_normal(att_output + e)\n",
    "        #恢复准备入全接\n",
    "        att_output = att_output.permute(1, 0, 2) # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n",
    "        #在这个地方可以把其他统计量拼接，再放入全连接层\n",
    "        x = self.ffn(att_output)\n",
    "        #残差结构\n",
    "        x = self.layer_normal(x + att_output)\n",
    "        x = self.pred(x)\n",
    "\n",
    "        return x.squeeze(-1), att_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:40:39.324825Z",
     "start_time": "2022-02-15T03:40:39.236011Z"
    },
    "execution": {
     "iopub.execute_input": "2020-12-11T07:44:39.660089Z",
     "iopub.status.busy": "2020-12-11T07:44:39.658970Z",
     "iopub.status.idle": "2020-12-11T07:44:43.773799Z",
     "shell.execute_reply": "2020-12-11T07:44:43.773210Z"
    },
    "papermill": {
     "duration": 4.572064,
     "end_time": "2020-12-11T07:44:43.773925",
     "exception": false,
     "start_time": "2020-12-11T07:44:39.201861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "model = SAKTModel(n_skill, embed_dim=128)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.99, weight_decay=0.005)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:40:46.765033Z",
     "start_time": "2022-02-15T03:40:46.747471Z"
    },
    "execution": {
     "iopub.execute_input": "2020-12-11T07:44:43.829821Z",
     "iopub.status.busy": "2020-12-11T07:44:43.827809Z",
     "iopub.status.idle": "2020-12-11T07:44:43.830625Z",
     "shell.execute_reply": "2020-12-11T07:44:43.831134Z"
    },
    "papermill": {
     "duration": 0.036866,
     "end_time": "2020-12-11T07:44:43.831257",
     "exception": false,
     "start_time": "2020-12-11T07:44:43.794391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_iterator, optim, criterion, device=\"cpu\"):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    tbar = tqdm(train_iterator)\n",
    "    for item in tbar:\n",
    "        x = item[0].to(device).long()\n",
    "        target_id = item[1].to(device).long()\n",
    "        label = item[2].to(device).float()\n",
    "        target_mask = (target_id != 0)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        output, atten_weight = model(x, target_id)\n",
    "        \n",
    "        output = torch.masked_select(output, target_mask)\n",
    "        label = torch.masked_select(label, target_mask)\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss.append(loss.item())\n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.average(train_loss)\n",
    "\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:40:48.581158Z",
     "start_time": "2022-02-15T03:40:48.561921Z"
    },
    "execution": {
     "iopub.execute_input": "2020-12-11T07:44:43.882480Z",
     "iopub.status.busy": "2020-12-11T07:44:43.875621Z",
     "iopub.status.idle": "2020-12-11T07:44:43.885383Z",
     "shell.execute_reply": "2020-12-11T07:44:43.884892Z"
    },
    "papermill": {
     "duration": 0.035963,
     "end_time": "2020-12-11T07:44:43.885489",
     "exception": false,
     "start_time": "2020-12-11T07:44:43.849526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_epoch(model, val_iterator, criterion, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    train_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    tbar = tqdm(val_iterator)\n",
    "    for item in tbar:\n",
    "        x = item[0].to(device).long()\n",
    "        target_id = item[1].to(device).long()\n",
    "        label = item[2].to(device).float()\n",
    "        target_mask = (target_id != 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, atten_weight = model(x, target_id)\n",
    "        \n",
    "        output = torch.masked_select(output, target_mask)\n",
    "        label = torch.masked_select(label, target_mask)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.average(train_loss)\n",
    "\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T04:28:27.709538Z",
     "start_time": "2022-02-15T04:28:27.691791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "       13651, 21383, 21445,   156, 13574, 13573, 21419, 21386, 13675,\n",
       "         104, 13631, 21423, 21424,  7971, 13548, 13706, 21449,  7927,\n",
       "       13527, 21507, 13568, 13708, 13578,  7876,     6,   172,  7898,\n",
       "         175, 13623,  7859, 21677, 21678, 21679,  8157, 21681, 20890,\n",
       "       20891, 20893, 20889,  7369, 20708,  7184,  7186,  1232,   357,\n",
       "        1278,  2063, 15587, 15588,  3363,  3364,  3365,  2948,  2946])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T07:44:43.933490Z",
     "iopub.status.busy": "2020-12-11T07:44:43.932802Z",
     "iopub.status.idle": "2020-12-11T08:02:05.460149Z",
     "shell.execute_reply": "2020-12-11T08:02:05.460874Z"
    },
    "papermill": {
     "duration": 1041.556817,
     "end_time": "2020-12-11T08:02:05.461080",
     "exception": false,
     "start_time": "2020-12-11T07:44:43.904263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5960: 100%|██████████| 153/153 [00:30<00:00,  5.02it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0 train_loss - 0.63 acc - 0.652 auc - 0.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5946: 100%|██████████| 39/39 [00:05<00:00,  6.66it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0 val_loss - 0.59 acc - 0.684 auc - 0.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5800: 100%|██████████| 153/153 [00:30<00:00,  4.99it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 1 train_loss - 0.58 acc - 0.691 auc - 0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5741: 100%|██████████| 39/39 [00:06<00:00,  6.28it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 1 val_loss - 0.58 acc - 0.695 auc - 0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5791: 100%|██████████| 153/153 [00:31<00:00,  4.91it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 2 train_loss - 0.58 acc - 0.697 auc - 0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5778: 100%|██████████| 39/39 [00:05<00:00,  6.62it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 2 val_loss - 0.57 acc - 0.698 auc - 0.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5747: 100%|██████████| 153/153 [00:30<00:00,  5.05it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 3 train_loss - 0.57 acc - 0.699 auc - 0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5757: 100%|██████████| 39/39 [00:06<00:00,  6.20it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 3 val_loss - 0.57 acc - 0.699 auc - 0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5714: 100%|██████████| 153/153 [00:29<00:00,  5.18it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 4 train_loss - 0.57 acc - 0.700 auc - 0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5722: 100%|██████████| 39/39 [00:07<00:00,  5.37it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 4 val_loss - 0.57 acc - 0.700 auc - 0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5711: 100%|██████████| 153/153 [00:30<00:00,  5.07it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 5 train_loss - 0.57 acc - 0.701 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5773: 100%|██████████| 39/39 [00:06<00:00,  6.27it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 5 val_loss - 0.57 acc - 0.700 auc - 0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5715: 100%|██████████| 153/153 [00:29<00:00,  5.13it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 6 train_loss - 0.57 acc - 0.702 auc - 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5714: 100%|██████████| 39/39 [00:06<00:00,  6.10it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 6 val_loss - 0.57 acc - 0.701 auc - 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5647: 100%|██████████| 153/153 [00:30<00:00,  5.06it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 7 train_loss - 0.57 acc - 0.702 auc - 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5788: 100%|██████████| 39/39 [00:06<00:00,  5.96it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 7 val_loss - 0.57 acc - 0.701 auc - 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5674: 100%|██████████| 153/153 [00:30<00:00,  4.96it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 8 train_loss - 0.57 acc - 0.703 auc - 0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5743: 100%|██████████| 39/39 [00:06<00:00,  5.81it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 8 val_loss - 0.57 acc - 0.701 auc - 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5702: 100%|██████████| 153/153 [00:31<00:00,  4.93it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 9 train_loss - 0.57 acc - 0.703 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5650: 100%|██████████| 39/39 [00:06<00:00,  6.06it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 9 val_loss - 0.57 acc - 0.701 auc - 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5670: 100%|██████████| 153/153 [00:29<00:00,  5.12it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 10 train_loss - 0.57 acc - 0.704 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5667: 100%|██████████| 39/39 [00:07<00:00,  5.27it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 10 val_loss - 0.57 acc - 0.701 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5652: 100%|██████████| 153/153 [00:30<00:00,  5.00it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 11 train_loss - 0.57 acc - 0.704 auc - 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5771: 100%|██████████| 39/39 [00:07<00:00,  5.32it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 11 val_loss - 0.57 acc - 0.701 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5687: 100%|██████████| 153/153 [00:29<00:00,  5.11it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 12 train_loss - 0.57 acc - 0.704 auc - 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5666: 100%|██████████| 39/39 [00:06<00:00,  5.91it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 12 val_loss - 0.57 acc - 0.701 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5693: 100%|██████████| 153/153 [00:30<00:00,  4.95it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 13 train_loss - 0.57 acc - 0.705 auc - 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5738: 100%|██████████| 39/39 [00:06<00:00,  5.66it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 13 val_loss - 0.57 acc - 0.701 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5637: 100%|██████████| 153/153 [00:31<00:00,  4.91it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 14 train_loss - 0.57 acc - 0.705 auc - 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5664: 100%|██████████| 39/39 [00:06<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 14 val_loss - 0.57 acc - 0.701 auc - 0.759\n",
      "early stop epoch  14\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "over_fit = 0\n",
    "last_auc = 0\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc, train_auc = train_epoch(model, train_dataloader, optimizer, criterion, device)\n",
    "    print(\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, train_loss, train_acc, train_auc))\n",
    "    \n",
    "    val_loss, avl_acc, val_auc = val_epoch(model, val_dataloader, criterion, device)\n",
    "    print(\"epoch - {} val_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, val_loss, avl_acc, val_auc))\n",
    "    \n",
    "    if val_auc > last_auc:\n",
    "        last_auc = val_auc\n",
    "        over_fit = 0\n",
    "    else:\n",
    "        over_fit += 1\n",
    "        \n",
    "    \n",
    "    if over_fit >= 2:\n",
    "        print(\"early stop epoch \", epoch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.052029,
     "end_time": "2020-12-11T08:02:09.535964",
     "exception": false,
     "start_time": "2020-12-11T08:02:07.483935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T08:02:14.307514Z",
     "iopub.status.busy": "2020-12-11T08:02:14.306538Z",
     "iopub.status.idle": "2020-12-11T08:02:14.309551Z",
     "shell.execute_reply": "2020-12-11T08:02:14.309026Z"
    },
    "papermill": {
     "duration": 2.600385,
     "end_time": "2020-12-11T08:02:14.309674",
     "exception": false,
     "start_time": "2020-12-11T08:02:11.709289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, samples, test_df, skills, max_seq=100):\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.samples = samples\n",
    "        self.user_ids = [x for x in test_df[\"user_id\"].unique()]\n",
    "        self.test_df = test_df\n",
    "        self.skills = skills\n",
    "        self.n_skill = len(skills)\n",
    "        self.max_seq = max_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.test_df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        test_info = self.test_df.iloc[index]\n",
    "\n",
    "        user_id = test_info[\"user_id\"]\n",
    "        target_id = test_info[\"content_id\"]\n",
    "\n",
    "        q = np.zeros(self.max_seq, dtype=int)\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "\n",
    "        if user_id in self.samples.index:\n",
    "            q_, qa_ = self.samples[user_id]\n",
    "            \n",
    "            seq_len = len(q_)\n",
    "\n",
    "            if seq_len >= self.max_seq:\n",
    "                q = q_[-self.max_seq:]\n",
    "                qa = qa_[-self.max_seq:]\n",
    "            else:\n",
    "                q[-seq_len:] = q_\n",
    "                qa[-seq_len:] = qa_          \n",
    "        \n",
    "        x = np.zeros(self.max_seq-1, dtype=int)\n",
    "        x = q[1:].copy()\n",
    "        x += (qa[1:] == 1) * self.n_skill\n",
    "        \n",
    "        questions = np.append(q[2:], [target_id])\n",
    "        \n",
    "        return x, questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T08:02:18.850103Z",
     "iopub.status.busy": "2020-12-11T08:02:18.849392Z",
     "iopub.status.idle": "2020-12-11T08:02:18.872781Z",
     "shell.execute_reply": "2020-12-11T08:02:18.872175Z"
    },
    "papermill": {
     "duration": 2.360512,
     "end_time": "2020-12-11T08:02:18.872928",
     "exception": false,
     "start_time": "2020-12-11T08:02:16.512416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "\n",
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T08:02:23.191171Z",
     "iopub.status.busy": "2020-12-11T08:02:23.190265Z",
     "iopub.status.idle": "2020-12-11T08:02:23.870446Z",
     "shell.execute_reply": "2020-12-11T08:02:23.869842Z"
    },
    "papermill": {
     "duration": 2.970938,
     "end_time": "2020-12-11T08:02:23.870605",
     "exception": false,
     "start_time": "2020-12-11T08:02:20.899667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 36.73it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.89it/s]\n",
      "2it [00:00, 12.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.95it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.5\n",
      "28.6\n",
      "28.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  5.95it/s]\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "model.eval()\n",
    "\n",
    "prev_test_df = None\n",
    "MAX_SEQ = 100\n",
    "\n",
    "for (test_df, sample_prediction_df) in tqdm(iter_test):\n",
    "    #HDKIM\n",
    "    if (prev_test_df is not None) & (psutil.virtual_memory().percent<90):\n",
    "        print(psutil.virtual_memory().percent)\n",
    "        prev_test_df['answered_correctly'] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "        prev_test_df = prev_test_df[prev_test_df.content_type_id == False]\n",
    "        prev_group = prev_test_df[['user_id', 'content_id', 'answered_correctly']].groupby('user_id').apply(lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values))\n",
    "        for prev_user_id in prev_group.index:\n",
    "            prev_group_content = prev_group[prev_user_id][0]\n",
    "            prev_group_ac = prev_group[prev_user_id][1]\n",
    "            if prev_user_id in group.index:\n",
    "                group[prev_user_id] = (np.append(group[prev_user_id][0],prev_group_content), \n",
    "                                       np.append(group[prev_user_id][1],prev_group_ac))\n",
    " \n",
    "            else:\n",
    "                group[prev_user_id] = (prev_group_content,prev_group_ac)\n",
    "            if len(group[prev_user_id][0])>MAX_SEQ:\n",
    "                new_group_content = group[prev_user_id][0][-MAX_SEQ:]\n",
    "                new_group_ac = group[prev_user_id][1][-MAX_SEQ:]\n",
    "                group[prev_user_id] = (new_group_content,new_group_ac)\n",
    "\n",
    "    prev_test_df = test_df.copy()\n",
    "    \n",
    "    test_df = test_df[test_df.content_type_id == False]\n",
    "    \n",
    "    test_dataset = TestDataset(group, test_df, skills)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=51200, shuffle=False)\n",
    "    \n",
    "    outs = []\n",
    "\n",
    "    for item in tqdm(test_dataloader):\n",
    "        x = item[0].to(device).long()\n",
    "        target_id = item[1].to(device).long()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, att_weight = model(x, target_id)\n",
    "        \n",
    "        \n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[:, -1]\n",
    "\n",
    "        # pred = (output >= 0.5).long()\n",
    "        # loss = criterion(output, label)\n",
    "\n",
    "        # val_loss.append(loss.item())\n",
    "        # num_corrects += (pred == label).sum().item()\n",
    "        # num_total += len(label)\n",
    "\n",
    "        # labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "        \n",
    "    test_df['answered_correctly'] =  outs\n",
    "    \n",
    "    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.341504,
     "end_time": "2020-12-11T08:02:28.283597",
     "exception": false,
     "start_time": "2020-12-11T08:02:25.942093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "原始单元格格式",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "duration": 1278.731182,
   "end_time": "2020-12-11T08:02:31.538790",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-11T07:41:12.807608",
   "version": "2.1.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
