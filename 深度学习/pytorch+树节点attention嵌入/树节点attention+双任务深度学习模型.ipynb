{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual of DATE (Dual-Attentive-Tree-aware-Embedding) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Date: 2020. 5. 27.\n",
    "* Written by Yeon Soo Choi, Technical Officer, Research Unit, WCO\n",
    "* Revised by Sundong Kim, Institute for Basic Science\n",
    "* Original paper\n",
    "    * Title: DATE: Dual Attentive Tree-aware Embedding for Customs Frauds Detection\n",
    "    * Authors\n",
    "        - IBS: Sundong Kim*, Karandeep Singh, Meeyoung Cha\n",
    "        - NCKU: Yu-Che Tsai∗, Cheng-Te Li\n",
    "        - WCO: Yeon Soo Choi\n",
    "        - NCS: Etim Ibok\n",
    "    * Source: https://github.com/Roytsai27/Dual-Attentive-Tree-aware-Embedding\n",
    "        - All the python codes are included in this one notebook.\n",
    "* Data: Synthetic import data (xxx at transaction-item level)\n",
    "\n",
    "\n",
    "## Summary (in non-technical terms)\n",
    "\n",
    "**DATE (Dual-Attentive-Tree-aware-Embedding)** is a neural network model to detect undervalued imports.  \n",
    "\n",
    "Imagine that you **(\"neural networks\")** are the head of a Customs targeting centre composed of **100 risk analysts (\"decision trees\")**. For a given import, you task the analysts with reporting **the probability of undervaluation** and **the estimate of additional revenue from the inspection (\"dual-task\")**.  \n",
    "\n",
    "How would you put 100 different reports together in making your final decision?\n",
    "Simply averaging their predictions may neglect some valuable information hidden in 100 reports. The DATE model help you keep all the information while paying more **ATTENTION** to specific pieces. Firstly, if there are a majority group of reports significantly similar to each other, you may pay more **ATTENTION** to those reports. Secondly, if you have analysts specialized in the specific HS code and importer of the given import, you may pay more **ATTENTION** to their reports. In the end, you make your final decision based on all the reports, however, in proportion to the amount of attention you paid to respective reports.\n",
    "\n",
    "## Summary (in technical terms)\n",
    "\n",
    "Now, lets take an overview of the model with some technical terms. For a given import, the DATE model works in the following steps;\n",
    "\n",
    "* **XGBoost**: The model passes the import into a XGBoost model which constructs multiple(eg. 100) decision trees. \n",
    "* **Embedding**: Each tree's decision (decision path, leaf-id) is transformed into a set of numbers to be fed into neural networks. \n",
    "* **Multi-head Self-attention**\n",
    "    - Self-attention: The numeric value (importance, weight) of each leaf-id is adjusted based on its correlation/interaction with other leaf-ids.\n",
    "    - Multi-head: Self-iteration is repeated in multiple times to achieve its robustness.\n",
    "* **Attention**: The numeric values (importance, weight) of each leaf-id is re-adjusted based on its correlation/interaction with the given importer-id and item-id(HScode).\n",
    "\n",
    "## OUTLINE\n",
    "* [Part 1. Preprocess data](#part1)\n",
    "* [Part 2. XGBoost model](#part2)\n",
    "* [Part 3. DATE (XGBoost + Neural Networks + Attention)](#part3)\n",
    "* [Part 4. Evaluation](#part4)\n",
    "* [Part 5. Practice of functions](#part5)\n",
    "* [Part 6. XGBoost + Logistic Regression model](#part6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Preprocess <a id='part1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:10:42.331858Z",
     "start_time": "2022-02-22T04:10:41.948691Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pickle\n",
    "pd.set_option('display.max_columns',100)\n",
    "from collections import defaultdict\n",
    "from itertools import islice, combinations\n",
    "from datetime import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:10:44.971854Z",
     "start_time": "2022-02-22T04:10:44.809803Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/synthetic-imports-declarations.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:10:47.765438Z",
     "start_time": "2022-02-22T04:10:47.755821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sgd.id</th>\n",
       "      <th>sgd.date</th>\n",
       "      <th>importer.id</th>\n",
       "      <th>declarant.id</th>\n",
       "      <th>country</th>\n",
       "      <th>office.id</th>\n",
       "      <th>tariff.code</th>\n",
       "      <th>quantity</th>\n",
       "      <th>gross.weight</th>\n",
       "      <th>fob.value</th>\n",
       "      <th>cif.value</th>\n",
       "      <th>total.taxes</th>\n",
       "      <th>illicit</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD1</td>\n",
       "      <td>13-01-02</td>\n",
       "      <td>IMP826164</td>\n",
       "      <td>DEC3207</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>OFFICE92</td>\n",
       "      <td>8703241128</td>\n",
       "      <td>1581</td>\n",
       "      <td>26494</td>\n",
       "      <td>2390</td>\n",
       "      <td>2809</td>\n",
       "      <td>647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD2</td>\n",
       "      <td>13-01-02</td>\n",
       "      <td>IMP837219</td>\n",
       "      <td>DEC1525</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>8703232926</td>\n",
       "      <td>1</td>\n",
       "      <td>3910</td>\n",
       "      <td>204098</td>\n",
       "      <td>266140</td>\n",
       "      <td>3262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD3</td>\n",
       "      <td>13-01-02</td>\n",
       "      <td>IMP117406</td>\n",
       "      <td>DEC4146</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>8517180000</td>\n",
       "      <td>1</td>\n",
       "      <td>699231</td>\n",
       "      <td>302275</td>\n",
       "      <td>302275</td>\n",
       "      <td>5612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD4</td>\n",
       "      <td>13-01-02</td>\n",
       "      <td>IMP435108</td>\n",
       "      <td>DEC4242</td>\n",
       "      <td>CNTRY376</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>8703222900</td>\n",
       "      <td>1288</td>\n",
       "      <td>22958</td>\n",
       "      <td>3019</td>\n",
       "      <td>4160</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGD5</td>\n",
       "      <td>13-01-02</td>\n",
       "      <td>IMP717900</td>\n",
       "      <td>DEC6324</td>\n",
       "      <td>CNTRY454</td>\n",
       "      <td>OFFICE92</td>\n",
       "      <td>8545200000</td>\n",
       "      <td>42</td>\n",
       "      <td>21248</td>\n",
       "      <td>156348</td>\n",
       "      <td>239549</td>\n",
       "      <td>397</td>\n",
       "      <td>1</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sgd.id  sgd.date importer.id declarant.id   country office.id  tariff.code  \\\n",
       "0   SGD1  13-01-02   IMP826164      DEC3207  CNTRY680  OFFICE92   8703241128   \n",
       "1   SGD2  13-01-02   IMP837219      DEC1525  CNTRY680  OFFICE51   8703232926   \n",
       "2   SGD3  13-01-02   IMP117406      DEC4146  CNTRY680  OFFICE59   8517180000   \n",
       "3   SGD4  13-01-02   IMP435108      DEC4242  CNTRY376  OFFICE51   8703222900   \n",
       "4   SGD5  13-01-02   IMP717900      DEC6324  CNTRY454  OFFICE92   8545200000   \n",
       "\n",
       "   quantity  gross.weight  fob.value  cif.value  total.taxes  illicit  revenue  \n",
       "0      1581         26494       2390       2809          647        0        0  \n",
       "1         1          3910     204098     266140         3262        0        0  \n",
       "2         1        699231     302275     302275         5612        0        0  \n",
       "3      1288         22958       3019       4160          514        0        0  \n",
       "4        42         21248     156348     239549          397        1      980  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:10:55.193809Z",
     "start_time": "2022-02-22T04:10:55.191450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define columns to use\n",
    "column_to_use = ['sgd.date','office.id','importer.id', \n",
    "                 'declarant.id','tariff.code','country',\n",
    "                 'cif.value','quantity','gross.weight',\n",
    "                 'total.taxes','revenue','illicit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:11:04.726411Z",
     "start_time": "2022-02-22T04:11:04.709408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select columns\n",
    "df = df[column_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T10:03:18.167013Z",
     "start_time": "2022-02-22T10:03:18.141303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sgd.date</th>\n",
       "      <th>office.id</th>\n",
       "      <th>importer.id</th>\n",
       "      <th>declarant.id</th>\n",
       "      <th>tariff.code</th>\n",
       "      <th>country</th>\n",
       "      <th>cif.value</th>\n",
       "      <th>quantity</th>\n",
       "      <th>gross.weight</th>\n",
       "      <th>total.taxes</th>\n",
       "      <th>revenue</th>\n",
       "      <th>illicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13-01-02</td>\n",
       "      <td>OFFICE92</td>\n",
       "      <td>IMP826164</td>\n",
       "      <td>DEC3207</td>\n",
       "      <td>8703241128</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>2809</td>\n",
       "      <td>1581</td>\n",
       "      <td>26494</td>\n",
       "      <td>647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>13-01-02</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>IMP585253</td>\n",
       "      <td>DEC9272</td>\n",
       "      <td>8703242900</td>\n",
       "      <td>CNTRY759</td>\n",
       "      <td>2279</td>\n",
       "      <td>1</td>\n",
       "      <td>1136</td>\n",
       "      <td>3305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13-01-02</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP837219</td>\n",
       "      <td>DEC1525</td>\n",
       "      <td>8703232926</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>266140</td>\n",
       "      <td>1</td>\n",
       "      <td>3910</td>\n",
       "      <td>3262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13-01-02</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>IMP117406</td>\n",
       "      <td>DEC4146</td>\n",
       "      <td>8517180000</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>302275</td>\n",
       "      <td>1</td>\n",
       "      <td>699231</td>\n",
       "      <td>5612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13-01-02</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP435108</td>\n",
       "      <td>DEC4242</td>\n",
       "      <td>8703222900</td>\n",
       "      <td>CNTRY376</td>\n",
       "      <td>4160</td>\n",
       "      <td>1288</td>\n",
       "      <td>22958</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>13-12-31</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>IMP589573</td>\n",
       "      <td>DEC2816</td>\n",
       "      <td>8704212025</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>4407</td>\n",
       "      <td>40982</td>\n",
       "      <td>400198</td>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>13-12-31</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP889666</td>\n",
       "      <td>DEC5765</td>\n",
       "      <td>3506910000</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>710125</td>\n",
       "      <td>1</td>\n",
       "      <td>1079</td>\n",
       "      <td>477</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>13-12-31</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP853002</td>\n",
       "      <td>DEC5832</td>\n",
       "      <td>8702101319</td>\n",
       "      <td>CNTRY759</td>\n",
       "      <td>303957</td>\n",
       "      <td>1</td>\n",
       "      <td>822679</td>\n",
       "      <td>795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>13-12-31</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>IMP933717</td>\n",
       "      <td>DEC5891</td>\n",
       "      <td>808100000</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>486070</td>\n",
       "      <td>1</td>\n",
       "      <td>12234</td>\n",
       "      <td>3092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>13-12-31</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP456549</td>\n",
       "      <td>DEC7180</td>\n",
       "      <td>8702101319</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>10495</td>\n",
       "      <td>5</td>\n",
       "      <td>1693</td>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sgd.date office.id importer.id declarant.id  tariff.code   country  \\\n",
       "0      13-01-02  OFFICE92   IMP826164      DEC3207   8703241128  CNTRY680   \n",
       "143    13-01-02  OFFICE59   IMP585253      DEC9272   8703242900  CNTRY759   \n",
       "1      13-01-02  OFFICE51   IMP837219      DEC1525   8703232926  CNTRY680   \n",
       "2      13-01-02  OFFICE59   IMP117406      DEC4146   8517180000  CNTRY680   \n",
       "3      13-01-02  OFFICE51   IMP435108      DEC4242   8703222900  CNTRY376   \n",
       "...         ...       ...         ...          ...          ...       ...   \n",
       "99988  13-12-31  OFFICE59   IMP589573      DEC2816   8704212025  CNTRY680   \n",
       "99987  13-12-31  OFFICE51   IMP889666      DEC5765   3506910000  CNTRY680   \n",
       "99986  13-12-31  OFFICE51   IMP853002      DEC5832   8702101319  CNTRY759   \n",
       "99992  13-12-31  OFFICE59   IMP933717      DEC5891    808100000  CNTRY680   \n",
       "99999  13-12-31  OFFICE51   IMP456549      DEC7180   8702101319  CNTRY680   \n",
       "\n",
       "       cif.value  quantity  gross.weight  total.taxes  revenue  illicit  \n",
       "0           2809      1581         26494          647        0        0  \n",
       "143         2279         1          1136         3305        0        0  \n",
       "1         266140         1          3910         3262        0        0  \n",
       "2         302275         1        699231         5612        0        0  \n",
       "3           4160      1288         22958          514        0        0  \n",
       "...          ...       ...           ...          ...      ...      ...  \n",
       "99988       4407     40982        400198          490        0        0  \n",
       "99987     710125         1          1079          477        0        0  \n",
       "99986     303957         1        822679          795        0        0  \n",
       "99992     486070         1         12234         3092        0        0  \n",
       "99999      10495         5          1693          468        0        0  \n",
       "\n",
       "[100000 rows x 12 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:11:14.187930Z",
     "start_time": "2022-02-22T04:11:14.150891Z"
    }
   },
   "outputs": [],
   "source": [
    "df=df.sort_values('sgd.date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:11:16.697771Z",
     "start_time": "2022-02-22T04:11:16.671695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   sgd.date      100000 non-null  object\n",
      " 1   office.id     100000 non-null  object\n",
      " 2   importer.id   100000 non-null  object\n",
      " 3   declarant.id  100000 non-null  object\n",
      " 4   tariff.code   100000 non-null  int64 \n",
      " 5   country       100000 non-null  object\n",
      " 6   cif.value     100000 non-null  int64 \n",
      " 7   quantity      100000 non-null  int64 \n",
      " 8   gross.weight  100000 non-null  int64 \n",
      " 9   total.taxes   100000 non-null  int64 \n",
      " 10  revenue       100000 non-null  int64 \n",
      " 11  illicit       100000 non-null  int64 \n",
      "dtypes: int64(7), object(5)\n",
      "memory usage: 9.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:11:31.624478Z",
     "start_time": "2022-02-22T04:11:31.615476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Finish loading data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Define functions to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. \"merge_attributes\" function [(link to practice)](#practice1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This \"merge_attributes\" fuction is to create a new categorical variable by combining multiple existing categorical variables into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:12:07.824859Z",
     "start_time": "2022-02-22T04:12:07.803857Z"
    }
   },
   "outputs": [],
   "source": [
    "#把两个字符串特征进行合并，本质上是特征交叉\n",
    "def merge_attributes(df: pd.DataFrame, *args: str) -> None: \n",
    "    # Note: \"*args\" represents multiple arguments, i.e. multiple variable names could come. \n",
    "    # Note: \"-> None\" represents that this function returns None (i.e. type annotation)\n",
    "    \"\"\"\n",
    "    dtype df: dataframe\n",
    "    dtype *args: strings (attribute names that want to be combined)\n",
    "    \"\"\"\n",
    "    # To set data type of each argument as string\n",
    "    iterables = [df[arg].astype(str) for arg in args] \n",
    "    # To name the newly combined variable/column\n",
    "    columnName = '&'.join([*args]) \n",
    "    # To create a column for the combined variable\n",
    "    fs = [''.join([v for v in var]) for var in zip(*iterables)] # \"*\" represents \"unzip\"\n",
    "    df.loc[:, columnName] = fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2. \"preprocess\" function [(link to practice)](#practice2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fuction is to;\n",
    "* generate additional features such as unitprice, weight-unitprice and effective tariff rate;\n",
    "* merge some attributes, using the above \"merge_attributes\" function; and \n",
    "* generate date-related features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:14:49.156929Z",
     "start_time": "2022-02-22T04:14:49.136925Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Note: \"-> pd.DataFrame\" represents that this function returns a dataframe.\n",
    "    \"\"\"\n",
    "    dtype df: dataframe\n",
    "    rtype df: dataframe\n",
    "    \"\"\"\n",
    "    df = df.dropna(subset=['total.taxes']) # Remove rows which does not have these values.\n",
    "    df.loc[:, 'Unitprice'] = df['cif.value']/df['quantity']\n",
    "    df.loc[:, 'WUnitprice'] = df['cif.value']/df['gross.weight']\n",
    "    df.loc[:, 'TaxRatio'] = df['total.taxes'] / df['cif.value']\n",
    "    df.loc[:, 'TaxUnitquantity'] = df['total.taxes'] / df['quantity']\n",
    "    df.loc[:, 'HS6'] = df['tariff.code'].apply(lambda x: int(x // 10000))\n",
    "    df.loc[:, 'HS4'] = df['HS6'].apply(lambda x: int(x // 100))\n",
    "    df.loc[:, 'HS2'] = df['HS4'].apply(lambda x: int(x // 100))\n",
    "    \n",
    "    # Made a general function \"merge_attributes\" for supporting any combination    \n",
    "    merge_attributes(df, 'HS6','country')\n",
    "    merge_attributes(df, 'office.id','importer.id')\n",
    "    merge_attributes(df, 'office.id','HS6')\n",
    "    merge_attributes(df, 'office.id','country')\n",
    "    \n",
    "    # another way of combining features\n",
    "    #df.loc[:, 'HS6.country'] = [str(i)+'&'+j for i, j in zip(df['HS6'], df['country'])]\n",
    "    \n",
    "    \n",
    "    # Day of Year of sgd.date\n",
    "    tmp2 = {}\n",
    "    for date in set(df['sgd.date']):\n",
    "        tmp2[date] = dt.strptime(date, '%y-%m-%d') \n",
    "    tmp_day = {}\n",
    "    tmp_week = {}\n",
    "    tmp_month = {}\n",
    "    yearStart = dt(tmp2[date].date().year, 1, 1)\n",
    "    for item in tmp2:\n",
    "        tmp_day[item] = (tmp2[item] - yearStart).days\n",
    "        tmp_week[item] = int(tmp_day[item] / 7)\n",
    "        tmp_month[item] = int(tmp_day[item] / 30)\n",
    "        \n",
    "    df.loc[:, 'SGD.DayofYear'] = df['sgd.date'].apply(lambda x: tmp_day[x])\n",
    "    df.loc[:, 'SGD.WeekofYear'] = df['sgd.date'].apply(lambda x: tmp_week[x])\n",
    "    df.loc[:, 'SGD.MonthofYear'] = df['sgd.date'].apply(lambda x: tmp_month[x])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3. \"find_risk_profile\" function [(link to practice)](#practice3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to identify/calculate risk-profiling indicators of the features;\n",
    "* option 1 (topk): Lists of top n high-risk categories in the features\n",
    "* option 2 (ratio): illicit ratio of categories in the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:17:41.918638Z",
     "start_time": "2022-02-22T04:17:41.901611Z"
    }
   },
   "outputs": [],
   "source": [
    "#把类别变量按照风险程度进行排序，然后选出前10的来进行标签？类似于目标编码，不建议使用。\n",
    "def find_risk_profile(df: pd.DataFrame, \n",
    "                      feature: str, \n",
    "                      topk_ratio: float, \n",
    "                      adj: float, \n",
    "                      option: str) -> list or dict:\n",
    "    \"\"\"\n",
    "    dtype feature: str\n",
    "    dtype topk_ratio: float (range: 0-1)\n",
    "    dtype adj: float (to modify the mean)\n",
    "    dtype option: str ('topk', 'ratio')\n",
    "    rtype: list(option='topk') or dict(option='ratio')\n",
    "    \n",
    "    The option topk is usually better than the ratio because of overfitting.\n",
    "    \"\"\"\n",
    "\n",
    "    # Top-k suspicious item flagging\n",
    "    if option == 'topk':\n",
    "        # Group data by a specified feature(vairable)\n",
    "        total_cnt = df.groupby([feature])['illicit']\n",
    "        # Set the number of entities to be included a black list.\n",
    "        nrisky_profile = int(topk_ratio*len(total_cnt))+1\n",
    "        # For each entity, calculate 'total number of frauds' divided by 'total number of imports' \n",
    "        adj_prob_illicit = total_cnt.sum() / (total_cnt.count()+adj)  # Smoothed mean\n",
    "        return list(adj_prob_illicit.sort_values(ascending=False).head(nrisky_profile).index)\n",
    "    \n",
    "    # Illicit-ratio encoding (Mean target encoding)\n",
    "    # Refer: http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging/target-encoding.html\n",
    "    # Refer: https://towardsdatascience.com/why-you-should-try-mean-encoding-17057262cd0\n",
    "    elif option == 'ratio':\n",
    "        # For target encoding, we just use 70% of train data to avoid overfitting (otherwise, test AUC drops significantly)\n",
    "        total_cnt = df.sample(frac=0.7).groupby([feature])['illicit']\n",
    "        # prob_illicit = total_cnt.mean()  # Simple mean\n",
    "        adj_prob_illicit = total_cnt.sum() / (total_cnt.count()+adj)  # Smoothed mean\n",
    "        return adj_prob_illicit.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4. \"tag_risky_profiles\" function [(link to practice)](#practice4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to generate risk-profiling tags of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:42:34.609343Z",
     "start_time": "2022-02-22T06:42:34.591336Z"
    }
   },
   "outputs": [],
   "source": [
    "def tag_risky_profiles(df: pd.DataFrame, \n",
    "                       profile: str, \n",
    "                       profiles: list or dict, \n",
    "                       option: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    dtype df: dataframe\n",
    "    dtype profile: str\n",
    "    dtype profiles: list(option='topk') or dictionary(option='ratio')\n",
    "    dtype option: str ('topk', 'ratio')\n",
    "    rtype: dataframe\n",
    "    \n",
    "    The option topk is usually better than the ratio because of overfitting.\n",
    "    \"\"\"\n",
    "    # Top-k suspicious item flagging\n",
    "    if option == 'topk':\n",
    "        d = defaultdict(int) # return 0 for not-defined keys\n",
    "        for id in profiles:\n",
    "            d[id] = 1\n",
    "    #     print(list(islice(d.items(), 10)))  # For debugging\n",
    "        df.loc[:, 'RiskH.'+profile] = df[profile].apply(lambda x: d[x])\n",
    "    \n",
    "    # Illicit-ratio encoding\n",
    "    elif option == 'ratio':\n",
    "        overall_ratio_train = np.mean(train.illicit) # When scripting, saving it as a class variable is clearer.\n",
    "        df.loc[:, 'RiskH.'+profile] = df[profile].apply(lambda x: profiles.get(x,overall_ratio_train))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.4. Preprocess data with pre-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:40:04.269558Z",
     "start_time": "2022-02-22T06:40:04.261451Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset settings\n",
    "data_length = df.shape[0]\n",
    "train_ratio = 0.6\n",
    "valid_ratio = 0.8\n",
    "train_length = int(data_length*train_ratio)\n",
    "valid_length = int(data_length*valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:40:06.049051Z",
     "start_time": "2022-02-22T06:40:05.995040Z"
    }
   },
   "outputs": [],
   "source": [
    "# One way of splitting train/valid/test set\n",
    "df=df.sort_values('sgd.date')\n",
    "train = df.iloc[:train_length,:]\n",
    "valid = df.iloc[train_length:valid_length,:]\n",
    "test = df.iloc[valid_length:,:]\n",
    "\n",
    "## Another way of splitting - explicitly split by time\n",
    "#train = df[df[\"sgd.date\"] < \"2013-11-01\"]\n",
    "#valid = df[(df[\"sgd.date\"] >= \"2013-11-01\") & (df[\"SGD.DATE\"] < \"2013-11-01\")]\n",
    "#test = df[df[\"sgd.date\"] >= \"2013-12-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:40:08.638396Z",
     "start_time": "2022-02-22T06:40:08.623393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 12), (20000, 12), (20000, 12))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:40:11.065935Z",
     "start_time": "2022-02-22T06:40:11.050914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sgd.date', 'office.id', 'importer.id', 'declarant.id', 'tariff.code',\n",
       "       'country', 'cif.value', 'quantity', 'gross.weight', 'total.taxes',\n",
       "       'revenue', 'illicit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:40:19.169231Z",
     "start_time": "2022-02-22T06:40:19.157159Z"
    }
   },
   "outputs": [],
   "source": [
    "# save label data\n",
    "train_reg_label = train['revenue'].values\n",
    "valid_reg_label = valid['revenue'].values\n",
    "test_reg_label = test['revenue'].values\n",
    "train_cls_label = train[\"illicit\"].values\n",
    "valid_cls_label = valid[\"illicit\"].values\n",
    "test_cls_label = test[\"illicit\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:40:37.824295Z",
     "start_time": "2022-02-22T06:40:36.967056Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run preprocessing\n",
    "train = preprocess(train)\n",
    "valid = preprocess(valid)\n",
    "test = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:40:40.328786Z",
     "start_time": "2022-02-22T06:40:40.311169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sgd.date', 'office.id', 'importer.id', 'declarant.id', 'tariff.code',\n",
       "       'country', 'cif.value', 'quantity', 'gross.weight', 'total.taxes',\n",
       "       'revenue', 'illicit', 'Unitprice', 'WUnitprice', 'TaxRatio',\n",
       "       'TaxUnitquantity', 'HS6', 'HS4', 'HS2', 'HS6&country',\n",
       "       'office.id&importer.id', 'office.id&HS6', 'office.id&country',\n",
       "       'SGD.DayofYear', 'SGD.WeekofYear', 'SGD.MonthofYear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:42:39.243437Z",
     "start_time": "2022-02-22T06:42:38.217504Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add a few more risky profiles\n",
    "risk_profiles = {}\n",
    "profile_candidates = ['importer.id', 'declarant.id', 'tariff.code', 'quantity', 'HS6', 'HS4', 'HS2', 'office.id'] + [col for col in train.columns if '&' in col]\n",
    "\n",
    "for profile in profile_candidates:\n",
    "    option = 'topk'\n",
    "    risk_profiles[profile] = find_risk_profile(train, profile, 0.1, 10, option=option)\n",
    "    train = tag_risky_profiles(train, profile, risk_profiles[profile], option=option)\n",
    "    valid = tag_risky_profiles(valid, profile, risk_profiles[profile], option=option)\n",
    "    test = tag_risky_profiles(test, profile, risk_profiles[profile], option=option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:42:54.178942Z",
     "start_time": "2022-02-22T06:42:54.151933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sgd.date</th>\n",
       "      <th>office.id</th>\n",
       "      <th>importer.id</th>\n",
       "      <th>declarant.id</th>\n",
       "      <th>tariff.code</th>\n",
       "      <th>country</th>\n",
       "      <th>cif.value</th>\n",
       "      <th>quantity</th>\n",
       "      <th>gross.weight</th>\n",
       "      <th>total.taxes</th>\n",
       "      <th>revenue</th>\n",
       "      <th>illicit</th>\n",
       "      <th>Unitprice</th>\n",
       "      <th>WUnitprice</th>\n",
       "      <th>TaxRatio</th>\n",
       "      <th>TaxUnitquantity</th>\n",
       "      <th>HS6</th>\n",
       "      <th>HS4</th>\n",
       "      <th>HS2</th>\n",
       "      <th>HS6&amp;country</th>\n",
       "      <th>office.id&amp;importer.id</th>\n",
       "      <th>office.id&amp;HS6</th>\n",
       "      <th>office.id&amp;country</th>\n",
       "      <th>SGD.DayofYear</th>\n",
       "      <th>SGD.WeekofYear</th>\n",
       "      <th>SGD.MonthofYear</th>\n",
       "      <th>RiskH.importer.id</th>\n",
       "      <th>RiskH.declarant.id</th>\n",
       "      <th>RiskH.tariff.code</th>\n",
       "      <th>RiskH.quantity</th>\n",
       "      <th>RiskH.HS6</th>\n",
       "      <th>RiskH.HS4</th>\n",
       "      <th>RiskH.HS2</th>\n",
       "      <th>RiskH.office.id</th>\n",
       "      <th>RiskH.HS6&amp;country</th>\n",
       "      <th>RiskH.office.id&amp;importer.id</th>\n",
       "      <th>RiskH.office.id&amp;HS6</th>\n",
       "      <th>RiskH.office.id&amp;country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13-01-02</td>\n",
       "      <td>OFFICE92</td>\n",
       "      <td>IMP826164</td>\n",
       "      <td>DEC3207</td>\n",
       "      <td>8703241128</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>2809</td>\n",
       "      <td>1581</td>\n",
       "      <td>26494</td>\n",
       "      <td>647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.776724</td>\n",
       "      <td>0.106024</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.409235</td>\n",
       "      <td>870324</td>\n",
       "      <td>8703</td>\n",
       "      <td>87</td>\n",
       "      <td>870324CNTRY680</td>\n",
       "      <td>OFFICE92IMP826164</td>\n",
       "      <td>OFFICE92870324</td>\n",
       "      <td>OFFICE92CNTRY680</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>13-01-02</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>IMP585253</td>\n",
       "      <td>DEC9272</td>\n",
       "      <td>8703242900</td>\n",
       "      <td>CNTRY759</td>\n",
       "      <td>2279</td>\n",
       "      <td>1</td>\n",
       "      <td>1136</td>\n",
       "      <td>3305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2279.000000</td>\n",
       "      <td>2.006162</td>\n",
       "      <td>1.450197</td>\n",
       "      <td>3305.000000</td>\n",
       "      <td>870324</td>\n",
       "      <td>8703</td>\n",
       "      <td>87</td>\n",
       "      <td>870324CNTRY759</td>\n",
       "      <td>OFFICE59IMP585253</td>\n",
       "      <td>OFFICE59870324</td>\n",
       "      <td>OFFICE59CNTRY759</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13-01-02</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP837219</td>\n",
       "      <td>DEC1525</td>\n",
       "      <td>8703232926</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>266140</td>\n",
       "      <td>1</td>\n",
       "      <td>3910</td>\n",
       "      <td>3262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266140.000000</td>\n",
       "      <td>68.066496</td>\n",
       "      <td>0.012257</td>\n",
       "      <td>3262.000000</td>\n",
       "      <td>870323</td>\n",
       "      <td>8703</td>\n",
       "      <td>87</td>\n",
       "      <td>870323CNTRY680</td>\n",
       "      <td>OFFICE51IMP837219</td>\n",
       "      <td>OFFICE51870323</td>\n",
       "      <td>OFFICE51CNTRY680</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13-01-02</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>IMP117406</td>\n",
       "      <td>DEC4146</td>\n",
       "      <td>8517180000</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>302275</td>\n",
       "      <td>1</td>\n",
       "      <td>699231</td>\n",
       "      <td>5612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302275.000000</td>\n",
       "      <td>0.432296</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>5612.000000</td>\n",
       "      <td>851718</td>\n",
       "      <td>8517</td>\n",
       "      <td>85</td>\n",
       "      <td>851718CNTRY680</td>\n",
       "      <td>OFFICE59IMP117406</td>\n",
       "      <td>OFFICE59851718</td>\n",
       "      <td>OFFICE59CNTRY680</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13-01-02</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP435108</td>\n",
       "      <td>DEC4242</td>\n",
       "      <td>8703222900</td>\n",
       "      <td>CNTRY376</td>\n",
       "      <td>4160</td>\n",
       "      <td>1288</td>\n",
       "      <td>22958</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.229814</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.123558</td>\n",
       "      <td>0.399068</td>\n",
       "      <td>870322</td>\n",
       "      <td>8703</td>\n",
       "      <td>87</td>\n",
       "      <td>870322CNTRY376</td>\n",
       "      <td>OFFICE51IMP435108</td>\n",
       "      <td>OFFICE51870322</td>\n",
       "      <td>OFFICE51CNTRY376</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>13-08-28</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>IMP566004</td>\n",
       "      <td>DEC8916</td>\n",
       "      <td>8703232926</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>3200</td>\n",
       "      <td>1</td>\n",
       "      <td>2072</td>\n",
       "      <td>4265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3200.000000</td>\n",
       "      <td>1.544402</td>\n",
       "      <td>1.332812</td>\n",
       "      <td>4265.000000</td>\n",
       "      <td>870323</td>\n",
       "      <td>8703</td>\n",
       "      <td>87</td>\n",
       "      <td>870323CNTRY680</td>\n",
       "      <td>OFFICE59IMP566004</td>\n",
       "      <td>OFFICE59870323</td>\n",
       "      <td>OFFICE59CNTRY680</td>\n",
       "      <td>239</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60024</th>\n",
       "      <td>13-08-28</td>\n",
       "      <td>OFFICE23</td>\n",
       "      <td>IMP975201</td>\n",
       "      <td>DEC8001</td>\n",
       "      <td>8468900000</td>\n",
       "      <td>CNTRY334</td>\n",
       "      <td>1737</td>\n",
       "      <td>1</td>\n",
       "      <td>1011</td>\n",
       "      <td>1181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1737.000000</td>\n",
       "      <td>1.718101</td>\n",
       "      <td>0.679908</td>\n",
       "      <td>1181.000000</td>\n",
       "      <td>846890</td>\n",
       "      <td>8468</td>\n",
       "      <td>84</td>\n",
       "      <td>846890CNTRY334</td>\n",
       "      <td>OFFICE23IMP975201</td>\n",
       "      <td>OFFICE23846890</td>\n",
       "      <td>OFFICE23CNTRY334</td>\n",
       "      <td>239</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>13-08-28</td>\n",
       "      <td>OFFICE41</td>\n",
       "      <td>IMP340373</td>\n",
       "      <td>DEC1829</td>\n",
       "      <td>8536610000</td>\n",
       "      <td>CNTRY881</td>\n",
       "      <td>2626</td>\n",
       "      <td>831</td>\n",
       "      <td>18705</td>\n",
       "      <td>1141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.160048</td>\n",
       "      <td>0.140390</td>\n",
       "      <td>0.434501</td>\n",
       "      <td>1.373045</td>\n",
       "      <td>853661</td>\n",
       "      <td>8536</td>\n",
       "      <td>85</td>\n",
       "      <td>853661CNTRY881</td>\n",
       "      <td>OFFICE41IMP340373</td>\n",
       "      <td>OFFICE41853661</td>\n",
       "      <td>OFFICE41CNTRY881</td>\n",
       "      <td>239</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>13-08-28</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP439370</td>\n",
       "      <td>DEC2253</td>\n",
       "      <td>8703232926</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>266996</td>\n",
       "      <td>1</td>\n",
       "      <td>1219</td>\n",
       "      <td>2845</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266996.000000</td>\n",
       "      <td>219.028712</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>2845.000000</td>\n",
       "      <td>870323</td>\n",
       "      <td>8703</td>\n",
       "      <td>87</td>\n",
       "      <td>870323CNTRY680</td>\n",
       "      <td>OFFICE51IMP439370</td>\n",
       "      <td>OFFICE51870323</td>\n",
       "      <td>OFFICE51CNTRY680</td>\n",
       "      <td>239</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>13-08-28</td>\n",
       "      <td>OFFICE41</td>\n",
       "      <td>IMP801175</td>\n",
       "      <td>DEC2630</td>\n",
       "      <td>4810290029</td>\n",
       "      <td>CNTRY764</td>\n",
       "      <td>20407</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>2576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6802.333333</td>\n",
       "      <td>583.057143</td>\n",
       "      <td>0.126231</td>\n",
       "      <td>858.666667</td>\n",
       "      <td>481029</td>\n",
       "      <td>4810</td>\n",
       "      <td>48</td>\n",
       "      <td>481029CNTRY764</td>\n",
       "      <td>OFFICE41IMP801175</td>\n",
       "      <td>OFFICE41481029</td>\n",
       "      <td>OFFICE41CNTRY764</td>\n",
       "      <td>239</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sgd.date office.id importer.id declarant.id  tariff.code   country  \\\n",
       "0      13-01-02  OFFICE92   IMP826164      DEC3207   8703241128  CNTRY680   \n",
       "143    13-01-02  OFFICE59   IMP585253      DEC9272   8703242900  CNTRY759   \n",
       "1      13-01-02  OFFICE51   IMP837219      DEC1525   8703232926  CNTRY680   \n",
       "2      13-01-02  OFFICE59   IMP117406      DEC4146   8517180000  CNTRY680   \n",
       "3      13-01-02  OFFICE51   IMP435108      DEC4242   8703222900  CNTRY376   \n",
       "...         ...       ...         ...          ...          ...       ...   \n",
       "59995  13-08-28  OFFICE59   IMP566004      DEC8916   8703232926  CNTRY680   \n",
       "60024  13-08-28  OFFICE23   IMP975201      DEC8001   8468900000  CNTRY334   \n",
       "59997  13-08-28  OFFICE41   IMP340373      DEC1829   8536610000  CNTRY881   \n",
       "59998  13-08-28  OFFICE51   IMP439370      DEC2253   8703232926  CNTRY680   \n",
       "59999  13-08-28  OFFICE41   IMP801175      DEC2630   4810290029  CNTRY764   \n",
       "\n",
       "       cif.value  quantity  gross.weight  total.taxes  revenue  illicit  \\\n",
       "0           2809      1581         26494          647        0        0   \n",
       "143         2279         1          1136         3305        0        0   \n",
       "1         266140         1          3910         3262        0        0   \n",
       "2         302275         1        699231         5612        0        0   \n",
       "3           4160      1288         22958          514        0        0   \n",
       "...          ...       ...           ...          ...      ...      ...   \n",
       "59995       3200         1          2072         4265        0        0   \n",
       "60024       1737         1          1011         1181        0        0   \n",
       "59997       2626       831         18705         1141        0        0   \n",
       "59998     266996         1          1219         2845        0        0   \n",
       "59999      20407         3            35         2576        0        0   \n",
       "\n",
       "           Unitprice  WUnitprice  TaxRatio  TaxUnitquantity     HS6   HS4  \\\n",
       "0           1.776724    0.106024  0.230331         0.409235  870324  8703   \n",
       "143      2279.000000    2.006162  1.450197      3305.000000  870324  8703   \n",
       "1      266140.000000   68.066496  0.012257      3262.000000  870323  8703   \n",
       "2      302275.000000    0.432296  0.018566      5612.000000  851718  8517   \n",
       "3           3.229814    0.181200  0.123558         0.399068  870322  8703   \n",
       "...              ...         ...       ...              ...     ...   ...   \n",
       "59995    3200.000000    1.544402  1.332812      4265.000000  870323  8703   \n",
       "60024    1737.000000    1.718101  0.679908      1181.000000  846890  8468   \n",
       "59997       3.160048    0.140390  0.434501         1.373045  853661  8536   \n",
       "59998  266996.000000  219.028712  0.010656      2845.000000  870323  8703   \n",
       "59999    6802.333333  583.057143  0.126231       858.666667  481029  4810   \n",
       "\n",
       "       HS2     HS6&country office.id&importer.id   office.id&HS6  \\\n",
       "0       87  870324CNTRY680     OFFICE92IMP826164  OFFICE92870324   \n",
       "143     87  870324CNTRY759     OFFICE59IMP585253  OFFICE59870324   \n",
       "1       87  870323CNTRY680     OFFICE51IMP837219  OFFICE51870323   \n",
       "2       85  851718CNTRY680     OFFICE59IMP117406  OFFICE59851718   \n",
       "3       87  870322CNTRY376     OFFICE51IMP435108  OFFICE51870322   \n",
       "...    ...             ...                   ...             ...   \n",
       "59995   87  870323CNTRY680     OFFICE59IMP566004  OFFICE59870323   \n",
       "60024   84  846890CNTRY334     OFFICE23IMP975201  OFFICE23846890   \n",
       "59997   85  853661CNTRY881     OFFICE41IMP340373  OFFICE41853661   \n",
       "59998   87  870323CNTRY680     OFFICE51IMP439370  OFFICE51870323   \n",
       "59999   48  481029CNTRY764     OFFICE41IMP801175  OFFICE41481029   \n",
       "\n",
       "      office.id&country  SGD.DayofYear  SGD.WeekofYear  SGD.MonthofYear  \\\n",
       "0      OFFICE92CNTRY680              1               0                0   \n",
       "143    OFFICE59CNTRY759              1               0                0   \n",
       "1      OFFICE51CNTRY680              1               0                0   \n",
       "2      OFFICE59CNTRY680              1               0                0   \n",
       "3      OFFICE51CNTRY376              1               0                0   \n",
       "...                 ...            ...             ...              ...   \n",
       "59995  OFFICE59CNTRY680            239              34                7   \n",
       "60024  OFFICE23CNTRY334            239              34                7   \n",
       "59997  OFFICE41CNTRY881            239              34                7   \n",
       "59998  OFFICE51CNTRY680            239              34                7   \n",
       "59999  OFFICE41CNTRY764            239              34                7   \n",
       "\n",
       "       RiskH.importer.id  RiskH.declarant.id  RiskH.tariff.code  \\\n",
       "0                      0                   0                  0   \n",
       "143                    0                   0                  0   \n",
       "1                      0                   0                  0   \n",
       "2                      0                   0                  0   \n",
       "3                      0                   0                  0   \n",
       "...                  ...                 ...                ...   \n",
       "59995                  0                   0                  0   \n",
       "60024                  0                   0                  0   \n",
       "59997                  0                   0                  0   \n",
       "59998                  0                   0                  0   \n",
       "59999                  0                   1                  1   \n",
       "\n",
       "       RiskH.quantity  RiskH.HS6  RiskH.HS4  RiskH.HS2  RiskH.office.id  \\\n",
       "0                   0          0          0          0                0   \n",
       "143                 0          0          0          0                0   \n",
       "1                   0          0          0          0                0   \n",
       "2                   0          0          0          0                0   \n",
       "3                   0          0          0          0                0   \n",
       "...               ...        ...        ...        ...              ...   \n",
       "59995               0          0          0          0                0   \n",
       "60024               0          0          0          0                0   \n",
       "59997               0          0          0          0                0   \n",
       "59998               0          0          0          0                0   \n",
       "59999               1          1          1          0                0   \n",
       "\n",
       "       RiskH.HS6&country  RiskH.office.id&importer.id  RiskH.office.id&HS6  \\\n",
       "0                      0                            0                    0   \n",
       "143                    0                            0                    0   \n",
       "1                      0                            0                    0   \n",
       "2                      0                            0                    0   \n",
       "3                      0                            0                    0   \n",
       "...                  ...                          ...                  ...   \n",
       "59995                  0                            0                    0   \n",
       "60024                  0                            0                    0   \n",
       "59997                  0                            0                    0   \n",
       "59998                  0                            0                    0   \n",
       "59999                  0                            0                    0   \n",
       "\n",
       "       RiskH.office.id&country  \n",
       "0                            0  \n",
       "143                          0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "...                        ...  \n",
       "59995                        0  \n",
       "60024                        0  \n",
       "59997                        0  \n",
       "59998                        0  \n",
       "59999                        0  \n",
       "\n",
       "[60000 rows x 38 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:43:30.986559Z",
     "start_time": "2022-02-22T06:43:30.936241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Features to use in a classifier\n",
    "column_to_use = ['cif.value', 'total.taxes', 'gross.weight', 'quantity', 'Unitprice', 'WUnitprice', 'TaxRatio', 'TaxUnitquantity', 'tariff.code', 'HS6', 'HS4', 'HS2', 'SGD.DayofYear', 'SGD.WeekofYear', 'SGD.MonthofYear'] + [col for col in train.columns if 'RiskH' in col] \n",
    "\n",
    "# Extract only numeric values from data to be fed into models\n",
    "X_train = train[column_to_use].values\n",
    "X_valid = valid[column_to_use].values\n",
    "X_test = test[column_to_use].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:43:37.963803Z",
     "start_time": "2022-02-22T06:43:37.937515Z"
    }
   },
   "outputs": [],
   "source": [
    "# impute nan\n",
    "X_train = np.nan_to_num(X_train, 0)\n",
    "X_valid = np.nan_to_num(X_valid, 0)\n",
    "X_test = np.nan_to_num(X_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:43:39.876330Z",
     "start_time": "2022-02-22T06:43:39.861159Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data size...\n",
      "(60000, 27) (60000,) (60000,)\n",
      "(20000, 27) (20000,) (20000,)\n",
      "(20000, 27) (20000,) (20000,)\n"
     ]
    }
   ],
   "source": [
    "# make sure the data size are correct\n",
    "print(\"Checking data size...\")\n",
    "print(X_train.shape, train_cls_label.shape, train_reg_label.shape)\n",
    "print(X_valid.shape, valid_cls_label.shape, valid_reg_label.shape)\n",
    "print(X_test.shape, test_cls_label.shape, test_reg_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Save all the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:43:59.058252Z",
     "start_time": "2022-02-22T06:43:59.056250Z"
    }
   },
   "outputs": [],
   "source": [
    "# store all data in a dictionary\n",
    "all_data = {\"raw\":{\"train\":train,\"valid\":valid,\"test\":test},\n",
    " \"xgboost_data\":{\"train_x\":X_train,\"train_y\":train_cls_label,\\\n",
    "                 \"valid_x\":X_valid,\"valid_y\":valid_cls_label,\\\n",
    "                 \"test_x\":X_test,\"test_y\":test_cls_label},\n",
    " \"revenue\":{\"train\":train_reg_label,\"valid\":valid_reg_label,\"test\":test_reg_label}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:44:43.905428Z",
     "start_time": "2022-02-22T06:44:43.878264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking label distribution\n",
      "Training: 0.08246585722275343\n",
      "Validation: 0.0803219359369092\n",
      "Testing: 0.08230964879051897\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"Checking label distribution\")\n",
    "cnt = Counter(train_cls_label)\n",
    "print(\"Training:\",cnt[1]/cnt[0])\n",
    "cnt = Counter(valid_cls_label)\n",
    "print(\"Validation:\",cnt[1]/cnt[0])\n",
    "cnt = Counter(test_cls_label)\n",
    "print(\"Testing:\",cnt[1]/cnt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:44:58.693535Z",
     "start_time": "2022-02-22T06:44:58.530774Z"
    }
   },
   "outputs": [],
   "source": [
    "# pickle a variable to a file\n",
    "# reference for pickle: https://www.datacamp.com/community/tutorials/pickle-python-tutorial\n",
    "file = open('./processed_data.pickle', 'wb')\n",
    "pickle.dump(all_data, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. XGBoost model <a id='part2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:45:09.721481Z",
     "start_time": "2022-02-22T06:45:04.907154Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pickle\n",
    "import copy\n",
    "import os \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Load the preprocessed data in Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:45:18.824672Z",
     "start_time": "2022-02-22T06:45:18.724736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['raw', 'xgboost_data', 'revenue'])\n",
      "Finish loading data...\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed data\n",
    "with open(\"./processed_data.pickle\",\"rb\") as f :\n",
    "    processed_data = pickle.load(f)\n",
    "print(processed_data.keys())\n",
    "print(\"Finish loading data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train-, valid- and test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:45:33.977409Z",
     "start_time": "2022-02-22T06:45:33.972303Z"
    }
   },
   "outputs": [],
   "source": [
    "# train/test data \n",
    "train = processed_data[\"raw\"][\"train\"]\n",
    "valid = processed_data[\"raw\"][\"valid\"]\n",
    "test = processed_data[\"raw\"][\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split labels into train-, valid- and test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:46:08.752392Z",
     "start_time": "2022-02-22T06:46:08.740308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Revenue data for regression target \n",
    "revenue_train = processed_data[\"revenue\"][\"train\"]\n",
    "revenue_valid = processed_data[\"revenue\"][\"valid\"]\n",
    "revenue_test = processed_data[\"revenue\"][\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take logged values of revenue, and normalize them. --> getting more densed distribution/minimizing outliers' impacts.  \n",
    "As we assume no information on valid-data and test-data, they are normalized with the information of train-data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:46:53.425680Z",
     "start_time": "2022-02-22T06:46:53.401674Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize revenue by f(x) = log(x+1)/max(xi)\n",
    "norm_revenue_train = np.log(revenue_train+1)\n",
    "norm_revenue_valid = np.log(revenue_valid+1)\n",
    "norm_revenue_test = np.log(revenue_test+1) \n",
    "global_max = max(norm_revenue_train) \n",
    "norm_revenue_train = norm_revenue_train/global_max\n",
    "norm_revenue_valid = norm_revenue_valid/global_max\n",
    "norm_revenue_test = norm_revenue_test/global_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split xgboost data into train-, valid- and test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:46:58.438707Z",
     "start_time": "2022-02-22T06:46:58.431329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Xgboost data \n",
    "xgb_trainx = processed_data[\"xgboost_data\"][\"train_x\"]\n",
    "xgb_trainy = processed_data[\"xgboost_data\"][\"train_y\"]\n",
    "xgb_validx = processed_data[\"xgboost_data\"][\"valid_x\"]\n",
    "xgb_validy = processed_data[\"xgboost_data\"][\"valid_y\"]\n",
    "xgb_testx = processed_data[\"xgboost_data\"][\"test_x\"]\n",
    "xgb_testy = processed_data[\"xgboost_data\"][\"test_y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Define functions to be used\n",
    "### 2.3.1. \"find_best_threshod\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:57:01.835116Z",
     "start_time": "2022-02-22T06:57:01.817608Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_best_threshold(model,x_list,y_test,best_thresh = None):\n",
    "    '''\n",
    "    This function is to find the best threshold to determine \"to inspect\" or \"not\".\n",
    "    We assume that we inspect only the imports where predicted probability of fraud is above the threshold.\n",
    "    The input arguments are;\n",
    "    - dtype model: scikit-learn classifier model\n",
    "    - dtype x_list: list or array of features (data)\n",
    "    - dtype y_test: array of true labels \n",
    "    '''\n",
    "    # Predict probability of fraud of each import.\n",
    "    y_pred_prob = model.predict_proba(x_list)[:,1]\n",
    "    # Set threshold range as [0.1, 0.2, ..., 0.5]. \n",
    "    threshold_list = np.arange(0.1,0.7,0.1)\n",
    "    # Set an initial value of best threshold.\n",
    "    best_f1 = 0\n",
    "    # if best_thresh is set as \"None\", this function is to find the best_thresh as well as best_f1 \n",
    "    if best_thresh ==None:\n",
    "        for th in threshold_list:\n",
    "            y_pred_label = (y_pred_prob > th)*1 \n",
    "            f_score = f1_score(y_test,y_pred_label)\n",
    "            if f_score > best_f1:\n",
    "                best_f1 = f_score\n",
    "                best_thresh = th \n",
    "        return best_thresh, best_f1\n",
    "    # if best_thresh is set as a certain number, this function is to calculate its f1 score.\n",
    "    else:\n",
    "        y_pred_label = (y_pred_prob > best_thresh)*1 \n",
    "        best_f1 = f1_score(y_test,y_pred_label)\n",
    "    print(\"F1-scre equals to:%.4f\"%(best_f1))\n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Deploy a XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:48:26.820732Z",
     "start_time": "2022-02-22T06:48:25.217315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training xgboost model...\n",
      "[14:48:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training xgboost model...\")\n",
    "columns = column_to_use\n",
    "xgb_trainx = pd.DataFrame(xgb_trainx,columns=columns)\n",
    "xgb_validx = pd.DataFrame(xgb_validx,columns=columns)\n",
    "xgb_testx = pd.DataFrame(xgb_testx,columns=columns)\n",
    "# Initiate the model\n",
    "xgb_clf = XGBClassifier(n_estimators=100, max_depth=4,n_jobs=-1)\n",
    "# Train/fit the model\n",
    "xgb_clf.fit(xgb_trainx,xgb_trainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the first tree out of 100 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:48:33.061648Z",
     "start_time": "2022-02-22T06:48:32.777263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"2722pt\" height=\"392pt\"\r\n",
       " viewBox=\"0.00 0.00 2722.44 392.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 388)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-388 2718.44,-388 2718.44,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1383.44\" cy=\"-366\" rx=\"129.977\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1383.44\" y=\"-362.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">RiskH.office.id&amp;importer.id&lt;0.5</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"961.443\" cy=\"-279\" rx=\"103.982\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"961.443\" y=\"-275.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">RiskH.HS6&amp;country&lt;0.5</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M1312.81,-350.773C1236.35,-335.372 1114.88,-310.906 1036.67,-295.153\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"1036.9,-291.629 1026.41,-293.086 1035.52,-298.491 1036.9,-291.629\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1232.94\" y=\"-318.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1656.44\" cy=\"-279\" rx=\"113.98\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1656.44\" y=\"-275.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tariff.code&lt;8.51698483e+09</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M1433.83,-349.311C1480.1,-334.905 1548.68,-313.553 1597.48,-298.36\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1598.76,-301.626 1607.27,-295.312 1596.68,-294.943 1598.76,-301.626\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1543.94\" y=\"-318.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"516.443\" cy=\"-192\" rx=\"106.681\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"516.443\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">RiskH.office.id&amp;HS6&lt;0.5</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M894.341,-265.183C813.764,-249.792 678.88,-224.027 593.941,-207.803\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"594.572,-204.36 584.093,-205.922 593.258,-211.236 594.572,-204.36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"800.943\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"961.443\" cy=\"-192\" rx=\"113.98\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"961.443\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tariff.code&lt;8.70322176e+09</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>1&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M961.443,-260.799C961.443,-249.163 961.443,-233.548 961.443,-220.237\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"964.944,-220.175 961.443,-210.175 957.944,-220.175 964.944,-220.175\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"968.943\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>5</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1656.44\" cy=\"-192\" rx=\"88.2844\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1656.44\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gross.weight&lt;178808</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;5 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>2&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M1656.44,-260.799C1656.44,-249.163 1656.44,-233.548 1656.44,-220.237\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"1659.94,-220.175 1656.44,-210.175 1652.94,-220.175 1659.94,-220.175\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1690.94\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>6</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2187.44\" cy=\"-192\" rx=\"81.4863\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2187.44\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">RiskH.quantity&lt;0.5</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;6 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>2&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M1733.37,-265.686C1835.22,-249.383 2013.57,-220.833 2113.76,-204.795\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"2114.48,-208.225 2123.8,-203.188 2113.37,-201.313 2114.48,-208.225\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1961.94\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>7</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"242.443\" cy=\"-105\" rx=\"92.8835\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"242.443\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">RiskH.importer.id&lt;0.5</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;7 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M467.774,-175.902C420.63,-161.277 349.158,-139.105 299.394,-123.667\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"300.332,-120.294 289.744,-120.673 298.258,-126.979 300.332,-120.294\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"430.943\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>8</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"516.443\" cy=\"-105\" rx=\"92.8835\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"516.443\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">RiskH.importer.id&lt;0.5</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;8 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>3&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M516.443,-173.799C516.443,-162.163 516.443,-146.548 516.443,-133.237\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"519.944,-133.175 516.443,-123.175 512.944,-133.175 519.944,-133.175\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"523.943\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>9</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"909.443\" cy=\"-105\" rx=\"94.7833\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"909.443\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gross.weight&lt;192917.5</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;9 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>4&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M950.921,-173.799C943.59,-161.817 933.68,-145.617 925.384,-132.057\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"928.155,-129.879 919.951,-123.175 922.184,-133.532 928.155,-129.879\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"973.943\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>10</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1115.44\" cy=\"-105\" rx=\"92.8835\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1115.44\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">RiskH.importer.id&lt;0.5</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;10 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>4&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M991.136,-174.611C1015.61,-161.104 1050.49,-141.852 1077.08,-127.177\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1079.04,-130.091 1086.1,-122.194 1075.66,-123.962 1079.04,-130.091\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1055.94\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 15 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>15</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"73.4435\" cy=\"-18\" rx=\"73.387\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"73.4435\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.57347405</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;15 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>7&#45;&gt;15</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M208.896,-88.2013C196.46,-82.2696 182.266,-75.411 169.443,-69 150.44,-59.4987 129.497,-48.6372 112.034,-39.4702\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"113.205,-36.1311 102.725,-34.5711 109.945,-42.3256 113.205,-36.1311\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"203.943\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 16 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>16</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"242.443\" cy=\"-18\" rx=\"77.9862\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"242.443\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.376076579</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;16 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;16</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M242.443,-86.799C242.443,-75.1626 242.443,-59.5479 242.443,-46.2368\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"245.944,-46.1754 242.443,-36.1754 238.944,-46.1755 245.944,-46.1754\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"249.943\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 17 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>17</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"416.443\" cy=\"-18\" rx=\"77.9862\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"416.443\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.295238107</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;17 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>8&#45;&gt;17</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M496.687,-87.2067C481.523,-74.3175 460.414,-56.3753 443.653,-42.1281\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"445.705,-39.2789 435.819,-35.4692 441.172,-44.6125 445.705,-39.2789\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"506.943\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 18 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>18</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"587.443\" cy=\"-18\" rx=\"75.2868\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"587.443\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.252336472</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;18 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>8&#45;&gt;18</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M530.811,-86.799C541.176,-74.3902 555.32,-57.4575 566.88,-43.6185\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"569.615,-45.804 573.339,-35.8854 564.242,-41.3164 569.615,-45.804\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"563.943\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 19 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>19</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"751.443\" cy=\"-18\" rx=\"70.6878\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"751.443\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.51921463</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;19 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>9&#45;&gt;19</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M878.35,-87.93C867.02,-82.0288 854.127,-75.2603 842.443,-69 824.613,-59.4457 804.929,-48.66 788.442,-39.5584\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"790.089,-36.4695 779.644,-34.6937 786.701,-42.5955 790.089,-36.4695\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"876.943\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 20 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>20</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"922.443\" cy=\"-18\" rx=\"82.5854\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"922.443\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.0545454584</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;20 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>9&#45;&gt;20</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M912.074,-86.799C913.854,-75.1626 916.242,-59.5479 918.278,-46.2368\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"921.765,-46.5897 919.817,-36.1754 914.845,-45.5313 921.765,-46.5897\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"924.943\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 21 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>21</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1101.44\" cy=\"-18\" rx=\"77.9862\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1101.44\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.329692841</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;21 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>10&#45;&gt;21</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M1112.61,-86.799C1110.69,-75.1626 1108.12,-59.5479 1105.93,-46.2368\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"1109.35,-45.4737 1104.27,-36.1754 1102.44,-46.6113 1109.35,-45.4737\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1143.94\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 22 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>22</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1272.44\" cy=\"-18\" rx=\"75.2868\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1272.44\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.257142872</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;22 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>10&#45;&gt;22</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M1146.55,-87.96C1157.88,-82.0618 1170.78,-75.2876 1182.44,-69 1199.94,-59.573 1219.21,-48.9036 1235.42,-39.849\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1237.56,-42.6645 1244.57,-34.7259 1234.14,-36.5563 1237.56,-42.6645\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1217.94\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>11</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1610.44\" cy=\"-105\" rx=\"62.2891\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1610.44\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">quantity&lt;8227</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;11 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>5&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M1647.13,-173.799C1640.61,-161.738 1631.77,-145.403 1624.4,-131.79\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"1627.42,-130.014 1619.58,-122.885 1621.26,-133.346 1627.42,-130.014\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1670.94\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>12</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1786.44\" cy=\"-105\" rx=\"81.4863\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1786.44\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">RiskH.quantity&lt;0.5</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;12 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>5&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M1681.51,-174.611C1701.83,-161.323 1730.66,-142.476 1752.96,-127.896\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1755,-130.74 1761.46,-122.339 1751.17,-124.882 1755,-130.74\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1736.94\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node26\" class=\"node\"><title>13</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2187.44\" cy=\"-105\" rx=\"106.681\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2187.44\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">RiskH.office.id&amp;HS6&lt;0.5</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;13 -->\r\n",
       "<g id=\"edge25\" class=\"edge\"><title>6&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M2187.44,-173.799C2187.44,-162.163 2187.44,-146.548 2187.44,-133.237\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"2190.94,-133.175 2187.44,-123.175 2183.94,-133.175 2190.94,-133.175\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2221.94\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node27\" class=\"node\"><title>14</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2465.44\" cy=\"-105\" rx=\"94.7833\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2465.44\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gross.weight&lt;277220.5</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;14 -->\r\n",
       "<g id=\"edge26\" class=\"edge\"><title>6&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M2233.04,-177.059C2280.79,-162.458 2355.93,-139.486 2407.77,-123.634\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"2408.95,-126.933 2417.49,-120.662 2406.91,-120.238 2408.95,-126.933\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2350.94\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 23 -->\r\n",
       "<g id=\"node22\" class=\"node\"><title>23</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1441.44\" cy=\"-18\" rx=\"75.2868\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1441.44\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.557292402</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;23 -->\r\n",
       "<g id=\"edge21\" class=\"edge\"><title>11&#45;&gt;23</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M1579.07,-89.2382C1566.13,-83.078 1551.02,-75.7881 1537.44,-69 1518.58,-59.5697 1497.81,-48.7992 1480.43,-39.6757\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"1481.63,-36.3545 1471.15,-34.7955 1478.37,-42.5493 1481.63,-36.3545\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1571.94\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 24 -->\r\n",
       "<g id=\"node23\" class=\"node\"><title>24</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1610.44\" cy=\"-18\" rx=\"75.2868\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1610.44\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.171428591</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;24 -->\r\n",
       "<g id=\"edge22\" class=\"edge\"><title>11&#45;&gt;24</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M1610.44,-86.799C1610.44,-75.1626 1610.44,-59.5479 1610.44,-46.2368\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1613.94,-46.1754 1610.44,-36.1754 1606.94,-46.1755 1613.94,-46.1754\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1617.94\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 25 -->\r\n",
       "<g id=\"node24\" class=\"node\"><title>25</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1786.44\" cy=\"-18\" rx=\"82.5854\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1786.44\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.0206896551</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;25 -->\r\n",
       "<g id=\"edge23\" class=\"edge\"><title>12&#45;&gt;25</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M1786.44,-86.799C1786.44,-75.1626 1786.44,-59.5479 1786.44,-46.2368\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"1789.94,-46.1754 1786.44,-36.1754 1782.94,-46.1755 1789.94,-46.1754\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1820.94\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 26 -->\r\n",
       "<g id=\"node25\" class=\"node\"><title>26</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1962.44\" cy=\"-18\" rx=\"75.2868\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1962.44\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.461538494</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;26 -->\r\n",
       "<g id=\"edge24\" class=\"edge\"><title>12&#45;&gt;26</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M1819.17,-88.3532C1831.76,-82.3187 1846.28,-75.3514 1859.44,-69 1879.97,-59.099 1902.76,-48.0395 1921.68,-38.8443\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1923.44,-41.8783 1930.91,-34.3579 1920.38,-35.583 1923.44,-41.8783\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1895.94\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 27 -->\r\n",
       "<g id=\"node28\" class=\"node\"><title>27</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2129.44\" cy=\"-18\" rx=\"73.387\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2129.44\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.12778905</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;27 -->\r\n",
       "<g id=\"edge27\" class=\"edge\"><title>13&#45;&gt;27</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M2175.71,-86.799C2167.4,-74.6221 2156.12,-58.0889 2146.77,-44.3977\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"2149.49,-42.1728 2140.97,-35.8854 2143.71,-46.1183 2149.49,-42.1728\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2196.94\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 28 -->\r\n",
       "<g id=\"node29\" class=\"node\"><title>28</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2296.44\" cy=\"-18\" rx=\"75.2868\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2296.44\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.559090912</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;28 -->\r\n",
       "<g id=\"edge28\" class=\"edge\"><title>13&#45;&gt;28</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M2211.08,-87.1726C2218.9,-81.4935 2227.61,-75.0573 2235.44,-69 2246.55,-60.4065 2258.56,-50.6719 2268.95,-42.0905\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"2271.43,-44.5786 2276.89,-35.4993 2266.96,-39.1916 2271.43,-44.5786\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2261.94\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "<!-- 29 -->\r\n",
       "<g id=\"node30\" class=\"node\"><title>29</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2465.44\" cy=\"-18\" rx=\"75.2868\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2465.44\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.480000019</text>\r\n",
       "</g>\r\n",
       "<!-- 14&#45;&gt;29 -->\r\n",
       "<g id=\"edge29\" class=\"edge\"><title>14&#45;&gt;29</title>\r\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M2465.44,-86.799C2465.44,-75.1626 2465.44,-59.5479 2465.44,-46.2368\"/>\r\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"2468.94,-46.1754 2465.44,-36.1754 2461.94,-46.1755 2468.94,-46.1754\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2499.94\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\r\n",
       "</g>\r\n",
       "<!-- 30 -->\r\n",
       "<g id=\"node31\" class=\"node\"><title>30</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2636.44\" cy=\"-18\" rx=\"77.9862\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2636.44\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.150000006</text>\r\n",
       "</g>\r\n",
       "<!-- 14&#45;&gt;30 -->\r\n",
       "<g id=\"edge30\" class=\"edge\"><title>14&#45;&gt;30</title>\r\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M2498.96,-88.1428C2511.39,-82.2047 2525.59,-75.3571 2538.44,-69 2557.83,-59.4073 2579.25,-48.516 2597.1,-39.3527\"/>\r\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"2598.79,-42.42 2606.08,-34.7345 2595.59,-36.1947 2598.79,-42.42\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2575.94\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x206a9ac3e50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb.to_graphviz(booster = xgb_clf, num_trees=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:57:07.131622Z",
     "start_time": "2022-02-22T06:57:07.063590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluating xgboost model------\n",
      "F1-scre equals to:0.1659\n",
      "AUC = 0.7268, F1-score = 0.1659\n"
     ]
    }
   ],
   "source": [
    "# evaluate xgboost model\n",
    "print(\"------Evaluating xgboost model------\")\n",
    "# Predict\n",
    "test_pred = xgb_clf.predict_proba(xgb_testx)[:,1]\n",
    "# Calculate auc\n",
    "xgb_auc = roc_auc_score(xgb_testy, test_pred)\n",
    "# Find the best threshold\n",
    "xgb_threshold,_ = find_best_threshold(xgb_clf, xgb_validx, xgb_validy)\n",
    "# Calculate the best f1 score\n",
    "xgb_f1 = find_best_threshold(xgb_clf, xgb_testx, xgb_testy,best_thresh=xgb_threshold)\n",
    "print(\"AUC = %.4f, F1-score = %.4f\" % (xgb_auc, xgb_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:57:18.488598Z",
     "start_time": "2022-02-22T06:57:18.476595Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. DATE model (XGB + Neural Networks + Attention) <a id='part3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Set environmenst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:57:59.728454Z",
     "start_time": "2022-02-22T06:57:59.722453Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import time \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T06:58:03.148441Z",
     "start_time": "2022-02-22T06:58:03.143346Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:05:07.752816Z",
     "start_time": "2022-02-22T07:05:07.729810Z"
    }
   },
   "outputs": [],
   "source": [
    "from ranger import Ranger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Preprocessing data: Integer-encoding of IMPORTER.TIN and TARIFF.CODE for attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:05:13.334480Z",
     "start_time": "2022-02-22T07:05:13.324869Z"
    }
   },
   "outputs": [],
   "source": [
    "# user & item information \n",
    "train_raw_importers = train['importer.id'].values\n",
    "train_raw_items = train['tariff.code'].values\n",
    "valid_raw_importers = valid['importer.id'].values\n",
    "valid_raw_items = valid['tariff.code'].values\n",
    "test_raw_importers = test['importer.id']\n",
    "test_raw_items = test['tariff.code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:05:15.239019Z",
     "start_time": "2022-02-22T07:05:15.225630Z"
    }
   },
   "outputs": [],
   "source": [
    "#只用训练集数据\n",
    "# we need padding for unseen user or item \n",
    "importer_set = set(train_raw_importers)\n",
    "item_set = set(train_raw_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:05:19.827610Z",
     "start_time": "2022-02-22T07:05:19.794485Z"
    }
   },
   "outputs": [],
   "source": [
    "#用train里拥有的importer来做一个字典\n",
    "# Remember to +1 for zero padding \n",
    "importer_mapping = {v:i+1 for i,v in enumerate(importer_set)} \n",
    "hs6_mapping = {v:i+1 for i,v in enumerate(item_set)}\n",
    "importer_size = len(importer_mapping) + 1\n",
    "item_size = len(hs6_mapping) + 1\n",
    "# label-encoding\n",
    "train_importers = [importer_mapping[x] for x in train_raw_importers]\n",
    "train_items = [hs6_mapping[x] for x in train_raw_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:05:26.417377Z",
     "start_time": "2022-02-22T07:05:26.391372Z"
    }
   },
   "outputs": [],
   "source": [
    "#有时候会出现tran的字典里没有test和和vaild的情况，这个时候补0\n",
    "# for test data, we use padding_idx=0 for unseen data\n",
    "# use dic.get(key,deafault) to handle unseen\n",
    "valid_importers = [importer_mapping.get(x,0) for x in valid_raw_importers]\n",
    "valid_items = [hs6_mapping.get(x,0) for x in valid_raw_items]\n",
    "test_importers = [importer_mapping.get(x,0) for x in test_raw_importers] \n",
    "test_items = [hs6_mapping.get(x,0) for x in test_raw_items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. \"process_leaf_idx\" function [(link to practice)](#practice5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:30:28.292957Z",
     "start_time": "2022-02-22T07:30:28.284955Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_leaf_idx(X_leaves): \n",
    "    '''\n",
    "    This function is to convert the output of XGBoost model to the input of DATE model.\n",
    "    For an individual import, the output of XGBoost model is a list of leaf index of multiple trees.\n",
    "    eg. [1, 1, 10, 9, 30, 30, 32, ... ]\n",
    "    How to distinguish \"node 1\" of the first tree from \"node 1\" of the second tree?\n",
    "    How to distinguish \"node 30\" of the fifth tree from \"node 30\" of the sixth tree?\n",
    "    This function is to assign unique index to every leaf node in all the trees. \n",
    "    This function returns;\n",
    "    - lists of unique leaf index;\n",
    "    - total number of unique leaf nodes; and\n",
    "    - a reference table (dictionary) composed of \"unique leaf index\", \"tree id\", \"(previous) leaf index\". \n",
    "    '''\n",
    "    leaves = X_leaves.copy()\n",
    "    new_leaf_index = dict() # dictionary to store leaf index\n",
    "    total_leaves = 0\n",
    "    for c in range(X_leaves.shape[1]): # iterate for each column (ie. 100 trees)\n",
    "        column = X_leaves[:,c]\n",
    "        unique_vals = list(sorted(set(column)))\n",
    "        new_idx = {v:(i+total_leaves) for i,v in enumerate(unique_vals)}\n",
    "        for i,v in enumerate(unique_vals):\n",
    "            leaf_id = i+total_leaves\n",
    "            new_leaf_index[leaf_id] = {c:v}\n",
    "        leaves[:,c] = [new_idx[v] for v in column]\n",
    "        total_leaves += len(unique_vals)\n",
    "        \n",
    "    assert leaves.ravel().max() == total_leaves - 1\n",
    "    return leaves,total_leaves,new_leaf_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. \"fgsm_attack\" function (Not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T08:19:04.663376Z",
     "start_time": "2022-02-22T08:19:04.651742Z"
    }
   },
   "outputs": [],
   "source": [
    "def fgsm_attack(model, loss, images, labels, eps) :\n",
    "    # images.requires_grad = True\n",
    "    images = Variable(images, requires_grad=True)\n",
    "    outputs = model.module.pred_from_hidden(images)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    cost = loss(outputs, labels)\n",
    "    cost.backward()\n",
    "    attack_images = images + eps * images.grad.sign()\n",
    "    return attack_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. \"metrics\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:33:56.050193Z",
     "start_time": "2022-02-22T07:33:56.035663Z"
    }
   },
   "outputs": [],
   "source": [
    "def metrics(y_prob,xgb_testy,revenue_test,best_thresh=None):\n",
    "    if best_thresh ==None:\n",
    "        _,overall_f1,auc = torch_threshold(y_prob,xgb_testy,best_thresh)\n",
    "    else:\n",
    "        overall_f1,auc = torch_threshold(y_prob,xgb_testy,best_thresh)\n",
    "    \n",
    "    pr, re, f, rev = [], [], [], []\n",
    "    for i in [99,98,95,90]:\n",
    "        threshold = np.percentile(y_prob, i)\n",
    "        #print(f'Checking top {100-i}% suspicious transactions: {len(y_prob[y_prob > threshold])}')\n",
    "        precision = np.mean(xgb_testy[y_prob > threshold])\n",
    "        recall = sum(xgb_testy[y_prob > threshold])/sum(xgb_testy)\n",
    "        f1 = 2*precision*recall/(precision+recall)\n",
    "        revenue_recall = sum(revenue_test[y_prob > threshold]) /sum(revenue_test)\n",
    "\n",
    "        # save results\n",
    "        pr.append(precision)\n",
    "        re.append(recall)\n",
    "        f.append(f1)\n",
    "        rev.append(revenue_recall)\n",
    "        # print(f'Precision: {round(precision, 4)}, Recall: {round(recall, 4)}, Seized Revenue (Recall): {round(revenue_recall, 4)}')\n",
    "    return overall_f1,auc,pr, re, f, rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4. \"torch_threshold\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:34:07.779009Z",
     "start_time": "2022-02-22T07:34:07.767540Z"
    }
   },
   "outputs": [],
   "source": [
    "def torch_threshold(y_pred_prob,y_test,best_thresh = None):\n",
    "    '''\n",
    "    This function is to find the best threshold to determine \"to inspect\" or \"not\".\n",
    "    We assume that we inspect only the imports where predicted probability of fraud is above the threshold.\n",
    "    '''\n",
    "    threshold_list = np.arange(0.1,0.6,0.1)\n",
    "    best_f1 = 0\n",
    "    if best_thresh == None:\n",
    "        for th in threshold_list:\n",
    "            y_pred_label = (y_pred_prob > th)*1 \n",
    "            f_score = f1_score(y_test,y_pred_label)\n",
    "            if f_score > best_f1:\n",
    "                best_f1 = f_score\n",
    "                best_thresh = th \n",
    "        return best_thresh, best_f1, roc_auc_score(y_test, y_pred_prob)\n",
    "    else:\n",
    "        y_pred_label = (y_pred_prob > best_thresh)*1 \n",
    "        best_f1 = f1_score(y_test,y_pred_label)\n",
    "        return best_f1, roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Identify leaf nodes of individual import from XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:40:48.045960Z",
     "start_time": "2022-02-22T07:40:47.922933Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "\n",
    "# get leaf index from xgboost model \n",
    "X_train_leaves = xgb_clf.apply(xgb_trainx) #apply: Return the predicted leaf every tree for each sample.\n",
    "X_valid_leaves = xgb_clf.apply(xgb_validx)\n",
    "X_test_leaves = xgb_clf.apply(xgb_testx)\n",
    "train_rows = X_train_leaves.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:41:49.990944Z",
     "start_time": "2022-02-22T07:41:47.295125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "train_rows = train.shape[0]\n",
    "valid_rows = valid.shape[0] + train_rows\n",
    "X_leaves = np.concatenate((X_train_leaves, X_valid_leaves, X_test_leaves), axis=0) # make sure the dimensionality\n",
    "transformed_leaves, leaf_num, new_leaf_index = process_leaf_idx(X_leaves)\n",
    "train_leaves, valid_leaves, test_leaves = transformed_leaves[:train_rows],\\\n",
    "                                          transformed_leaves[train_rows:valid_rows],\\\n",
    "                                          transformed_leaves[valid_rows:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T10:13:48.833235Z",
     "start_time": "2022-02-22T10:13:48.828232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1380"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Convert data to tensor\n",
    "Tensor is a collection of numbers with specific shape (dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:53:57.893618Z",
     "start_time": "2022-02-22T07:53:57.828423Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to torch type\n",
    "train_leaves = torch.tensor(train_leaves).long()\n",
    "train_user = torch.tensor(train_importers).long()\n",
    "train_item = torch.tensor(train_items).long()\n",
    "\n",
    "valid_leaves = torch.tensor(valid_leaves).long()\n",
    "valid_user = torch.tensor(valid_importers).long()\n",
    "valid_item = torch.tensor(valid_items).long()\n",
    "\n",
    "test_leaves = torch.tensor(test_leaves).long()\n",
    "test_user = torch.tensor(test_importers).long()\n",
    "test_item = torch.tensor(test_items).long()\n",
    "\n",
    "# cls data\n",
    "train_label_cls = torch.tensor(xgb_trainy).float()\n",
    "valid_label_cls = torch.tensor(xgb_validy).float()\n",
    "test_label_cls = torch.tensor(xgb_testy).float()\n",
    "\n",
    "# revenue data \n",
    "train_label_reg = torch.tensor(norm_revenue_train).float()\n",
    "valid_label_reg = torch.tensor(revenue_valid).float()\n",
    "test_label_reg = torch.tensor(revenue_test).float()\n",
    "\n",
    "# create dataloader \n",
    "\n",
    "train_dataset = Data.TensorDataset(train_leaves,train_user,train_item,train_label_cls,train_label_reg)\n",
    "valid_dataset = Data.TensorDataset(valid_leaves,valid_user,valid_item,valid_label_cls,valid_label_reg)\n",
    "test_dataset = Data.TensorDataset(test_leaves,test_user,test_item,test_label_cls,test_label_reg)\n",
    "\n",
    "\n",
    "\n",
    "data4embedding = {\"train_dataset\":train_dataset,\"valid_dataset\":valid_dataset,\"test_dataset\":test_dataset,\\\n",
    "                  \"leaf_num\":leaf_num,\"importer_num\":importer_size,\"item_size\":item_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Save and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:54:35.584563Z",
     "start_time": "2022-02-22T07:54:35.477442Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"torch_data.pickle\", 'wb') as f:\n",
    "    pickle.dump(data4embedding, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(\"leaf_index.pickle\", \"wb\") as f:\n",
    "    pickle.dump(new_leaf_index, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:55:01.548332Z",
     "start_time": "2022-02-22T07:55:01.544332Z"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:55:03.544926Z",
     "start_time": "2022-02-22T07:55:03.465909Z"
    }
   },
   "outputs": [],
   "source": [
    "# load torch dataset \n",
    "with open(\"torch_data.pickle\",\"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:55:05.157388Z",
     "start_time": "2022-02-22T07:55:05.150384Z"
    }
   },
   "outputs": [],
   "source": [
    "# get torch dataset \n",
    "train_dataset = data[\"train_dataset\"]\n",
    "valid_dataset = data[\"valid_dataset\"]\n",
    "test_dataset = data[\"test_dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T08:23:45.772840Z",
     "start_time": "2022-02-22T08:23:45.762838Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "batch_size = 256\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,     \n",
    "    batch_size=batch_size,      \n",
    "    shuffle=True,               \n",
    ")\n",
    "valid_loader = Data.DataLoader(\n",
    "    dataset=valid_dataset,     \n",
    "    batch_size=batch_size,      \n",
    "    shuffle=False,               \n",
    ")\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=test_dataset,     \n",
    "    batch_size=batch_size,      \n",
    "    shuffle=False,               \n",
    ")\n",
    "\n",
    "# parameters for model \n",
    "leaf_num = data[\"leaf_num\"]\n",
    "importer_size = data[\"importer_num\"]\n",
    "item_size = data[\"item_size\"]\n",
    "\n",
    "# global variables\n",
    "xgb_validy = valid_loader.dataset.tensors[-2].detach().numpy()\n",
    "xgb_testy = test_loader.dataset.tensors[-2].detach().numpy()\n",
    "revenue_valid = valid_loader.dataset.tensors[-1].detach().numpy()\n",
    "revenue_test = test_loader.dataset.tensors[-1].detach().numpy()\n",
    "\n",
    "# model information\n",
    "curr_time = str(time.time())\n",
    "model_name = \"DATE\"\n",
    "model_path = \".%s%s.pkl\" % (model_name,curr_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7. Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:59:46.184226Z",
     "start_time": "2022-02-22T07:59:46.179225Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link to practice Mish()](#practice6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link to practice FusionAttention()](#practice7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:57:26.141159Z",
     "start_time": "2022-02-22T07:57:26.125145Z"
    }
   },
   "outputs": [],
   "source": [
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mish,self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x *( torch.tanh(F.softplus(x))) #softplus???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:57:48.490299Z",
     "start_time": "2022-02-22T07:57:48.477297Z"
    }
   },
   "outputs": [],
   "source": [
    "class FusionAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim):\n",
    "        super(FusionAttention, self).__init__()\n",
    "        self.attention_matrix = nn.Linear(dim, dim) # nn.Linear(size of input, size of output)\n",
    "        self.project_weight = nn.Linear(dim,1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        query_project = self.attention_matrix(inputs) # (b,t,d) -> (b,t,d2)\n",
    "        query_project = F.leaky_relu(query_project)\n",
    "        project_value = self.project_weight(query_project) # (b,t,h) -> (b,t,1)\n",
    "        attention_weight = torch.softmax(project_value, dim=1) # Normalize and calculate weights (b,t,1)\n",
    "        attention_vec = inputs * attention_weight\n",
    "        attention_vec = torch.sum(attention_vec,dim=1)\n",
    "        return attention_vec, attention_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link to practice Attention()](#practice8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:58:14.896693Z",
     "start_time": "2022-02-22T07:58:14.881166Z"
    }
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim,hidden,aggregate=\"sum\"):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention_matrix = nn.Linear(dim, hidden)\n",
    "        self.project_weight = nn.Linear(hidden*2,hidden)\n",
    "        self.h = nn.Parameter(torch.rand(hidden,1))\n",
    "        self.agg_type = aggregate\n",
    "        \n",
    "    def forward(self, query, key): # query: 256 X 16, # key: 256 X 100 X 16, # assume key==value\n",
    "        dim = query.size(-1) # 16 (n_embedding_dimension)\n",
    "        batch = key.size(0) # 256 (batch_size = n_observation in a batch)\n",
    "        time_step = key.size(1) # 100 (n_trees from xgboot model)\n",
    "        \n",
    "        # concate input query and key \n",
    "        query = query.view(batch,1,dim) # view = reshape: (256X16) -> (256X1X16)\n",
    "        query = query.expand(batch,time_step,-1) # expand to the same dimension: (256X1X16) -> (256X100X16)\n",
    "        cat_vector = torch.cat((query,key),dim=-1) # (256X100X32)\n",
    "        \n",
    "        # project to single value\n",
    "        project_vector = self.project_weight(cat_vector) \n",
    "        project_vector = torch.relu(project_vector)\n",
    "        attention_alpha = torch.matmul(project_vector,self.h)\n",
    "        attention_weight = torch.softmax(attention_alpha, dim=1) # Normalize and calculate weights (b,t,1)\n",
    "        attention_vec = key * attention_weight\n",
    "        \n",
    "        # aggregate leaves\n",
    "        if self.agg_type == \"max\":\n",
    "            attention_vec,_ = torch.max(attention_vec,dim=1)\n",
    "        elif self.agg_type ==\"mean\":\n",
    "            attention_vec = torch.mean(attention_vec,dim=1)\n",
    "        elif self.agg_type ==\"sum\":\n",
    "            attention_vec = torch.sum(attention_vec,dim=1)\n",
    "        return attention_vec, attention_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link to practice DATE()](#practice9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T08:18:14.028096Z",
     "start_time": "2022-02-22T08:18:14.003088Z"
    }
   },
   "outputs": [],
   "source": [
    "class DATE(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 max_leaf,importer_size,item_size,dim,\n",
    "                 head_num=4,fusion_type=\"concat\",act=\"relu\",device=\"cpu\",use_self=True,agg_type=\"sum\"):\n",
    "        super(DATE, self).__init__()\n",
    "        self.d = dim\n",
    "        self.device = device\n",
    "        if act == \"relu\":\n",
    "            self.act = nn.LeakyReLU()\n",
    "        elif act == \"mish\":\n",
    "            self.act = Mish() \n",
    "        self.fusion_type = fusion_type\n",
    "        self.use_self = use_self\n",
    "\n",
    "        # embedding layers \n",
    "        self.leaf_embedding = nn.Embedding(max_leaf,dim)\n",
    "        self.user_embedding = nn.Embedding(importer_size,dim,padding_idx=0)\n",
    "        self.user_embedding.weight.data[0] = torch.zeros(dim) # unseen data? initial value?\n",
    "        self.item_embedding = nn.Embedding(item_size,dim,padding_idx=0)\n",
    "        self.item_embedding.weight.data[0] = torch.zeros(dim)\n",
    "\n",
    "        # attention layer\n",
    "        self.attention_bolck = Attention(dim,dim,agg_type).to(device)\n",
    "        self.self_att = nn.MultiheadAttention(dim,head_num).to(device)\n",
    "        self.fusion_att = FusionAttention(dim)\n",
    "\n",
    "        # Hidden & output layer\n",
    "        self.layer_norm = nn.LayerNorm((100,dim))\n",
    "        self.fussionlayer = nn.Linear(dim*3,dim)\n",
    "        self.hidden = nn.Linear(dim,dim)\n",
    "        self.output_cls_layer = nn.Linear(dim,1)\n",
    "        self.output_reg_layer = nn.Linear(dim,1)\n",
    "    \n",
    "    def forward(self,feature,uid,item_id):\n",
    "        \n",
    "        # Embedding of leaf_id\n",
    "        leaf_vectors = self.leaf_embedding(feature)\n",
    "        \n",
    "        # 1st attention: Multi-Head Self-Attention\n",
    "        # Calculate the weight(importance) of each leaf(cross-feature) based on the correlation with other leafs\n",
    "        if self.use_self:\n",
    "            # Apply multy head attention\n",
    "            leaf_vectors,_ = self.self_att(leaf_vectors,leaf_vectors,leaf_vectors)\n",
    "            # Normalization?\n",
    "            leaf_vectors = self.layer_norm(leaf_vectors)\n",
    "        \n",
    "        # Embedding of importer_id\n",
    "        importer_vector = self.user_embedding(uid)\n",
    "        # Embedding of item_id\n",
    "        item_vector = self.item_embedding(item_id)\n",
    "        # Multiply embeddings of importer_id and item_id\n",
    "        query_vector = importer_vector * item_vector\n",
    "        \n",
    "        # 2nd attention: Attention with leaf_id, importer_id and item_id (all embeddings)\n",
    "        set_vector, self.attention_w = self.attention_bolck(query_vector,leaf_vectors)\n",
    "        \n",
    "        # concat the user, item and tree vectors into a fusion attention\n",
    "        if self.fusion_type == \"concat\":\n",
    "            fusion = torch.cat((importer_vector, item_vector, set_vector), dim=-1) # attach as columns\n",
    "            fusion = self.act(self.fussionlayer(fusion))\n",
    "        elif self.fusion_type == \"attention\":\n",
    "            importer_vector=importer_vector.view(-1,1,self.d), \n",
    "            item_vector=item_vector.view(-1,1,self.d), \n",
    "            set_vector=set_vector.view(-1,1,self.d)\n",
    "            fusion = torch.cat((importer_vector, item_vector, set_vector), dim=1) # attach as columns\n",
    "            fusion,_ = self.fusion_att(fusion)\n",
    "        else:\n",
    "            raise \"Fusion type error\"\n",
    "        hidden = self.hidden(fusion)\n",
    "        hidden = self.act(hidden)\n",
    "\n",
    "        # multi-task output \n",
    "        classification_output = torch.sigmoid(self.output_cls_layer(hidden))\n",
    "        regression_output = torch.relu(self.output_reg_layer(hidden))\n",
    "        return classification_output, regression_output, hidden\n",
    "\n",
    "    def pred_from_hidden(self,hidden):\n",
    "        classification_output = torch.sigmoid(self.output_cls_layer(hidden))\n",
    "        return classification_output \n",
    "\n",
    "    def eval_on_batch(self,test_loader): # predict test data using batch \n",
    "        final_output = []\n",
    "        cls_loss = []\n",
    "        reg_loss = []\n",
    "        for batch in test_loader:\n",
    "            batch_feature, batch_user, batch_item, batch_cls, batch_reg = batch\n",
    "            batch_feature,batch_user,batch_item,batch_cls,batch_reg =  \\\n",
    "            batch_feature.to(self.device), batch_user.to(self.device),\\\n",
    "            batch_item.to(self.device), batch_cls.to(self.device), batch_reg.to(self.device)\n",
    "            batch_cls,batch_reg = batch_cls.view(-1,1), batch_reg.view(-1,1)\n",
    "            y_pred_prob, y_pred_rev,_ = self.forward(batch_feature,batch_user,batch_item)\n",
    "\n",
    "            # compute classification loss\n",
    "            cls_losses = nn.BCELoss()(y_pred_prob,batch_cls)\n",
    "            cls_loss.append(cls_losses.item())\n",
    "\n",
    "            # compute regression loss \n",
    "            reg_losses = nn.MSELoss()(y_pred_rev, batch_reg)\n",
    "            reg_loss.append(reg_losses.item())\n",
    "\n",
    "            # store predicted probability \n",
    "            y_pred = y_pred_prob.detach().cpu().numpy().tolist()\n",
    "            final_output.extend(y_pred)\n",
    "\n",
    "        print(\"CLS loss: %.4f, REG loss: %.4f\"% (np.mean(cls_loss), np.mean(reg_loss)) )\n",
    "        return np.array(final_output).ravel(), np.mean(cls_loss)+ np.mean(reg_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8. Train (hyperparameter + loss function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.1. Set hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T08:18:18.613486Z",
     "start_time": "2022-02-22T08:18:18.598837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--save'], dest='save', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help='save model or not', metavar=None)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse argument\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_name', \n",
    "                        type=str, \n",
    "                        default=\"DATE\", \n",
    "                        help=\"Name of model\",\n",
    "                        )\n",
    "parser.add_argument('--epoch', \n",
    "                        type=int, \n",
    "                        default=5, \n",
    "                        help=\"Number of epochs\",\n",
    "                        )\n",
    "parser.add_argument('--dim', \n",
    "                        type=int, \n",
    "                        default=16, \n",
    "                        help=\"Hidden layer dimension\",\n",
    "                        )\n",
    "parser.add_argument('--lr', \n",
    "                        type=float, \n",
    "                        default=0.005, \n",
    "                        help=\"learning rate\",\n",
    "                        )\n",
    "parser.add_argument('--l2',\n",
    "                        type=float,\n",
    "                        default=0.00,\n",
    "                        help=\"l2 reg\",\n",
    "                        )\n",
    "parser.add_argument('--alpha',\n",
    "                        type=float,\n",
    "                        default=10,\n",
    "                        help=\"Regression loss weight\",\n",
    "                        )\n",
    "parser.add_argument('--beta', type=float, default=0.00, help=\"Adversarial loss weight\")\n",
    "parser.add_argument('--head_num', type=int, default=4, help=\"Number of heads for self attention\")\n",
    "parser.add_argument('--use_self', type=int, default=1, help=\"Wheter to use self attention\")\n",
    "parser.add_argument('--fusion', type=str, choices=[\"concat\",\"attention\"], default=\"concat\", help=\"Fusion method for final embedding\")\n",
    "parser.add_argument('--agg', type=str, choices=[\"sum\",\"max\",\"mean\"], default=\"sum\", help=\"Aggreate type for leaf embedding\")\n",
    "parser.add_argument('--act', type=str, choices=[\"mish\",\"relu\"], default=\"relu\", help=\"Activation function\")\n",
    "parser.add_argument('--device', type=str, choices=[\"cuda:0\",\"cuda:1\",\"cpu\"], default=\"cpu\", help=\"device name for training\")\n",
    "parser.add_argument('--output', type=str, default=\"full.csv\", help=\"Name of output file\")\n",
    "parser.add_argument('--save', type=int, default=0, help=\"save model or not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T08:00:01.769891Z",
     "start_time": "2022-02-22T08:00:01.759464Z"
    }
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args([])\n",
    "# Refer to: https://stackoverflow.com/questions/50763033/argparse-in-jupyter-notebook-throws-a-typeerror"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T10:43:16.484872Z",
     "start_time": "2022-02-22T10:43:16.453239Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    # get configs\n",
    "    epochs = 20 #args.epoch\n",
    "    dim = args.dim\n",
    "    lr = args.lr\n",
    "    weight_decay = args.l2\n",
    "    head_num = args.head_num\n",
    "    device = 'cpu'  #'cpu' if you run this code on cpu    #args.device\n",
    "    act = args.act\n",
    "    fusion = args.fusion\n",
    "    beta = args.beta\n",
    "    alpha = args.alpha\n",
    "    use_self = args.use_self\n",
    "    agg = args.agg\n",
    "    model = DATE(leaf_num,importer_size,item_size,\\\n",
    "                                    dim,head_num,\\\n",
    "                                    fusion_type=fusion,act=act,device=device,\\\n",
    "                                    use_self=use_self,agg_type=agg,\n",
    "                                    ).to(device)\n",
    "    model = nn.DataParallel(model,device_ids=[0,1])\n",
    "\n",
    "    # initialize parameters\n",
    "    # Fills the input Tensor with values according to the method described in \n",
    "    # Understanding the difficulty of training deep feedforward neural networks - Glorot, X. & Bengio, Y. (2010), \n",
    "    # using a uniform distribution.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "\n",
    "    # optimizer & loss \n",
    "    optimizer = Ranger(model.parameters(), weight_decay=weight_decay,lr=lr)\n",
    "    cls_loss_func = nn.BCELoss()\n",
    "    reg_loss_func = nn.MSELoss()\n",
    "\n",
    "    # save best model\n",
    "    global_best_score = 0\n",
    "    model_state = None\n",
    "\n",
    "    # early stop settings \n",
    "    stop_rounds = 3\n",
    "    no_improvement = 0\n",
    "    current_score = None \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for step, (batch_feature,batch_user,batch_item,batch_cls,batch_reg) in enumerate(train_loader):\n",
    "            model.train() # prep to train model\n",
    "            batch_feature,batch_user,batch_item,batch_cls,batch_reg =  \\\n",
    "            batch_feature.to(device), batch_user.to(device), batch_item.to(device),\\\n",
    "             batch_cls.to(device), batch_reg.to(device)\n",
    "            batch_cls,batch_reg = batch_cls.view(-1,1), batch_reg.view(-1,1)\n",
    "\n",
    "            # model output\n",
    "            classification_output, regression_output, hidden_vector = model(batch_feature,batch_user,batch_item)\n",
    "\n",
    "            # FGSM attack\n",
    "            adv_vector = fgsm_attack(model,cls_loss_func,hidden_vector,batch_cls,0.01)\n",
    "            adv_output = model.module.pred_from_hidden(adv_vector) \n",
    "\n",
    "            # calculate loss\n",
    "            adv_loss_func = nn.BCELoss(weight=batch_cls) \n",
    "            adv_loss = beta * adv_loss_func(adv_output,batch_cls) \n",
    "            cls_loss = cls_loss_func(classification_output,batch_cls)\n",
    "            revenue_loss = alpha * reg_loss_func(regression_output, batch_reg)\n",
    "            loss = cls_loss + revenue_loss + adv_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (step+1) % 10 ==0:  \n",
    "                print(\"CLS loss:%.4f, REG loss:%.4f, ADV loss:%.4f, Loss:%.4f\"\\\n",
    "                %(cls_loss.item(),revenue_loss.item(),adv_loss.item(),loss.item()))\n",
    "                \n",
    "        # evaluate \n",
    "        model.eval()\n",
    "        print(\"Validate at epoch %s\"%(epoch+1))\n",
    "        y_prob, val_loss = model.module.eval_on_batch(valid_loader)\n",
    "        y_pred_tensor = torch.tensor(y_prob).float().to(device)\n",
    "        best_threshold, val_score, roc = torch_threshold(y_prob,xgb_validy)\n",
    "        overall_f1, auc, precisions, recalls, f1s, revenues = metrics(y_prob,xgb_validy,revenue_valid)\n",
    "        select_best = np.mean(f1s)\n",
    "        print(\"Over-all F1:%.4f, AUC:%.4f, F1-top:%.4f\" % (overall_f1, auc, select_best) )\n",
    "\n",
    "        print(\"Evaluate at epoch %s\"%(epoch+1))\n",
    "        y_prob, val_loss = model.module.eval_on_batch(test_loader)\n",
    "        y_pred_tensor = torch.tensor(y_prob).float().to(device)\n",
    "        overall_f1, auc, precisions, recalls, f1s, revenues = metrics(y_prob,xgb_testy,revenue_test,best_thresh=best_threshold)\n",
    "        print(\"Over-all F1:%.4f, AUC:%.4f, F1-top:%.4f\" %(overall_f1, auc, np.mean(f1s)) )\n",
    "\n",
    "        # save best model \n",
    "        if select_best > global_best_score:\n",
    "            global_best_score = select_best\n",
    "            torch.save(model,model_path)\n",
    "        \n",
    "         # early stopping \n",
    "        if current_score == None:\n",
    "            current_score = select_best\n",
    "            continue\n",
    "        if select_best < current_score:\n",
    "            current_score = select_best\n",
    "            no_improvement += 1\n",
    "        if no_improvement >= stop_rounds:\n",
    "            print(\"Early stopping...\")\n",
    "            break \n",
    "        if select_best > current_score:\n",
    "            no_improvement = 0\n",
    "            current_score = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T10:47:38.525132Z",
     "start_time": "2022-02-22T10:47:38.511028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(act='relu', agg='sum', alpha=10, beta=0.0, device='cuda:0', dim=16, epoch=5, fusion='concat', head_num=4, l2=0.0, lr=0.005, model_name='DATE', output='full.csv', save=0, use_self=1)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T10:45:35.234637Z",
     "start_time": "2022-02-22T10:43:17.215543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "CLS loss:0.6490, REG loss:0.4325, ADV loss:0.0000, Loss:1.0815\n",
      "CLS loss:0.6407, REG loss:0.2746, ADV loss:0.0000, Loss:0.9154\n",
      "CLS loss:0.6334, REG loss:0.3724, ADV loss:0.0000, Loss:1.0058\n",
      "CLS loss:0.6307, REG loss:0.5568, ADV loss:0.0000, Loss:1.1876\n",
      "CLS loss:0.6205, REG loss:0.5389, ADV loss:0.0000, Loss:1.1594\n",
      "CLS loss:0.5999, REG loss:0.4419, ADV loss:0.0000, Loss:1.0418\n",
      "CLS loss:0.5913, REG loss:0.5618, ADV loss:0.0000, Loss:1.1532\n",
      "CLS loss:0.5722, REG loss:0.4322, ADV loss:0.0000, Loss:1.0044\n",
      "CLS loss:0.5484, REG loss:0.4605, ADV loss:0.0000, Loss:1.0089\n",
      "CLS loss:0.5300, REG loss:0.4109, ADV loss:0.0000, Loss:0.9409\n",
      "CLS loss:0.5055, REG loss:0.3458, ADV loss:0.0000, Loss:0.8514\n",
      "CLS loss:0.4618, REG loss:0.2520, ADV loss:0.0000, Loss:0.7137\n",
      "CLS loss:0.4708, REG loss:0.4780, ADV loss:0.0000, Loss:0.9489\n",
      "CLS loss:0.4459, REG loss:0.4455, ADV loss:0.0000, Loss:0.8914\n",
      "CLS loss:0.3750, REG loss:0.2679, ADV loss:0.0000, Loss:0.6429\n",
      "CLS loss:0.3583, REG loss:0.2981, ADV loss:0.0000, Loss:0.6563\n",
      "CLS loss:0.3867, REG loss:0.5110, ADV loss:0.0000, Loss:0.8978\n",
      "CLS loss:0.3109, REG loss:0.3942, ADV loss:0.0000, Loss:0.7051\n",
      "CLS loss:0.3045, REG loss:0.4273, ADV loss:0.0000, Loss:0.7318\n",
      "CLS loss:0.2720, REG loss:0.4065, ADV loss:0.0000, Loss:0.6785\n",
      "CLS loss:0.2496, REG loss:0.4015, ADV loss:0.0000, Loss:0.6511\n",
      "CLS loss:0.2296, REG loss:0.3235, ADV loss:0.0000, Loss:0.5531\n",
      "CLS loss:0.2479, REG loss:0.3586, ADV loss:0.0000, Loss:0.6066\n",
      "Validate at epoch 1\n",
      "CLS loss: 0.2590, REG loss: 105244.0936\n",
      "Over-all F1:0.2734, AUC:0.8019, F1-top:0.1704\n",
      "Evaluate at epoch 1\n",
      "CLS loss: 0.2637, REG loss: 116765.7176\n",
      "Over-all F1:0.2725, AUC:0.7985, F1-top:0.1700\n",
      "CLS loss:0.1807, REG loss:0.2688, ADV loss:0.0000, Loss:0.4495\n",
      "CLS loss:0.2433, REG loss:0.3266, ADV loss:0.0000, Loss:0.5699\n",
      "CLS loss:0.2404, REG loss:0.3231, ADV loss:0.0000, Loss:0.5634\n",
      "CLS loss:0.3653, REG loss:0.5849, ADV loss:0.0000, Loss:0.9502\n",
      "CLS loss:0.3138, REG loss:0.4207, ADV loss:0.0000, Loss:0.7345\n",
      "CLS loss:0.2155, REG loss:0.3019, ADV loss:0.0000, Loss:0.5174\n",
      "CLS loss:0.2586, REG loss:0.3888, ADV loss:0.0000, Loss:0.6475\n",
      "CLS loss:0.2447, REG loss:0.3193, ADV loss:0.0000, Loss:0.5641\n",
      "CLS loss:0.2331, REG loss:0.2806, ADV loss:0.0000, Loss:0.5137\n",
      "CLS loss:0.1899, REG loss:0.2773, ADV loss:0.0000, Loss:0.4672\n",
      "CLS loss:0.2516, REG loss:0.3448, ADV loss:0.0000, Loss:0.5964\n",
      "CLS loss:0.2433, REG loss:0.3711, ADV loss:0.0000, Loss:0.6144\n",
      "CLS loss:0.3127, REG loss:0.4443, ADV loss:0.0000, Loss:0.7570\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-233-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-232-2d20fa507591>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;31m# model output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mclassification_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_user\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_item\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;31m# FGSM attack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DataParallel.forward\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-134-5cad262b7fd8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, feature, uid, item_id)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_self\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;31m# Apply multy head attention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mleaf_vectors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_att\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleaf_vectors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleaf_vectors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleaf_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[1;31m# Normalization?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mleaf_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleaf_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[0;32m   1001\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[0;32m   1002\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[0;32m   1004\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[0;32m   5099\u001b[0m     \u001b[1;31m# (deep breath) calculate attention and out projection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5100\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5101\u001b[1;33m     \u001b[0mattn_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_output_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_scaled_dot_product_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5102\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5103\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_proj_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_scaled_dot_product_attention\u001b[1;34m(q, k, v, attn_mask, dropout_p)\u001b[0m\n\u001b[0;32m   4849\u001b[0m         \u001b[0mattn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4850\u001b[0m     \u001b[1;31m# (B, Nt, Ns) x (B, Ns, E) -> (B, Nt, E)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4851\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4852\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T08:23:26.061182Z",
     "start_time": "2022-02-22T08:23:24.225Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4. Evaluation <a id='part4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T08:48:14.374460Z",
     "start_time": "2022-02-22T08:48:14.367453Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(save_model):\n",
    "    print()\n",
    "    print(\"--------Evaluating DATE model---------\")\n",
    "    # create best model\n",
    "    best_model = torch.load(model_path)\n",
    "    best_model.eval()\n",
    "\n",
    "    # get threshold\n",
    "    y_prob, val_loss = best_model.module.eval_on_batch(valid_loader)\n",
    "    best_threshold, val_score, roc = torch_threshold(y_prob,xgb_validy)\n",
    "\n",
    "    # predict test \n",
    "    y_prob, val_loss = best_model.module.eval_on_batch(test_loader)\n",
    "    overall_f1, auc, precisions, recalls, f1s, revenues = metrics(y_prob,xgb_testy,revenue_test,best_threshold)\n",
    "    best_score = f1s[0]\n",
    "    #os.system(\"rm %s\"%model_path)\n",
    "    if save_model:\n",
    "        scroed_name = \".%s_%.4f.pkl\" % (model_name,overall_f1)\n",
    "        torch.save(best_model,scroed_name)\n",
    "    \n",
    "    return overall_f1, auc, precisions, recalls, f1s, revenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T08:48:37.976555Z",
     "start_time": "2022-02-22T08:48:16.533453Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Evaluating DATE model---------\n",
      "CLS loss: 0.2175, REG loss: 105262.9703\n",
      "CLS loss: 0.2230, REG loss: 116785.5223\n"
     ]
    }
   ],
   "source": [
    "overall_f1, auc, precisions, recalls, f1s, revenues = evaluate(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T08:49:20.900014Z",
     "start_time": "2022-02-22T08:49:20.881173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving result... .full.csv\n",
      "\n",
      "Metrics:\n",
      "f1:0.3342 auc:0.8070\n",
      "Pr@1:0.2650 Pr@2:0.2950 Pr@5:0.2960 Pr@10:0.2745\n",
      "Re@1:0.0348 Re@2:0.0776 Re@5:0.1946 Re@10:0.3609\n",
      "Rev@1:0.0379 Rev@2:0.0819 Rev@5:0.2121 Rev@10:0.3847\n"
     ]
    }
   ],
   "source": [
    "# save result\n",
    "output_file =  \".full.csv\"\n",
    "print(\"Saving result...\",output_file)\n",
    "with open(output_file, 'a') as ff:\n",
    "    # print(args,file=ff)\n",
    "    print()\n",
    "    print(\"\"\"Metrics:\\nf1:%.4f auc:%.4f\\nPr@1:%.4f Pr@2:%.4f Pr@5:%.4f Pr@10:%.4f\\nRe@1:%.4f Re@2:%.4f Re@5:%.4f Re@10:%.4f\\nRev@1:%.4f Rev@2:%.4f Rev@5:%.4f Rev@10:%.4f\"\"\" \\\n",
    "          % (overall_f1, auc,\\\n",
    "             precisions[0],precisions[1],precisions[2],precisions[3],\\\n",
    "             recalls[0],recalls[1],recalls[2],recalls[3],\\\n",
    "             revenues[0],revenues[1],revenues[2],revenues[3]\n",
    "            ),\n",
    "        ) \n",
    "    output_metric = [16,overall_f1,auc] + precisions + recalls + revenues\n",
    "    output_metric = list(map(str,output_metric))\n",
    "    print(\" \".join(output_metric),file=ff)\n",
    "        \n",
    "    # print(\"Model:%s epoch:%d dim:%d lr:%f l2:%f beta:%f heads:%d fusion:%s activation:%s\"\n",
    "    #       % (model_name, epochs, dim, lr, weight_decay, beta, head_num,fusion,act),file=ff) \n",
    "    # print(\"\"\"Metrics:\\nf1:%.4f auc:%.4f\\nPr@1:%.4f Pr@2:%.4f Pr@5:%.4f Pr@10:%.4f\\nRe@1:%.4f Re@2:%.4f Re@5:%.4f Re@10:%.4f\\nRev@1:%.4f Rev@2:%.4f Rev@5:%.4f Rev@10:%.4f\"\"\"  \\\n",
    "    #       % (overall_f1, auc,\\\n",
    "    #          precisions[0],precisions[1],precisions[2],precisions[3],\\\n",
    "    #          recalls[0],recalls[1],recalls[2],recalls[3],\\\n",
    "    #          revenues[0],revenues[1],revenues[2],revenues[3]\n",
    "    #          ),\n",
    "    #          file=ff)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5. Practice of functions <a id='part5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge_attributes <a id='practice1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sgd.date</th>\n",
       "      <th>office.id</th>\n",
       "      <th>importer.id</th>\n",
       "      <th>declarant.id</th>\n",
       "      <th>tariff.code</th>\n",
       "      <th>country</th>\n",
       "      <th>cif.value</th>\n",
       "      <th>quantity</th>\n",
       "      <th>gross.weight</th>\n",
       "      <th>total.taxes</th>\n",
       "      <th>revenue</th>\n",
       "      <th>illicit</th>\n",
       "      <th>tariff.code&amp;country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85303</th>\n",
       "      <td>13-11-18</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>IMP648653</td>\n",
       "      <td>DEC5544</td>\n",
       "      <td>8703241128</td>\n",
       "      <td>CNTRY759</td>\n",
       "      <td>8335</td>\n",
       "      <td>4</td>\n",
       "      <td>14344</td>\n",
       "      <td>4188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8703241128CNTRY759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83064</th>\n",
       "      <td>13-11-08</td>\n",
       "      <td>OFFICE81</td>\n",
       "      <td>IMP617843</td>\n",
       "      <td>DEC9556</td>\n",
       "      <td>8703210011</td>\n",
       "      <td>CNTRY939</td>\n",
       "      <td>3398</td>\n",
       "      <td>63</td>\n",
       "      <td>92044</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8703210011CNTRY939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25070</th>\n",
       "      <td>13-04-19</td>\n",
       "      <td>OFFICE92</td>\n",
       "      <td>IMP606401</td>\n",
       "      <td>DEC1200</td>\n",
       "      <td>9505900000</td>\n",
       "      <td>CNTRY825</td>\n",
       "      <td>1477</td>\n",
       "      <td>3</td>\n",
       "      <td>852</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9505900000CNTRY825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sgd.date office.id importer.id declarant.id  tariff.code   country  \\\n",
       "85303  13-11-18  OFFICE59   IMP648653      DEC5544   8703241128  CNTRY759   \n",
       "83064  13-11-08  OFFICE81   IMP617843      DEC9556   8703210011  CNTRY939   \n",
       "25070  13-04-19  OFFICE92   IMP606401      DEC1200   9505900000  CNTRY825   \n",
       "\n",
       "       cif.value  quantity  gross.weight  total.taxes  revenue  illicit  \\\n",
       "85303       8335         4         14344         4188        0        0   \n",
       "83064       3398        63         92044          188        0        0   \n",
       "25070       1477         3           852          700        0        0   \n",
       "\n",
       "      tariff.code&country  \n",
       "85303  8703241128CNTRY759  \n",
       "83064  8703210011CNTRY939  \n",
       "25070  9505900000CNTRY825  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a small data for the demonstration.\n",
    "df_sample = df.sample(3)\n",
    "merge_attributes(df_sample, 'tariff.code','country')\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can identify that new column \"TARIFF.CODE&ORIGIN.CODE\" has been created.  \n",
    "You can learn each step of the function by replicating the codes line by line as follows;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check what happens from \"iterables = [df[arg].astype(str) for arg in args]\"\n",
      "=====\n",
      "[88531    4203300000\n",
      "58655    8703241128\n",
      "7861     4115100000\n",
      "Name: tariff.code, dtype: object, 88531    CNTRY915\n",
      "58655    CNTRY759\n",
      "7861     CNTRY759\n",
      "Name: country, dtype: object]\n",
      "\n",
      "Check what happens from \"zip(*iterables)\"\n",
      "=====\n",
      "[('4203300000', 'CNTRY915'), ('8703241128', 'CNTRY759'), ('4115100000', 'CNTRY759')]\n",
      "\n",
      "What happens from \"fs = [.join([v for v in var]) for var in zip(*iterables)]\" - part1\n",
      "=====\n",
      "[('4203300000', 'CNTRY915'), ('8703241128', 'CNTRY759'), ('4115100000', 'CNTRY759')]\n",
      "\n",
      "What happens from \"fs = [.join([v for v in var]) for var in zip(*iterables)]\" - part2\n",
      "=====\n",
      "['4203300000CNTRY915', '8703241128CNTRY759', '4115100000CNTRY759']\n",
      "\n",
      "What happens from \"columnName = '&'.join([*args])'&'.join([*args])\"\n",
      "=====\n",
      "tariff.code&country\n",
      "\n",
      "df_sample[columnName]\n",
      "=====\n",
      "88531    4203300000CNTRY915\n",
      "58655    8703241128CNTRY759\n",
      "7861     4115100000CNTRY759\n",
      "Name: tariff.code&country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_sample = df.sample(3)\n",
    "print('Check what happens from \"iterables = [df[arg].astype(str) for arg in args]\"\\n=====')\n",
    "iterables = [df_sample[arg].astype(str) for arg in ['tariff.code','country']] \n",
    "print(iterables)\n",
    "print('')\n",
    "print('Check what happens from \"zip(*iterables)\"\\n=====')\n",
    "print(list(zip(*iterables)))\n",
    "print('')\n",
    "print('What happens from \"fs = [''.join([v for v in var]) for var in zip(*iterables)]\" - part1\\n=====')\n",
    "print(list(var for var in zip(*iterables)))\n",
    "print('')\n",
    "print('What happens from \"fs = [''.join([v for v in var]) for var in zip(*iterables)]\" - part2\\n=====')\n",
    "fs = [''.join([v for v in var]) for var in zip(*iterables)]\n",
    "print(fs)\n",
    "print('')\n",
    "print('What happens from \"columnName = \\'&\\'.join([*args])\\'&\\'.join([*args])\"\\n=====')\n",
    "columnName = '&'.join(['tariff.code','country'])\n",
    "print(columnName)\n",
    "print('')\n",
    "df_sample.loc[:, columnName] = fs\n",
    "print('df_sample[columnName]\\n=====')\n",
    "print(df_sample[columnName])\n",
    "\n",
    "# Now, we finish the line-by-line practice of the \"merge_attributes\" fuction, and delete temporarily created data. \n",
    "\n",
    "del df_sample, iterables, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess <a id='practice2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:16:02.938419Z",
     "start_time": "2022-02-22T04:16:02.933698Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sample = df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:16:06.672171Z",
     "start_time": "2022-02-22T04:16:06.650165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sgd.date</th>\n",
       "      <th>office.id</th>\n",
       "      <th>importer.id</th>\n",
       "      <th>declarant.id</th>\n",
       "      <th>tariff.code</th>\n",
       "      <th>country</th>\n",
       "      <th>cif.value</th>\n",
       "      <th>quantity</th>\n",
       "      <th>gross.weight</th>\n",
       "      <th>total.taxes</th>\n",
       "      <th>revenue</th>\n",
       "      <th>illicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73806</th>\n",
       "      <td>13-10-10</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP960205</td>\n",
       "      <td>DEC4665</td>\n",
       "      <td>8703241128</td>\n",
       "      <td>CNTRY615</td>\n",
       "      <td>5171</td>\n",
       "      <td>38</td>\n",
       "      <td>41206</td>\n",
       "      <td>6265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51678</th>\n",
       "      <td>13-07-29</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>IMP294703</td>\n",
       "      <td>DEC8281</td>\n",
       "      <td>8703242100</td>\n",
       "      <td>CNTRY959</td>\n",
       "      <td>2723</td>\n",
       "      <td>1</td>\n",
       "      <td>13153</td>\n",
       "      <td>29183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>13-01-11</td>\n",
       "      <td>OFFICE60</td>\n",
       "      <td>IMP472168</td>\n",
       "      <td>DEC6433</td>\n",
       "      <td>8702902099</td>\n",
       "      <td>CNTRY277</td>\n",
       "      <td>21915</td>\n",
       "      <td>3506</td>\n",
       "      <td>1696</td>\n",
       "      <td>9238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sgd.date office.id importer.id declarant.id  tariff.code   country  \\\n",
       "73806  13-10-10  OFFICE51   IMP960205      DEC4665   8703241128  CNTRY615   \n",
       "51678  13-07-29  OFFICE59   IMP294703      DEC8281   8703242100  CNTRY959   \n",
       "2484   13-01-11  OFFICE60   IMP472168      DEC6433   8702902099  CNTRY277   \n",
       "\n",
       "       cif.value  quantity  gross.weight  total.taxes  revenue  illicit  \n",
       "73806       5171        38         41206         6265        0        0  \n",
       "51678       2723         1         13153        29183        0        0  \n",
       "2484       21915      3506          1696         9238        0        0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T04:16:10.722312Z",
     "start_time": "2022-02-22T04:16:10.686232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sgd.date</th>\n",
       "      <th>office.id</th>\n",
       "      <th>importer.id</th>\n",
       "      <th>declarant.id</th>\n",
       "      <th>tariff.code</th>\n",
       "      <th>country</th>\n",
       "      <th>cif.value</th>\n",
       "      <th>quantity</th>\n",
       "      <th>gross.weight</th>\n",
       "      <th>total.taxes</th>\n",
       "      <th>revenue</th>\n",
       "      <th>illicit</th>\n",
       "      <th>Unitprice</th>\n",
       "      <th>WUnitprice</th>\n",
       "      <th>TaxRatio</th>\n",
       "      <th>TaxUnitquantity</th>\n",
       "      <th>HS6</th>\n",
       "      <th>HS4</th>\n",
       "      <th>HS2</th>\n",
       "      <th>HS6&amp;country</th>\n",
       "      <th>office.id&amp;importer.id</th>\n",
       "      <th>office.id&amp;HS6</th>\n",
       "      <th>office.id&amp;country</th>\n",
       "      <th>SGD.DayofYear</th>\n",
       "      <th>SGD.WeekofYear</th>\n",
       "      <th>SGD.MonthofYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63143</th>\n",
       "      <td>13-09-06</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP450852</td>\n",
       "      <td>DEC8408</td>\n",
       "      <td>8703331226</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>2609</td>\n",
       "      <td>8662</td>\n",
       "      <td>296948</td>\n",
       "      <td>5053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.301201</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>1.936757</td>\n",
       "      <td>0.583353</td>\n",
       "      <td>870333</td>\n",
       "      <td>8703</td>\n",
       "      <td>87</td>\n",
       "      <td>870333CNTRY680</td>\n",
       "      <td>OFFICE51IMP450852</td>\n",
       "      <td>OFFICE51870333</td>\n",
       "      <td>OFFICE51CNTRY680</td>\n",
       "      <td>248</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81592</th>\n",
       "      <td>13-11-05</td>\n",
       "      <td>OFFICE40</td>\n",
       "      <td>IMP397810</td>\n",
       "      <td>DEC9353</td>\n",
       "      <td>8702901396</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>2182</td>\n",
       "      <td>97</td>\n",
       "      <td>191175</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.494845</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>0.150779</td>\n",
       "      <td>3.391753</td>\n",
       "      <td>870290</td>\n",
       "      <td>8702</td>\n",
       "      <td>87</td>\n",
       "      <td>870290CNTRY680</td>\n",
       "      <td>OFFICE40IMP397810</td>\n",
       "      <td>OFFICE40870290</td>\n",
       "      <td>OFFICE40CNTRY680</td>\n",
       "      <td>308</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27278</th>\n",
       "      <td>13-04-29</td>\n",
       "      <td>OFFICE92</td>\n",
       "      <td>IMP354522</td>\n",
       "      <td>DEC1384</td>\n",
       "      <td>8702902099</td>\n",
       "      <td>CNTRY656</td>\n",
       "      <td>2392</td>\n",
       "      <td>1</td>\n",
       "      <td>2653</td>\n",
       "      <td>2893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2392.000000</td>\n",
       "      <td>0.901621</td>\n",
       "      <td>1.209448</td>\n",
       "      <td>2893.000000</td>\n",
       "      <td>870290</td>\n",
       "      <td>8702</td>\n",
       "      <td>87</td>\n",
       "      <td>870290CNTRY656</td>\n",
       "      <td>OFFICE92IMP354522</td>\n",
       "      <td>OFFICE92870290</td>\n",
       "      <td>OFFICE92CNTRY656</td>\n",
       "      <td>118</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sgd.date office.id importer.id declarant.id  tariff.code   country  \\\n",
       "63143  13-09-06  OFFICE51   IMP450852      DEC8408   8703331226  CNTRY680   \n",
       "81592  13-11-05  OFFICE40   IMP397810      DEC9353   8702901396  CNTRY680   \n",
       "27278  13-04-29  OFFICE92   IMP354522      DEC1384   8702902099  CNTRY656   \n",
       "\n",
       "       cif.value  quantity  gross.weight  total.taxes  revenue  illicit  \\\n",
       "63143       2609      8662        296948         5053        0        0   \n",
       "81592       2182        97        191175          329        0        0   \n",
       "27278       2392         1          2653         2893        0        0   \n",
       "\n",
       "         Unitprice  WUnitprice  TaxRatio  TaxUnitquantity     HS6   HS4  HS2  \\\n",
       "63143     0.301201    0.008786  1.936757         0.583353  870333  8703   87   \n",
       "81592    22.494845    0.011414  0.150779         3.391753  870290  8702   87   \n",
       "27278  2392.000000    0.901621  1.209448      2893.000000  870290  8702   87   \n",
       "\n",
       "          HS6&country office.id&importer.id   office.id&HS6 office.id&country  \\\n",
       "63143  870333CNTRY680     OFFICE51IMP450852  OFFICE51870333  OFFICE51CNTRY680   \n",
       "81592  870290CNTRY680     OFFICE40IMP397810  OFFICE40870290  OFFICE40CNTRY680   \n",
       "27278  870290CNTRY656     OFFICE92IMP354522  OFFICE92870290  OFFICE92CNTRY656   \n",
       "\n",
       "       SGD.DayofYear  SGD.WeekofYear  SGD.MonthofYear  \n",
       "63143            248              35                8  \n",
       "81592            308              44               10  \n",
       "27278            118              16                3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(3)\n",
    "df_sample = preprocess(df_sample)\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find_risk_profile <a id='practice3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMP243487',\n",
       " 'IMP264340',\n",
       " 'IMP692823',\n",
       " 'IMP913967',\n",
       " 'IMP505713',\n",
       " 'IMP865586',\n",
       " 'IMP355376',\n",
       " 'IMP358915',\n",
       " 'IMP361374',\n",
       " 'IMP366360']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(100)\n",
    "\n",
    "# We will identify top 10% of high risk importers in terms of its non-compliance records. \n",
    "find_risk_profile(df=df_sample, feature='importer.id', topk_ratio=0.1, adj=10, option='topk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tag_risky_profiles <a id='practice4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMP221442',\n",
       " 'IMP317314',\n",
       " 'IMP606401',\n",
       " 'IMP643025',\n",
       " 'IMP783306',\n",
       " 'IMP438805',\n",
       " 'IMP225876',\n",
       " 'IMP412513',\n",
       " 'IMP358915',\n",
       " 'IMP359656']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a sample data\n",
    "df_sample = df.sample(100)\n",
    "# Identify top 10% high-risk importer\n",
    "risk_profiles = find_risk_profile(df_sample, 'importer.id', 0.1, 10, option='topk')\n",
    "risk_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sgd.date</th>\n",
       "      <th>office.id</th>\n",
       "      <th>importer.id</th>\n",
       "      <th>declarant.id</th>\n",
       "      <th>tariff.code</th>\n",
       "      <th>country</th>\n",
       "      <th>cif.value</th>\n",
       "      <th>quantity</th>\n",
       "      <th>gross.weight</th>\n",
       "      <th>total.taxes</th>\n",
       "      <th>revenue</th>\n",
       "      <th>illicit</th>\n",
       "      <th>RiskH.importer.id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97391</th>\n",
       "      <td>13-12-23</td>\n",
       "      <td>OFFICE40</td>\n",
       "      <td>IMP606401</td>\n",
       "      <td>DEC3641</td>\n",
       "      <td>8516800000</td>\n",
       "      <td>CNTRY415</td>\n",
       "      <td>3577</td>\n",
       "      <td>1</td>\n",
       "      <td>565</td>\n",
       "      <td>510</td>\n",
       "      <td>1442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38968</th>\n",
       "      <td>13-06-11</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP359656</td>\n",
       "      <td>DEC8254</td>\n",
       "      <td>8703321922</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>8124</td>\n",
       "      <td>1</td>\n",
       "      <td>25077</td>\n",
       "      <td>4141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93071</th>\n",
       "      <td>13-12-09</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>IMP358915</td>\n",
       "      <td>DEC6350</td>\n",
       "      <td>8703321922</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>4365</td>\n",
       "      <td>4</td>\n",
       "      <td>1993</td>\n",
       "      <td>4381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31041</th>\n",
       "      <td>13-05-13</td>\n",
       "      <td>OFFICE76</td>\n",
       "      <td>IMP412513</td>\n",
       "      <td>DEC3474</td>\n",
       "      <td>8704322000</td>\n",
       "      <td>CNTRY454</td>\n",
       "      <td>6729</td>\n",
       "      <td>1</td>\n",
       "      <td>8557</td>\n",
       "      <td>3222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>13-01-29</td>\n",
       "      <td>OFFICE60</td>\n",
       "      <td>IMP317314</td>\n",
       "      <td>DEC8824</td>\n",
       "      <td>8210000000</td>\n",
       "      <td>CNTRY859</td>\n",
       "      <td>4051</td>\n",
       "      <td>596</td>\n",
       "      <td>206579</td>\n",
       "      <td>4163</td>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10500</th>\n",
       "      <td>13-02-18</td>\n",
       "      <td>OFFICE76</td>\n",
       "      <td>IMP322276</td>\n",
       "      <td>DEC3949</td>\n",
       "      <td>8703332100</td>\n",
       "      <td>CNTRY615</td>\n",
       "      <td>4616</td>\n",
       "      <td>1342</td>\n",
       "      <td>236012</td>\n",
       "      <td>2690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70057</th>\n",
       "      <td>13-09-30</td>\n",
       "      <td>OFFICE60</td>\n",
       "      <td>IMP891508</td>\n",
       "      <td>DEC1704</td>\n",
       "      <td>9022120000</td>\n",
       "      <td>CNTRY874</td>\n",
       "      <td>1841</td>\n",
       "      <td>1</td>\n",
       "      <td>8582</td>\n",
       "      <td>726</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49383</th>\n",
       "      <td>13-07-17</td>\n",
       "      <td>OFFICE59</td>\n",
       "      <td>IMP839288</td>\n",
       "      <td>DEC5426</td>\n",
       "      <td>8703241128</td>\n",
       "      <td>CNTRY680</td>\n",
       "      <td>271655</td>\n",
       "      <td>1</td>\n",
       "      <td>376516</td>\n",
       "      <td>62042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92026</th>\n",
       "      <td>13-12-05</td>\n",
       "      <td>OFFICE76</td>\n",
       "      <td>IMP992026</td>\n",
       "      <td>DEC2777</td>\n",
       "      <td>8517180000</td>\n",
       "      <td>CNTRY759</td>\n",
       "      <td>9305</td>\n",
       "      <td>1</td>\n",
       "      <td>504647</td>\n",
       "      <td>3772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93351</th>\n",
       "      <td>13-12-10</td>\n",
       "      <td>OFFICE51</td>\n",
       "      <td>IMP896567</td>\n",
       "      <td>DEC5070</td>\n",
       "      <td>7004900000</td>\n",
       "      <td>CNTRY316</td>\n",
       "      <td>1089058</td>\n",
       "      <td>84</td>\n",
       "      <td>991</td>\n",
       "      <td>317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sgd.date office.id importer.id declarant.id  tariff.code   country  \\\n",
       "97391  13-12-23  OFFICE40   IMP606401      DEC3641   8516800000  CNTRY415   \n",
       "38968  13-06-11  OFFICE51   IMP359656      DEC8254   8703321922  CNTRY680   \n",
       "93071  13-12-09  OFFICE59   IMP358915      DEC6350   8703321922  CNTRY680   \n",
       "31041  13-05-13  OFFICE76   IMP412513      DEC3474   8704322000  CNTRY454   \n",
       "5849   13-01-29  OFFICE60   IMP317314      DEC8824   8210000000  CNTRY859   \n",
       "...         ...       ...         ...          ...          ...       ...   \n",
       "10500  13-02-18  OFFICE76   IMP322276      DEC3949   8703332100  CNTRY615   \n",
       "70057  13-09-30  OFFICE60   IMP891508      DEC1704   9022120000  CNTRY874   \n",
       "49383  13-07-17  OFFICE59   IMP839288      DEC5426   8703241128  CNTRY680   \n",
       "92026  13-12-05  OFFICE76   IMP992026      DEC2777   8517180000  CNTRY759   \n",
       "93351  13-12-10  OFFICE51   IMP896567      DEC5070   7004900000  CNTRY316   \n",
       "\n",
       "       cif.value  quantity  gross.weight  total.taxes  revenue  illicit  \\\n",
       "97391       3577         1           565          510     1442        1   \n",
       "38968       8124         1         25077         4141        0        0   \n",
       "93071       4365         4          1993         4381        0        0   \n",
       "31041       6729         1          8557         3222        0        0   \n",
       "5849        4051       596        206579         4163      336        1   \n",
       "...          ...       ...           ...          ...      ...      ...   \n",
       "10500       4616      1342        236012         2690        0        0   \n",
       "70057       1841         1          8582          726        0        0   \n",
       "49383     271655         1        376516        62042        0        0   \n",
       "92026       9305         1        504647         3772        0        0   \n",
       "93351    1089058        84           991          317        0        0   \n",
       "\n",
       "       RiskH.importer.id  \n",
       "97391                  1  \n",
       "38968                  1  \n",
       "93071                  1  \n",
       "31041                  1  \n",
       "5849                   1  \n",
       "...                  ...  \n",
       "10500                  0  \n",
       "70057                  0  \n",
       "49383                  0  \n",
       "92026                  0  \n",
       "93351                  0  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tag \"RiskH\" to the top 10% high-risk importers\n",
    "aaa = tag_risky_profiles(df=df_sample, profile='importer.id', profiles=risk_profiles, option='topk')\n",
    "aaa.sort_values('RiskH.importer.id', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_sample, aaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process_leaf_idx <a id='practice5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T07:30:42.943955Z",
     "start_time": "2022-02-22T07:30:42.921947Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_leaves' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-bcd0b3e96106>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_leaves\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 100 trees in our xgboost model!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_leaves' is not defined"
     ]
    }
   ],
   "source": [
    "df_sample = X_train_leaves[:3] # 100 trees in our xgboost model!\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves, total_leaves, new_leaf_index = process_leaf_idx(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  65,\n",
       "         67,  69,  70,  71,  72,  73,  74,  75,  77,  79,  81,  83,  84,\n",
       "         85,  86,  88,  89,  91,  93,  96,  97,  98, 100, 101, 102, 106,\n",
       "        108, 111, 112, 115, 116, 117, 119, 120, 121],\n",
       "       [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  64,  65,\n",
       "         66,  69,  70,  71,  72,  73,  74,  75,  76,  80,  82,  83,  84,\n",
       "         85,  87,  88,  89,  90,  94,  95,  97,  99, 100, 101, 103, 105,\n",
       "        109, 110, 113, 114, 116, 118, 119, 120, 121],\n",
       "       [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  64,  65,\n",
       "         68,  69,  70,  71,  72,  73,  74,  75,  78,  80,  82,  83,  84,\n",
       "         85,  86,  88,  89,  92,  94,  95,  97,  98, 100, 101, 104, 107,\n",
       "        108, 110, 112, 115, 116, 118, 119, 120, 121]], dtype=int32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new idex of leaf\n",
    "leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: 15},\n",
       " 1: {1: 15},\n",
       " 2: {2: 15},\n",
       " 3: {3: 15},\n",
       " 4: {4: 15},\n",
       " 5: {5: 15},\n",
       " 6: {6: 15},\n",
       " 7: {7: 15},\n",
       " 8: {8: 15},\n",
       " 9: {9: 15},\n",
       " 10: {10: 13},\n",
       " 11: {11: 15},\n",
       " 12: {12: 15},\n",
       " 13: {13: 13},\n",
       " 14: {14: 13},\n",
       " 15: {15: 13},\n",
       " 16: {16: 13},\n",
       " 17: {17: 15},\n",
       " 18: {18: 15},\n",
       " 19: {19: 15},\n",
       " 20: {20: 15},\n",
       " 21: {21: 15},\n",
       " 22: {22: 15},\n",
       " 23: {23: 15},\n",
       " 24: {24: 15},\n",
       " 25: {25: 15},\n",
       " 26: {26: 17},\n",
       " 27: {27: 23},\n",
       " 28: {28: 15},\n",
       " 29: {29: 23},\n",
       " 30: {30: 17},\n",
       " 31: {31: 15},\n",
       " 32: {32: 17},\n",
       " 33: {33: 15},\n",
       " 34: {34: 15},\n",
       " 35: {35: 19},\n",
       " 36: {36: 15},\n",
       " 37: {37: 25},\n",
       " 38: {38: 15},\n",
       " 39: {39: 15},\n",
       " 40: {40: 15},\n",
       " 41: {41: 20},\n",
       " 42: {42: 17},\n",
       " 43: {43: 15},\n",
       " 44: {44: 16},\n",
       " 45: {45: 28},\n",
       " 46: {46: 15},\n",
       " 47: {47: 15},\n",
       " 48: {48: 17},\n",
       " 49: {49: 16},\n",
       " 50: {50: 16},\n",
       " 51: {51: 15},\n",
       " 52: {52: 17},\n",
       " 53: {53: 15},\n",
       " 54: {54: 21},\n",
       " 55: {55: 20},\n",
       " 56: {56: 15},\n",
       " 57: {57: 15},\n",
       " 58: {58: 20},\n",
       " 59: {59: 15},\n",
       " 60: {60: 17},\n",
       " 61: {61: 21},\n",
       " 62: {62: 15},\n",
       " 63: {63: 19},\n",
       " 64: {63: 20},\n",
       " 65: {64: 16},\n",
       " 66: {65: 15},\n",
       " 67: {65: 25},\n",
       " 68: {65: 27},\n",
       " 69: {66: 16},\n",
       " 70: {67: 16},\n",
       " 71: {68: 18},\n",
       " 72: {69: 15},\n",
       " 73: {70: 15},\n",
       " 74: {71: 19},\n",
       " 75: {72: 22},\n",
       " 76: {73: 15},\n",
       " 77: {73: 17},\n",
       " 78: {73: 18},\n",
       " 79: {74: 17},\n",
       " 80: {74: 18},\n",
       " 81: {75: 19},\n",
       " 82: {75: 20},\n",
       " 83: {76: 17},\n",
       " 84: {77: 15},\n",
       " 85: {78: 16},\n",
       " 86: {79: 18},\n",
       " 87: {79: 19},\n",
       " 88: {80: 19},\n",
       " 89: {81: 18},\n",
       " 90: {82: 15},\n",
       " 91: {82: 19},\n",
       " 92: {82: 22},\n",
       " 93: {83: 16},\n",
       " 94: {83: 20},\n",
       " 95: {84: 15},\n",
       " 96: {84: 16},\n",
       " 97: {85: 18},\n",
       " 98: {86: 18},\n",
       " 99: {86: 19},\n",
       " 100: {87: 29},\n",
       " 101: {88: 15},\n",
       " 102: {89: 16},\n",
       " 103: {89: 19},\n",
       " 104: {89: 20},\n",
       " 105: {90: 18},\n",
       " 106: {90: 21},\n",
       " 107: {90: 27},\n",
       " 108: {91: 20},\n",
       " 109: {91: 23},\n",
       " 110: {92: 15},\n",
       " 111: {92: 17},\n",
       " 112: {93: 18},\n",
       " 113: {93: 21},\n",
       " 114: {94: 13},\n",
       " 115: {94: 16},\n",
       " 116: {95: 18},\n",
       " 117: {96: 16},\n",
       " 118: {96: 23},\n",
       " 119: {97: 23},\n",
       " 120: {98: 15},\n",
       " 121: {99: 18}}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference: {new_leaf_index: {tree_index: leaf_index}}\n",
    "new_leaf_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_sample, leaves, total_leaves, new_leaf_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mish <a id='practice6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[0.5517, 0.7971, 0.1953]]) Mish(x):  tensor([[0.4217, 0.6568, 0.1292]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1,3))\n",
    "Mish_test = Mish()\n",
    "print(\"x: \", x,\"Mish(x): \", Mish_test(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FusionAttention <a id='practice7'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T08:52:57.324441Z",
     "start_time": "2022-02-22T08:52:57.301826Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Set an arbitrary imput data\n",
      "=====\n",
      "torch.Size([256, 3, 16])\n",
      "\n",
      "1. query_project \n",
      "==============\n",
      "torch.Size([256, 3, 16])\n",
      "\n",
      "2. query_project \n",
      "==============\n",
      "torch.Size([256, 3, 16])\n",
      "\n",
      "3. project_value \n",
      "==============\n",
      "torch.Size([256, 3, 1])\n",
      "\n",
      "4. attention_weight \n",
      "==============\n",
      "torch.Size([256, 3, 1])\n",
      "\n",
      "5. attention_vec \n",
      "==============\n",
      "torch.Size([256, 3, 16])\n",
      "\n",
      "6. attention_vec \n",
      "==============\n",
      "torch.Size([256, 16])\n"
     ]
    }
   ],
   "source": [
    "print('0. Set an arbitrary imput data\\n=====')\n",
    "inputs_test = torch.randn(256,3,16)\n",
    "print(inputs_test.shape)\n",
    "dim_test=inputs_test.shape[-1]\n",
    "print('')\n",
    "print(\"1. query_project \\n==============\")\n",
    "query_project = nn.Linear(dim_test,dim_test)(inputs_test)\n",
    "print(query_project.shape)\n",
    "print('')\n",
    "print(\"2. query_project \\n==============\")\n",
    "query_project = F.leaky_relu(query_project)\n",
    "print(query_project.shape)\n",
    "print('')\n",
    "print(\"3. project_value \\n==============\")\n",
    "project_value = nn.Linear(dim_test,1)(query_project)\n",
    "print(project_value.shape)\n",
    "print('')\n",
    "print(\"4. attention_weight \\n==============\")\n",
    "attention_weight = torch.softmax(project_value, dim=1)\n",
    "print(attention_weight.shape)\n",
    "print('')\n",
    "print(\"5. attention_vec \\n==============\")\n",
    "attention_vec = inputs_test*attention_weight\n",
    "print(attention_vec.shape)\n",
    "print('')\n",
    "print(\"6. attention_vec \\n==============\")\n",
    "attention_vec = torch.sum(attention_vec, dim=1)\n",
    "print(attention_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention <a id='practice8'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T09:38:43.387538Z",
     "start_time": "2022-02-22T09:38:43.365532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Set arbitrary \"query\" and \"key\"\n",
      "=====\n",
      "query: torch.Size([256, 16])\n",
      "key: torch.Size([256, 100, 16])\n",
      "\n",
      "2. Transform \"quary\" to be merged with \"key\"\n",
      "=====\n",
      "query: torch.Size([256, 100, 16])\n",
      "cat_vector: torch.Size([256, 100, 32])\n",
      "\n",
      "3. Neural Network\n",
      "=====\n",
      "3-1. project_vector: torch.Size([256, 100, 16])\n",
      "3-2. project_vector: torch.Size([256, 100, 16])\n",
      "3-3. h: torch.Size([16, 1])\n",
      "3-4. attention_weight: torch.Size([256, 100, 1])\n",
      "3-5. attention_vec: torch.Size([256, 100, 16])\n",
      "\n",
      "4. Result\n",
      "=====\n",
      "4-1. max_attention_vec: torch.Size([256, 16])\n",
      "4-2. mean_attention_vec: torch.Size([256, 16])\n",
      "4-3. sum_attention_vec: torch.Size([256, 16])\n"
     ]
    }
   ],
   "source": [
    "print('1. Set arbitrary \"query\" and \"key\"\\n=====')\n",
    "# \"query\" is the embedding layer of importer_id + HScode_id in the final model.\n",
    "# \"key\" is the embedding layer of leaf_id of 100 decision trees in the final model.\n",
    "query = torch.randn(256, 16) # (batch_size, n_embedding_dim)\n",
    "print('query:',query.shape)\n",
    "key = torch.randn(256, 100, 16) # (batch_size, n_trees, n_embedding_dim)\n",
    "print('key:',key.shape)\n",
    "print('')\n",
    "print('2. Transform \"quary\" to be merged with \"key\"\\n=====')\n",
    "dim = query.size(-1) # 16 (n_embedding_dimension)\n",
    "batch = key.size(0) # 256 (batch_size = n_observation in a batch)\n",
    "time_step = key.size(1) # 100 (n_trees from xgboot model)\n",
    "query = query.view(batch,1,dim) # view = reshape: (256X16) -> (256X1X16)\n",
    "query = query.expand(batch,time_step,-1) # expand to the same dimension: (256X1X16) -> (256X100X16)\n",
    "print('query:', query.shape)\n",
    "cat_vector = torch.cat((query,key),dim=-1) # (256X100X32)\n",
    "print('cat_vector:',cat_vector.shape)\n",
    "print('')\n",
    "print('3. Neural Network\\n=====')\n",
    "project_vector = nn.Linear(32,16)(cat_vector)\n",
    "print('3-1. project_vector:',project_vector.shape)\n",
    "project_vector = torch.relu(project_vector)\n",
    "print('3-2. project_vector:',project_vector.shape)\n",
    "h = nn.Parameter(torch.rand(16,1))\n",
    "print('3-3. h:',h.shape)\n",
    "attention_alpha = torch.matmul(project_vector,h)\n",
    "attention_weight = torch.softmax(attention_alpha, dim=1) # Normalize and calculate weights (b,t,1)\n",
    "print('3-4. attention_weight:',attention_weight.shape)\n",
    "attention_vec = key * attention_weight # assumed 'key'=='value'\n",
    "print('3-5. attention_vec:',attention_vec.shape)\n",
    "print('')\n",
    "print('4. Result\\n=====')\n",
    "max_attention_vec,_ = torch.max(attention_vec,dim=1)\n",
    "print('4-1. max_attention_vec:',max_attention_vec.shape)\n",
    "mean_attention_vec = torch.mean(attention_vec,dim=1)\n",
    "print('4-2. mean_attention_vec:',mean_attention_vec.shape)\n",
    "sum_attention_vec = torch.sum(attention_vec,dim=1)\n",
    "print('4-3. sum_attention_vec:',sum_attention_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATE model <a id='practice9'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T10:18:44.762302Z",
     "start_time": "2022-02-22T10:18:44.541304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Hyperparameters\n",
      "=====\n",
      "dim: 16\n",
      "leaf_num: 1380\n",
      "device: cpu\n",
      "item_size: 1877\n",
      "importer_size: 7342\n",
      "\n",
      "2. Toy data (batch)\n",
      "=====\n",
      "one batch from 'train_loader'\n",
      "feature: torch.Size([256, 100])\n",
      "uid: torch.Size([256])\n",
      "item_id: torch.Size([256])\n",
      "\n",
      "3. Embedding of feature (cross-features, leaf_ids)\n",
      "=====\n",
      "leaf_vectors: torch.Size([256, 100, 16])\n",
      "\n",
      "4. Multi-Head Self-Attention (1st attention) \n",
      "=====\n",
      "torch.Size([256, 100, 16])\n",
      "torch.Size([256, 100, 16])\n",
      "\n",
      "5. Embedding of importer_id\n",
      "=====\n",
      "torch.Size([256, 16])\n",
      "\n",
      "6. Embedding of item_id(HScode)\n",
      "=====\n",
      "torch.Size([256, 16])\n",
      " \n",
      "7. Multiply embeddings of importer_id and item_id\n",
      "=====\n",
      "torch.Size([256, 16])\n",
      " \n",
      "8. Attention with leaf_id, importer_id and item_id (2nd attention)\n",
      "=====\n",
      "torch.Size([256, 16])\n",
      "\n",
      "9. Concat the user_id, item_id and set(attention)_vector to fusion\n",
      "=====\n",
      "importer_vector: torch.Size([256, 1, 16])\n",
      "item_vector: torch.Size([256, 1, 16])\n",
      "set_vector: torch.Size([256, 1, 16])\n",
      "fusion: torch.Size([256, 3, 16])\n",
      "\n",
      "10. Fusion Attention\n",
      "=====\n",
      "fusion: torch.Size([256, 16])\n",
      "\n",
      "11. Task-specific layers\n",
      "=====\n",
      "hidden: torch.Size([256, 16])\n",
      "\n",
      "12. output\n",
      "=====\n",
      "classification_output: torch.Size([256, 1])\n",
      "regression_output: torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "head_num = 4\n",
    "\n",
    "print('1. Hyperparameters\\n=====')\n",
    "print('dim:',dim)\n",
    "print('leaf_num:',leaf_num)\n",
    "print('device:',device)\n",
    "print('item_size:',item_size)\n",
    "print('importer_size:',importer_size)\n",
    "print('')\n",
    "print('2. Toy data (batch)\\n=====\\none batch from \\'train_loader\\'')\n",
    "#分别为叶节点，importer_id，物品id，欺诈标签，收入标签\n",
    "feature,uid,item_id,cls,reg = next(iter(train_loader))\n",
    "print('feature:',feature.shape)\n",
    "print('uid:',uid.shape)\n",
    "print('item_id:',item_id.shape)\n",
    "# other option\n",
    "#feature = train_loader.dataset.tensors[0][:256]\n",
    "#uid = train_loader.dataset.tensors[1][:256]\n",
    "#item_id = train_loader.dataset.tensors[2][:256]\n",
    "print('')\n",
    "print('3. Embedding of feature (cross-features, leaf_ids)\\n=====')\n",
    "leaf_vectors = nn.Embedding(leaf_num,dim)(feature)\n",
    "print('leaf_vectors:',leaf_vectors.shape)\n",
    "print('')\n",
    "print('4. Multi-Head Self-Attention (1st attention) \\n=====')\n",
    "# Calculate the weight(importance) of each leaf(cross-feature) based on the correlation with other leafs\n",
    "# Apply multy head attention\n",
    "multiheadattention = nn.MultiheadAttention(dim,head_num).to(device)\n",
    "leaf_vectors,_ = multiheadattention(leaf_vectors,leaf_vectors,leaf_vectors)\n",
    "print(leaf_vectors.shape)\n",
    "leaf_vectors = nn.LayerNorm((100,dim))(leaf_vectors)\n",
    "print(leaf_vectors.shape)\n",
    "print('')\n",
    "print('5. Embedding of importer_id\\n=====')\n",
    "#原本值为0向量会继续被嵌入为0，那些在train里没有的importer这里继续为0\n",
    "importer_vector = nn.Embedding(importer_size,dim,padding_idx=0)(uid)\n",
    "print(importer_vector.shape)\n",
    "print('')\n",
    "print('6. Embedding of item_id(HScode)\\n=====')\n",
    "item_vector = nn.Embedding(item_size,dim,padding_idx=0)(item_id)\n",
    "print(item_vector.shape)\n",
    "print(' ')\n",
    "print('7. Multiply embeddings of importer_id and item_id\\n=====')\n",
    "query_vector = importer_vector * item_vector\n",
    "print(query_vector.shape)\n",
    "print(' ')\n",
    "print('8. Attention with leaf_id, importer_id and item_id (2nd attention)\\n=====')\n",
    "#相当于把uid和item的权重加到了叶节点上\n",
    "attention = Attention(dim,dim,\"sum\").to(device)\n",
    "set_vector, _ = attention(query_vector,leaf_vectors)\n",
    "print(set_vector.shape)\n",
    "print('')\n",
    "print('9. Concat the user_id, item_id and set(attention)_vector to fusion\\n=====')\n",
    "importer_vector=importer_vector.view(-1,1,dim)\n",
    "print('importer_vector:',importer_vector.shape)\n",
    "item_vector=item_vector.view(-1,1,dim) \n",
    "print('item_vector:',item_vector.shape)\n",
    "set_vector=set_vector.view(-1,1,dim)\n",
    "print('set_vector:',set_vector.shape)\n",
    "fusion = torch.cat((importer_vector, item_vector, set_vector), dim=1) # attach as columns\n",
    "print('fusion:', fusion.shape)\n",
    "print('')\n",
    "print('10. Fusion Attention\\n=====')\n",
    "fusion_att = FusionAttention(dim)\n",
    "fusion,_ = fusion_att(fusion) # fusion attention\n",
    "print('fusion:',fusion.shape)\n",
    "print('')\n",
    "print('11. Task-specific layers\\n=====')\n",
    "hidden = nn.Linear(dim,dim)(fusion)\n",
    "hidden = nn.LeakyReLU()(hidden)\n",
    "print('hidden:',hidden.shape)\n",
    "print('')\n",
    "print('12. output\\n=====')\n",
    "classification_output = torch.sigmoid(nn.Linear(dim,1)(hidden))\n",
    "print('classification_output:',classification_output.shape)\n",
    "regression_output = torch.relu(nn.Linear(dim,1)(hidden))\n",
    "print('regression_output:',regression_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annex: XGBoost and Logistic Regression <a id='part6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.1. Performance of XGBoost model\n",
    "Performance indicators;\n",
    "- precision = (number of seizures)/(number of inspections) --> targeting accuracy\n",
    "- recall = (number of seizures)/(number of actual frauds)\n",
    "- revenue_recall = (revenue from seizures)/(revenue from actual frauds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking top 1% suspicious transactions: 200\n",
      "Precision: 0.20499999821186066, Recall: 0.027, Seized Revenue (Recall): 0.0314\n",
      "Checking top 2% suspicious transactions: 400\n",
      "Precision: 0.20250000059604645, Recall: 0.0533, Seized Revenue (Recall): 0.0546\n",
      "Checking top 5% suspicious transactions: 1000\n",
      "Precision: 0.1889999955892563, Recall: 0.1243, Seized Revenue (Recall): 0.1255\n",
      "Checking top 10% suspicious transactions: 2000\n",
      "Precision: 0.19050000607967377, Recall: 0.2505, Seized Revenue (Recall): 0.2686\n"
     ]
    }
   ],
   "source": [
    "# Precision and Recall\n",
    "y_prob = test_pred\n",
    "for i in [99,98,95,90]:\n",
    "    # Find the ith value in ascending order.\n",
    "    threshold = np.percentile(y_prob, i)\n",
    "    print(f'Checking top {100-i}% suspicious transactions: {len(y_prob[y_prob > threshold])}')\n",
    "    precision = np.mean(xgb_testy[y_prob > threshold])\n",
    "    recall = sum(xgb_testy[y_prob > threshold])/sum(xgb_testy)\n",
    "    revenue_recall = sum(revenue_test[y_prob > threshold]) /sum(revenue_test)\n",
    "    print(f'Precision: {round(precision, 4)}, Recall: {round(recall, 4)}, Seized Revenue (Recall): {round(revenue_recall, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the structured trees in txt file\n",
    "xgb_clf.get_booster().dump_model('xgb_model.txt', with_stats=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2. XGBoost + Logistic Regression model <a id='part3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2.1. Deploy Xgboost+LR model \n",
    "Summary\n",
    "    1. Apply the pre-trained XGBoost model to train-, valid- and test-data. \n",
    "    2. For an individual import, the XGBoost model returns a list of leaf index of the multiple trees. \n",
    "    3. One-hot-encode leaf node.\n",
    "    4. The encoded leaf index is fed as an input into the logistic regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Apply the pre-trained XGBoost model to train-, valid- and test-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xgboost+LR model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "\n",
    "# get leaf index from xgboost model \n",
    "X_train_leaves = xgb_clf.apply(xgb_trainx) #apply: Return the predicted leaf every tree for each sample.\n",
    "X_valid_leaves = xgb_clf.apply(xgb_validx)\n",
    "X_test_leaves = xgb_clf.apply(xgb_testx)\n",
    "train_rows = X_train_leaves.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For an individual import, the XGBoost model returns a list of leaf index of the multiple trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 13, 15, 15, 13, 13, 13, 13,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 17, 23, 15, 23, 17, 15, 17, 15,\n",
       "       15, 19, 15, 25, 15, 15, 15, 20, 17, 15, 16, 28, 15, 15, 17, 16, 16,\n",
       "       15, 17, 15, 21, 20, 15, 15, 20, 15, 17, 21, 15, 19, 16, 25, 16, 16,\n",
       "       18, 15, 15, 19, 22, 17, 17, 19, 17, 15, 16, 18, 19, 18, 19, 16, 16,\n",
       "       18, 18, 29, 15, 16, 21, 20, 17, 18, 16, 18, 16, 23, 15, 18],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the 100 leaf nodes of the first import in the train-data\n",
    "X_train_leaves[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. One-hot-encode the leaf (Create unique set of 0s and 1s for individual leaf index).\n",
    "For instance, \n",
    "    - Leaf index 1: [100000...00]\n",
    "    - Leaf index 2: [010000...00]\n",
    "    - Leaf index 3: [001000...00]\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding for leaf index\n",
    "xgbenc = OneHotEncoder(categories=\"auto\")\n",
    "lr_trainx = xgbenc.fit_transform(X_train_leaves)\n",
    "lr_validx = xgbenc.transform(X_valid_leaves)\n",
    "lr_testx = xgbenc.transform(X_test_leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Input the encoded leaf index into the logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic regression model...\n",
      "------Evaluating xgboost+LR model------\n",
      "F1-scre equals to:0.1607\n",
      "AUC = 0.6581, F1-score = 0.1607\n"
     ]
    }
   ],
   "source": [
    "# model \n",
    "print(\"Training Logistic regression model...\")\n",
    "lr = LogisticRegression(n_jobs=-1)\n",
    "lr.fit(lr_trainx, xgb_trainy)\n",
    "test_pred = lr.predict_proba(lr_testx)[:,1]\n",
    "print(\"------Evaluating xgboost+LR model------\")\n",
    "xgb_auc = roc_auc_score(xgb_testy, test_pred)\n",
    "xgb_threshold,_ = find_best_threshold(lr, lr_validx, xgb_validy) # threshold was select from validation set\n",
    "xgb_f1 = find_best_threshold(lr, lr_testx, xgb_testy,best_thresh=xgb_threshold) # then applied on test set\n",
    "print(\"AUC = %.4f, F1-score = %.4f\" % (xgb_auc, xgb_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2.2. Performance of XGBoost + LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking top 1% suspicious transactions: 200\n",
      "Precision: 0.20000000298023224, Recall: 0.0263, Seized Revenue (Recall): 0.0285\n",
      "Checking top 2% suspicious transactions: 400\n",
      "Precision: 0.1875, Recall: 0.0493, Seized Revenue (Recall): 0.0534\n",
      "Checking top 5% suspicious transactions: 1000\n",
      "Precision: 0.17900000512599945, Recall: 0.1177, Seized Revenue (Recall): 0.1233\n",
      "Checking top 10% suspicious transactions: 2000\n",
      "Precision: 0.16599999368190765, Recall: 0.2183, Seized Revenue (Recall): 0.2291\n"
     ]
    }
   ],
   "source": [
    "# Precision and Recall\n",
    "y_prob = test_pred\n",
    "for i in [99,98,95,90]:\n",
    "    threshold = np.percentile(y_prob, i)\n",
    "    print(f'Checking top {100-i}% suspicious transactions: {len(y_prob[y_prob > threshold])}')\n",
    "    precision = np.mean(xgb_testy[y_prob > threshold])\n",
    "    recall = sum(xgb_testy[y_prob > threshold])/sum(xgb_testy)\n",
    "    revenue_recall = sum(revenue_test[y_prob > threshold]) /sum(revenue_test)\n",
    "    print(f'Precision: {round(precision, 4)}, Recall: {round(recall, 4)}, Seized Revenue (Recall): {round(revenue_recall, 4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
