{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分类别和连续变量\n",
    "categorical_features = [\n",
    "    'ProductCD',\n",
    "    'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
    "    'addr1', 'addr2',\n",
    "    'P_emaildomain',\n",
    "    'R_emaildomain',\n",
    "    'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9'\n",
    "]\n",
    "\n",
    "continuous_features = list(filter(lambda x: x not in categorical_features, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对于偏度大于1的变量进行log化，再去中心化\n",
    "class ContinuousFeatureConverter:\n",
    "    def __init__(self, name, feature, log_transform):\n",
    "        self.name = name\n",
    "        self.skew = feature.skew()\n",
    "        self.log_transform = log_transform\n",
    "        \n",
    "    def transform(self, feature):\n",
    "        if self.skew > 1:\n",
    "            feature = self.log_transform(feature)\n",
    "        \n",
    "        mean = feature.mean()\n",
    "        std = feature.std()\n",
    "        return (feature - mean)/(std + 1e-6)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "feature_converters = {}\n",
    "continuous_features_processed = []\n",
    "continuous_features_processed_test = []\n",
    "\n",
    "for f in tqdm(continuous_features):\n",
    "    feature = X[f]#这里修改trian和test\n",
    "    feature_test = X_test[f]\n",
    "    log = lambda x: np.log10(x + 1 - min(0, x.min()))\n",
    "    converter = ContinuousFeatureConverter(f, feature, log)\n",
    "    feature_converters[f] = converter\n",
    "    continuous_features_processed.append(converter.transform(feature))\n",
    "    continuous_features_processed_test.append(converter.transform(feature_test))\n",
    "    \n",
    "continuous_train = pd.DataFrame({s.name: s for s in continuous_features_processed}).astype(np.float32)\n",
    "continuous_test = pd.DataFrame({s.name: s for s in continuous_features_processed_test}).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a608988",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_train['isna_sum'] = continuous_train.isna().sum(axis=1)\n",
    "continuous_test['isna_sum'] = continuous_test.isna().sum(axis=1)\n",
    "\n",
    "continuous_train['isna_sum'] = (continuous_train['isna_sum'] - continuous_train['isna_sum'].mean())/continuous_train['isna_sum'].std()\n",
    "continuous_test['isna_sum'] = (continuous_test['isna_sum'] - continuous_test['isna_sum'].mean())/continuous_test['isna_sum'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "isna_columns = []\n",
    "for column in tqdm(continuous_features):\n",
    "    isna = continuous_train[column].isna()\n",
    "    if isna.mean() > 0.:\n",
    "        continuous_train[column + '_isna'] = isna.astype(int)\n",
    "        continuous_test[column + '_isna'] = continuous_test[column].isna().astype(int)\n",
    "        isna_columns.append(column)\n",
    "        \n",
    "continuous_train = continuous_train.fillna(continuous_train.median())\n",
    "continuous_test = continuous_test.fillna(continuous_test.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f0a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def categorical_encode(df_train, df_test, categorical_features, n_values=140):\n",
    "    df_train = df_train[categorical_features].astype(str)\n",
    "    df_test = df_test[categorical_features].astype(str)\n",
    "    \n",
    "    categories = []\n",
    "    for column in tqdm(categorical_features):\n",
    "        categories.append(list(df_train[column].value_counts().iloc[: n_values - 1].index) + ['Other'])\n",
    "        values2use = categories[-1]\n",
    "        df_train[column] = df_train[column].apply(lambda x: x if x in values2use else 'Other')\n",
    "        df_test[column] = df_test[column].apply(lambda x: x if x in values2use else 'Other')\n",
    "        \n",
    "    \n",
    "    ohe = OneHotEncoder(categories=categories)\n",
    "    ohe.fit(pd.concat([df_train, df_test]))\n",
    "    df_train = pd.DataFrame(ohe.transform(df_train).toarray()).astype(np.float16)\n",
    "    df_test = pd.DataFrame(ohe.transform(df_test).toarray()).astype(np.float16)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a85439",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in categorical_features:\n",
    "    print(X[feat].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff991fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categorical, test_categorical = categorical_encode(X, X_test, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#作为分隔数值和类别变量的界限，非常重要\n",
    "num_shape = continuous_train.shape[1]\n",
    "cat_shape = train_categorical.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991abacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([continuous_train, train_categorical], axis=1)\n",
    "del continuous_train, train_categorical\n",
    "X_test = pd.concat([continuous_test, test_categorical], axis=1)\n",
    "del continuous_test, test_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22610ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l2 \n",
    "def create_model():\n",
    "    num_inp = Input(shape=(num_shape,))\n",
    "    cat_inp = Input(shape=(cat_shape,))\n",
    "    inps = concatenate([num_inp, cat_inp])\n",
    "    x = Dense(128, activation=\"selu\",\\\n",
    "                kernel_initializer='lecun_normal')(inps)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dense(32, activation=custom_gelu)(x)\n",
    "    x = Dense(32, activation=custom_gelu)(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dense(128, activation='selu',kernel_initializer='lecun_normal')(x)\n",
    "    #x = Dropout(.2)(x)\n",
    "    cat_out = Dense(cat_shape, activation = \"linear\")(x)\n",
    "    num_out = Dense(num_shape, activation = \"linear\")(x)\n",
    "    model = Model(inputs=[num_inp, cat_inp], outputs=[num_out, cat_out])\n",
    "    model.compile(\n",
    "        optimizer=Adam(.05, clipnorm = 1, clipvalue = 1),\n",
    "        loss=[\"mse\", \"mse\"]\n",
    "    )\n",
    "      \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff212a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputSwapNoise(arr, p):\n",
    "    n, m = arr.shape\n",
    "    idx = range(n)\n",
    "    swap_n = round(n*p)\n",
    "    for i in range(m):\n",
    "        col_vals = np.random.permutation(arr[:, i]) # change the order of the row\n",
    "        swap_idx = np.random.choice(idx, size= swap_n) # choose row\n",
    "        arr[swap_idx, i] = np.random.choice(col_vals, size = swap_n) # n*p row and change it \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_generator(X, swap_rate, batch_size):\n",
    "    indexes = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        np.random.shuffle(indexes)\n",
    "        num_X = X[indexes[:batch_size], :num_shape] \n",
    "        num_y = inputSwapNoise(num_X, swap_rate)\n",
    "        cat_X = X[indexes[:batch_size], num_shape:] \n",
    "        cat_y = inputSwapNoise(cat_X, swap_rate)\n",
    "        yield [num_y, cat_y], [num_X, cat_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b644fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048#128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef33d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = auto_generator(X.values, .25, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe2316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_mse.fit_generator(train_gen, steps_per_epoch=len(X)//batch_size, epochs=epochs,\n",
    "                           verbose=1, workers=-1, \n",
    "                           use_multiprocessing=True,\n",
    "                              callbacks=[auto_ckpt, warm_up_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里也是\n",
    "fraud_model.fit([X_tr.iloc[:, :num_shape], X_tr.iloc[:, num_shape:]], y_tr, epochs=100,\n",
    "                batch_size=2048, \n",
    "                validation_data = ([X_val.iloc[:, :num_shape], X_val.iloc[:, num_shape:]], y_val),\n",
    "               callbacks=[ckpt], verbose = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
