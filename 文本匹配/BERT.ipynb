{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8baf67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:07:29.469053Z",
     "start_time": "2022-03-09T08:07:29.455825Z"
    }
   },
   "outputs": [],
   "source": [
    "# pgd对抗训练\n",
    "class PGD:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.emb_backup = {}\n",
    "        self.grad_backup = {}\n",
    "\n",
    "    def attack(self, epsilon=1., alpha=0.3, emb_name='word_embeddings', is_first_attack=False):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                if is_first_attack:\n",
    "                    self.emb_backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    r_at = alpha * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "                    param.data = self.project(name, param.data, epsilon)\n",
    "\n",
    "    def restore(self, emb_name='word_embeddings'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.emb_backup\n",
    "                param.data = self.emb_backup[name]\n",
    "        self.emb_backup = {}\n",
    "\n",
    "    def project(self, param_name, param_data, epsilon):\n",
    "        r = param_data - self.emb_backup[param_name]\n",
    "        if torch.norm(r) > epsilon:\n",
    "            r = epsilon * r / torch.norm(r)\n",
    "        return self.emb_backup[param_name] + r\n",
    "\n",
    "    def backup_grad(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                self.grad_backup[name] = param.grad.clone()\n",
    "\n",
    "    def restore_grad(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                param.grad = self.grad_backup[name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7028c027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:07:29.796397Z",
     "start_time": "2022-03-09T08:07:29.779670Z"
    }
   },
   "outputs": [],
   "source": [
    "# fgm对抗训练\n",
    "class FGM:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon=0.1, emb_name='word_embeddings'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        # 拿出原始的模型参数\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                print(param)\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                # 把原视的参数进行备份\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    # 计算x+r的前向loss，反向传播得到梯度，然后累加到原来的梯度上\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                print(param)\n",
    "\n",
    "    def restore(self, emb_name='word_embeddings'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96f62a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:07:35.936843Z",
     "start_time": "2022-03-09T08:07:35.924840Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据增强\n",
    "def aug_group_by_a(df):\n",
    "    aug_data = defaultdict(list)\n",
    "    # 以text_a中的句子为 a\n",
    "    for g, data in df.groupby(by=['text_a']):\n",
    "        if len(data) < 2:\n",
    "            continue\n",
    "        for i in range(len(data)):\n",
    "            for j in range(i + 1, len(data)):\n",
    "                # 取出b的值，a,b的label\n",
    "                row_i_text = data.iloc[i, 1]\n",
    "                row_i_label = data.iloc[i, 2]\n",
    "\n",
    "                # 取出c的值，a,c的label\n",
    "                row_j_text = data.iloc[j, 1]\n",
    "                row_j_label = data.iloc[j, 2]\n",
    "\n",
    "                if row_i_label == row_j_label == 0:\n",
    "                    continue\n",
    "\n",
    "                aug_label = 1 if row_i_label == row_j_label == 1 else 0\n",
    "\n",
    "                aug_data['text_a'].append(row_i_text)\n",
    "                aug_data['text_b'].append(row_j_text)\n",
    "                aug_data['label'].append(aug_label)\n",
    "    return pd.DataFrame(aug_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb5cd79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:07:44.147806Z",
     "start_time": "2022-03-09T08:07:42.361365Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizer, BertTokenizer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc1ee20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:07:48.583161Z",
     "start_time": "2022-03-09T08:07:48.576531Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # 数据加载部分\n",
    "    dataset = 'paws-x'\n",
    "    max_seq_len = 64  # 句子长度\n",
    "    need_data_aug = True  # 使用数据增强\n",
    "    # 模型部分\n",
    "    model_path = 'hfl/chinese-bert-wwm-ext'  # 本地模型路径\n",
    "    tokenizer = None  # tokenizer对象\n",
    "    load_model = False  # 是否加载已有模型预测\n",
    "    save_model = True  # 是否保存训练好的模型\n",
    "    # 训练部分\n",
    "    device = 'cpu'\n",
    "    learning_rate = 1e-5\n",
    "    batch_size = 2  # batch大小\n",
    "    epochs = 8  # 训练次数\n",
    "    print_loss = 200  # 打印loss次数\n",
    "    num_labels = 2  # 分类数\n",
    "    adv = 'fgm' # 对抗训练\n",
    "    eps = 0.1  # pgd需要的参数\n",
    "    alpha = 0.3  # 对抗模型需要的参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed3fcf82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:31:25.506928Z",
     "start_time": "2022-03-09T08:31:25.484245Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def read_data(config: Config):\n",
    "    # train = pd.read_csv('../input/qianyan-textsim/' + config.dataset + '_train.tsv', sep='\\t',\n",
    "    #                     names=['text_a', 'text_b', 'label'])\n",
    "    # dev = pd.read_csv('../input/qianyan-textsim/' + config.dataset + '_dev.tsv', sep='\\t',\n",
    "    #                   names=['text_a', 'text_b', 'label'])\n",
    "    # test = pd.read_csv('../input/qianyan-textsim/' + config.dataset + '_test.tsv', sep='\\t', names=['text_a', 'text_b'])\n",
    "    train = pd.read_csv('data/'+config.dataset+'/train.tsv', sep='\\t',\n",
    "                        names=['text_a', 'text_b', 'label'])\n",
    "    dev = pd.read_csv('data/'+config.dataset+'/dev.tsv', sep='\\t',\n",
    "                      names=['text_a', 'text_b', 'label'])\n",
    "    test = pd.read_csv('data/'+config.dataset+'/test.tsv', sep='\\t', names=['text_a', 'text_b'])\n",
    "\n",
    "    if len(set(train['label'])) > 2:\n",
    "        train = train[train['label'].isin(['0', '1'])]\n",
    "        train['label'] = train['label'].astype('int')\n",
    "    train = train.dropna()\n",
    "\n",
    "    if len(set(train['label'])) > 2:\n",
    "        dev = dev[dev['label'].isin(['0', '1'])]\n",
    "        dev['label'] = dev['label'].astype('int')\n",
    "    dev = dev.dropna()\n",
    "    test['label'] = 0\n",
    "\n",
    "    # 数据增强，加大训练集数据量\n",
    "    if config.need_data_aug is True:\n",
    "        aug_train = aug_group_by_a(train)\n",
    "        aug_dev = aug_group_by_a(dev)\n",
    "        # 拼接数据\n",
    "        train = pd.concat([train, aug_train, aug_dev])\n",
    "\n",
    "    # tokenizer\n",
    "    tokenizer = config.tokenizer\n",
    "    data_df = {'train': train, 'dev': dev, 'test': test}\n",
    "    full_data_dict = {}\n",
    "    for k, df in data_df.items():\n",
    "        inputs = defaultdict(list)\n",
    "        for i, row in tqdm(df.iterrows(), desc='encode {} data'.format(k), total=len(df)):\n",
    "            seq_a = row[0]\n",
    "            seq_b = row[1]\n",
    "            label = row[2]\n",
    "            try:\n",
    "                inputs_dict = tokenizer.encode_plus(seq_a, seq_b, add_special_tokens=True, return_token_type_ids=True,\n",
    "                                                    return_attention_mask=True)\n",
    "            except TypeError as ex:\n",
    "                print(row)\n",
    "            inputs['input_ids'].append(inputs_dict['input_ids'])\n",
    "            inputs['token_type_ids'].append(inputs_dict['token_type_ids'])\n",
    "            inputs['attention_mask'].append(inputs_dict['attention_mask'])\n",
    "            inputs['labels'].append(label)\n",
    "        full_data_dict[k] = inputs\n",
    "\n",
    "    return full_data_dict['train'], full_data_dict['dev'], full_data_dict['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17439989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:08:31.682360Z",
     "start_time": "2022-03-09T08:08:31.666483Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, data_dict):\n",
    "        super(SimDataset, self).__init__()\n",
    "        self.input_ids = data_dict['input_ids']\n",
    "        self.token_type_ids = data_dict['token_type_ids']\n",
    "        self.attention_mask = data_dict['attention_mask']\n",
    "        self.labels = data_dict['labels']\n",
    "        self.len = len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = (self.input_ids[index],\n",
    "                self.token_type_ids[index],\n",
    "                self.attention_mask[index],\n",
    "                self.labels[index])\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac532ba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:09:00.641062Z",
     "start_time": "2022-03-09T08:09:00.633060Z"
    }
   },
   "outputs": [],
   "source": [
    "# 统一处理数据\n",
    "class Collator:\n",
    "\n",
    "    def __init__(self, tokenizer, max_seq_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def pad(self, input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len):\n",
    "        # 初始化填充长度\n",
    "        input_ids = torch.zeros((len(input_ids_list), max_seq_len), dtype=torch.long)\n",
    "        token_type_ids = torch.zeros_like(input_ids)\n",
    "        attention_mask = torch.zeros_like(input_ids)\n",
    "        # 遍历获取输入\n",
    "        for i in range(len(input_ids_list)):\n",
    "            seq_len = len(input_ids_list[i])\n",
    "\n",
    "            if seq_len < max_seq_len:  # 如果小于最大长度\n",
    "                input_ids[i, :seq_len] = torch.tensor(input_ids_list[i], dtype=torch.long)\n",
    "                token_type_ids[i, :seq_len] = torch.tensor(token_type_ids_list[i], dtype=torch.long)\n",
    "                attention_mask[i, :seq_len] = torch.tensor(attention_mask_list[i], dtype=torch.long)\n",
    "            else:  # 如果大于或等于\n",
    "                # 最后一位加上tokenizer的特殊占位\n",
    "                input_ids[i] = torch.tensor(\n",
    "                    input_ids_list[i][:max_seq_len - 1] + [self.tokenizer.sep_token_id], dtype=torch.long)\n",
    "                token_type_ids[i] = torch.tensor(\n",
    "                    token_type_ids_list[i][:max_seq_len], dtype=torch.long)\n",
    "                attention_mask[i] = torch.tensor(\n",
    "                    attention_mask_list[i][:max_seq_len], dtype=torch.long)\n",
    "        # 格式化输出\n",
    "        labels = torch.tensor([[label] for label in labels_list], dtype=torch.long)\n",
    "\n",
    "        return input_ids, token_type_ids, attention_mask, labels\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        # 获取数据\n",
    "        input_ids_list, token_type_ids_list, attention_mask_list, labels_list = list(zip(*examples))\n",
    "        # 求句子最大长度\n",
    "        cur_seq_len = max([len(ids) for ids in input_ids_list])  # 当前数据最大长度\n",
    "        max_seq_len = min(cur_seq_len, self.max_seq_len)  # 最大长度\n",
    "        # 填充句子\n",
    "        input_ids, token_type_ids, attention_mask, labels = self.pad(input_ids_list, token_type_ids_list,\n",
    "                                                                     attention_mask_list, labels_list, max_seq_len)\n",
    "        # 返回结果\n",
    "        data = {\n",
    "            'input_ids': input_ids,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels,\n",
    "        }\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e6caf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:08:58.739239Z",
     "start_time": "2022-03-09T08:08:58.728084Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataloader(config: Config):\n",
    "    # 读取数据\n",
    "    train, dev, test = read_data(config)\n",
    "    # 构建dataset\n",
    "    train_dataset = SimDataset(train)\n",
    "    dev_dataset = SimDataset(dev)\n",
    "    test_dataset = SimDataset(test)\n",
    "    # 构建dataloader\n",
    "    collate_fn = Collator(config.tokenizer, config.max_seq_len)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, collate_fn=collate_fn, shuffle=True,\n",
    "                                  num_workers=0)\n",
    "    dev_dataloader = DataLoader(dev_dataset, batch_size=config.batch_size, collate_fn=collate_fn, shuffle=True,\n",
    "                                num_workers=0)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=config.batch_size, collate_fn=collate_fn, shuffle=False,\n",
    "                                 num_workers=0)\n",
    "    return train_dataloader, dev_dataloader, test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21691af7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:10:24.470700Z",
     "start_time": "2022-03-09T08:10:18.999865Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoModelForSequenceClassification, BertForNextSentencePrediction, AdamW\n",
    "from sklearn.metrics import f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1f3b48b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:10:28.623431Z",
     "start_time": "2022-03-09T08:10:28.604953Z"
    }
   },
   "outputs": [],
   "source": [
    "# 校验\n",
    "def evaluation(config, model, val_dataloader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    val_loss = 0.\n",
    "    # val_iterator = tqdm(val_dataloader, desc='Evaluation', total=len(val_dataloader))\n",
    "    with torch.no_grad():\n",
    "        for mini_batch in val_dataloader:\n",
    "            batch_cuda = {item: value.to(config.device) for item, value in mini_batch.items()}\n",
    "            labels += batch_cuda['labels'].view(-1)\n",
    "            # 获取数据\n",
    "            result = model(**batch_cuda)\n",
    "            loss = result[0]\n",
    "            logits = result[1]\n",
    "            # 返回逻辑值最大的位置，要么0，要么1\n",
    "            _, indices = torch.max(logits, dim=1)\n",
    "            preds += indices\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    labels = torch.tensor(labels).numpy()\n",
    "    preds = torch.tensor(preds).numpy()\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    # -----------new ----------------#\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    # -----------new ----------------#\n",
    "    return avg_val_loss, f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "173b4372",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:10:35.783785Z",
     "start_time": "2022-03-09T08:10:35.777946Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(config, model, test_dataloader):\n",
    "    predict_labels = []\n",
    "    # 创建dataloader\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for mini_batch in test_dataloader:\n",
    "            batch_cuda = {item: value.to(config.device) for item, value in mini_batch.items()}\n",
    "            # 获取数据\n",
    "            result = model(**batch_cuda)\n",
    "            logits = result[1]\n",
    "            _, indices = torch.max(logits, dim=1)\n",
    "            predict_labels += indices\n",
    "    return torch.tensor(predict_labels).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daa1b3c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T09:31:53.303430Z",
     "start_time": "2022-03-09T09:31:53.274720Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(config: Config, train_dataloader: DataLoader, dev_dataloader: DataLoader):\n",
    "    # 创建模型\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(config.model_path, num_labels=config.num_labels)\n",
    "    # model = BertForNextSentencePrediction.from_pretrained('bert-base-chinese')\n",
    "\n",
    "    model.to(config.device)\n",
    "    # 定义优化器\n",
    "    opt = AdamW(lr=config.learning_rate, params=model.parameters())\n",
    "    # 定义损失函数\n",
    "    loss_fn = nn.CrossEntropyLoss()  # 遍历epoch，开始训练\n",
    "\n",
    "#     # 初始化对抗训练的参数\n",
    "#     if config.adv == 'fgm':\n",
    "#         fgm = FGM(model)\n",
    "#     else:\n",
    "#         pgd = PGD(model)\n",
    "#         K = 3\n",
    "\n",
    "\n",
    "    # 遍历训练次数训练\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        for iter_id, mini_batch in enumerate(train_dataloader):\n",
    "            batch_cuda = {item: value.to(config.device) for item, value in mini_batch.items()}\n",
    "\n",
    "            result = model(**batch_cuda)\n",
    "            loss = result[0]\n",
    "            logits = result[1]\n",
    "\n",
    "            _, indices = torch.max(logits, dim=1)\n",
    "            correct = torch.sum(indices == batch_cuda['labels'].view(-1))\n",
    "\n",
    "            # 初始化梯度为0\n",
    "            model.zero_grad()\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "#             #------------------ 对抗训练 ------------------#\n",
    "#             if config.adv == 'fgm':\n",
    "#                 # 计算x+r的前向loss, 反向传播得到梯度，然后累加到(1)的梯度上；\n",
    "#                 fgm.attack(epsilon=config.eps)\n",
    "#                 # 计算x+r的前向loss\n",
    "#                 loss_adv = model(**batch_cuda)[0]\n",
    "#                 # 反向传播得到梯度，然后累加到(1)的梯度上；\n",
    "#                 loss_adv.backward()\n",
    "#                 # 将embedding恢复为（1）时的embedding；\n",
    "#                 fgm.restore()\n",
    "#             elif config.adv == 'pgd':\n",
    "#                 pgd.backup_grad()\n",
    "#                 for t in range(K):\n",
    "#                     # 根据embedding矩阵计算的梯度计算出r, 并加到当前embedding上，相当于x + r\n",
    "#                     pgd.attack(epsilon=config.eps, alpha=config.alpha, is_first_attack=(t == 0))\n",
    "#                     if t != K - 1:\n",
    "#                         # t如果不是最后一步，将梯度归0， 根据2的x + r计算前后向并得到梯度\n",
    "#                         model.zero_grad()\n",
    "#                     else:\n",
    "#                         # t是最后一步，恢复1的梯度，计算最后的x + r并将梯度累加到(1)\n",
    "#                         pgd.restore_grad()\n",
    "#                     loss_adv = model(**batch_cuda)[0]\n",
    "#                     loss_adv.backward()\n",
    "#                 #将embedding恢复\n",
    "#                 pgd.restore()\n",
    "\n",
    "#             # ------------------ 对抗训练 ------------------#\n",
    "\n",
    "            # 更新参数\n",
    "            opt.step()\n",
    "            # 打印模型性能\n",
    "            if iter_id % config.print_loss == 0:\n",
    "                print('epoch:{}, iter_id:{}, loss:{}, acc:{}'.format(epoch, iter_id, loss,\n",
    "                                                                     correct.item() * 1.0 / len(batch_cuda['labels'])))\n",
    "        # 运行完一个epoch验证机校验\n",
    "        avg_val_loss, f1, acc = evaluation(config, model, dev_dataloader)\n",
    "        print('-' * 50)\n",
    "        print('epoch: {}, val_loss: {}, val_f1: {}, val_acc: {}'.format(epoch, avg_val_loss, f1, acc))\n",
    "        print('-' * 50)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7535dcdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:28:38.623921Z",
     "start_time": "2022-03-09T08:28:38.613062Z"
    }
   },
   "outputs": [],
   "source": [
    "conf = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "995c9857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:11:11.844201Z",
     "start_time": "2022-03-09T08:11:11.834198Z"
    }
   },
   "outputs": [],
   "source": [
    "data_list = ['paws-x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9d441a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T09:55:39.737723Z",
     "start_time": "2022-03-09T09:32:00.299061Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode train data: 100%|███████████████████████████████████████████████████████| 69513/69513 [00:16<00:00, 4193.07it/s]\n",
      "encode dev data: 100%|███████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 4150.42it/s]\n",
      "encode test data: 100%|██████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 4245.35it/s]\n",
      "Some weights of the model checkpoint at hfl/chinese-bert-wwm-ext were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-bert-wwm-ext and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, iter_id:0, loss:0.5014705657958984, acc:1.0\n",
      "epoch:0, iter_id:200, loss:0.73826003074646, acc:0.5\n",
      "epoch:0, iter_id:400, loss:0.908128559589386, acc:0.5\n",
      "epoch:0, iter_id:600, loss:0.5132473707199097, acc:1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-c580ac2be234>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# 训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m# 推理模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpredict_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-4980c1d6de13>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config, train_dataloader, dev_dataloader)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mbatch_cuda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1545\u001b[1;33m         outputs = self.bert(\n\u001b[0m\u001b[0;32m   1546\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    994\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m         )\n\u001b[1;32m--> 996\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    583\u001b[0m                 )\n\u001b[0;32m    584\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    586\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    511\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[0;32m    514\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m   2368\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2370\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for data in data_list:\n",
    "    conf = Config()\n",
    "    conf.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    conf.dataset = data\n",
    "\n",
    "    conf.tokenizer = AutoTokenizer.from_pretrained(conf.model_path)\n",
    "    # 读取数据\n",
    "    train_dataloader, dev_dataloader, test_dataloader = create_dataloader(conf)\n",
    "    # 训练\n",
    "    model = train(conf, train_dataloader, dev_dataloader)\n",
    "    # 推理模型\n",
    "    predict_labels = predict(conf, model, test_dataloader)\n",
    "    # 保存结果\n",
    "    test_df = pd.DataFrame(predict_labels, columns=['prediction'])\n",
    "    test_df['index'] = test_df.index\n",
    "    print(test_df)\n",
    "    test_df.to_csv(conf.dataset + '.tsv', index=False, columns=['index', 'prediction'], sep='\\t')\n",
    "    print('保存结果成功')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909c6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
