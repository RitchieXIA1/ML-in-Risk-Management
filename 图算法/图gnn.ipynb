{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5075d496-6945-4560-9373-d46fc0277c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from typing import Optional, Callable, List, Union\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.nn import SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c8432ddc-d710-4ba9-b7af-86b5ce05a74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/featurize/work/whl\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bce2df3-6f6b-416c-b16c-e1a7339f28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从npz文件里挨个读出需要的数据\n",
    "def read_xygraphp1(folder):\n",
    "    print('read_xygraphp1')\n",
    "    names = ['phase1_gdata.npz']\n",
    "    items = [np.load(folder+'/'+name) for name in names]\n",
    "    \n",
    "    x = items[0]['x']\n",
    "    y = items[0]['y'].reshape(-1,1)\n",
    "    edge_index = items[0]['edge_index']\n",
    "    edge_type = items[0]['edge_type']\n",
    "    np.random.seed(42)\n",
    "    train_mask_t = items[0]['train_mask']\n",
    "    np.random.shuffle(train_mask_t)\n",
    "    train_mask = train_mask_t[:int(len(train_mask_t)/10*6)]\n",
    "    valid_mask = train_mask_t[int(len(train_mask_t)/10*6):]\n",
    "    test_mask = items[0]['test_mask']\n",
    "\n",
    "    x = torch.tensor(x, dtype=torch.float).contiguous()\n",
    "    y = torch.tensor(y, dtype=torch.int64)\n",
    "    #边的index 必须要转置并且转化为连续型\n",
    "    edge_index = torch.tensor(edge_index.transpose(), dtype=torch.int64).contiguous()\n",
    "    edge_type = torch.tensor(edge_type, dtype=torch.float)\n",
    "    train_mask = torch.tensor(train_mask, dtype=torch.int64)\n",
    "    valid_mask = torch.tensor(valid_mask, dtype=torch.int64)\n",
    "    test_mask = torch.tensor(test_mask, dtype=torch.int64)\n",
    "    #非常重要 在pyg里必须要要转化为这样的图格式\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_type, y=y)\n",
    "    data.train_mask = train_mask\n",
    "    data.valid_mask = valid_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    return data\n",
    "\n",
    "class XYGraphP1(InMemoryDataset):\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "        root (string): Root directory where the dataset should be saved.\n",
    "        name (string): The name of the dataset (:obj:`\"xygraphp1\"`).\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    #如果有下载需求\n",
    "    url = ''\n",
    "\n",
    "    def __init__(self, root: str, name: str, \n",
    "                 transform: Optional[Callable] = None,\n",
    "                 pre_transform: Optional[Callable] = None):\n",
    "        \n",
    "        self.name = name\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self) -> str:\n",
    "        return osp.join(self.root, self.name, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self) -> str:\n",
    "        return osp.join(self.root, self.name, 'processed')\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        names = ['phase1_gdata.npz']\n",
    "        return names\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "#         for name in self.raw_file_names:\n",
    "#             download_url('{}/{}'.format(self.url, name), self.raw_dir)\n",
    "\n",
    "    def process(self):\n",
    "        data = read_xygraphp1(self.raw_dir)\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.name}()'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c975c5-0d09-4ada-901b-75400043b70c",
   "metadata": {},
   "source": [
    "用于建立文件夹，按（数据集，模型）的格式填写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7810d894-c99b-4d74-8160-cf3d177f8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_folder(name, model_name):\n",
    "    model_dir = f'./model_files/{name}/{model_name}/'\n",
    "   \n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n",
    "    os.makedirs(model_dir)\n",
    "    return model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d10ea85b-48e2-4657-814b-8c5726d8bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "class Evaluator:\n",
    "    def __init__(self, eval_metric):\n",
    "        if eval_metric not in ['acc', 'auc']:\n",
    "            raise ValueError('eval_metric should be acc or auc')\n",
    "            \n",
    "        self.eval_metric = eval_metric\n",
    "\n",
    "    def _check_input(self, y_true, y_pred):\n",
    "        '''\n",
    "            y_true: numpy ndarray or torch tensor of shape (num_node)\n",
    "            y_pred: numpy ndarray or torch tensor of shape (num_node, num_tasks)\n",
    "        '''\n",
    "\n",
    "        # converting to torch.Tensor to numpy on cpu\n",
    "        if torch is not None and isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.detach().cpu().numpy()\n",
    "\n",
    "        if torch is not None and isinstance(y_pred, torch.Tensor):\n",
    "            y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "        ## check type\n",
    "        if not (isinstance(y_true, np.ndarray) and isinstance(y_true, np.ndarray)):\n",
    "            raise RuntimeError('Arguments to Evaluator need to be either numpy ndarray or torch tensor')\n",
    "\n",
    "        if not y_pred.ndim == 2:\n",
    "            raise RuntimeError('y_pred must to 2-dim arrray, {}-dim array given'.format(y_true.ndim))\n",
    "\n",
    "        return y_true, y_pred\n",
    "\n",
    "    def eval(self, y_true, y_pred):\n",
    "        if self.eval_metric == 'auc':\n",
    "            y_true, y_pred = self._check_input(y_true, y_pred)\n",
    "            return self._eval_rocauc(y_true, y_pred)\n",
    "        if self.eval_metric == 'acc':\n",
    "            y_true, y_pred = self._check_input(y_true, y_pred)\n",
    "            return self._eval_acc(y_true, y_pred)\n",
    "\n",
    "\n",
    "    def _eval_rocauc(self, y_true, y_pred):\n",
    "        '''\n",
    "            compute ROC-AUC and AP score averaged across tasks\n",
    "        '''\n",
    "        \n",
    "        if y_pred.shape[1] ==2:\n",
    "            auc = roc_auc_score(y_true, y_pred[:, 1])\n",
    "        else:\n",
    "            onehot_code = np.eye(y_pred.shape[1])\n",
    "            y_true_onehot = onehot_code[y_true]\n",
    "            auc = roc_auc_score(y_true_onehot, y_pred)\n",
    "\n",
    "        return {'auc': auc}\n",
    "\n",
    "    def _eval_acc(self, y_true, y_pred):\n",
    "        y_pred = y_pred.argmax(axis=-1)\n",
    "\n",
    "        correct = y_true == y_pred\n",
    "        acc = float(np.sum(correct))/len(correct)\n",
    "\n",
    "        return {'acc': acc}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca566b4-54f4-4961-8b6b-9f274fee0296",
   "metadata": {},
   "source": [
    "简简单单一个MLP和SAGE做对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "963ab56e-21a1-4f63-b697-6d1613902322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns = torch.nn.ModuleList()\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):    \n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            if self.batchnorm:\n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "    \n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index: Union[Tensor, SparseTensor]):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            if self.batchnorm: \n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x.log_softmax(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c418539c-bd69-4b5c-be36-eefff2eb7fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer, no_conv=False):\n",
    "    # data.y is labels of shape (N, ) \n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    if no_conv:\n",
    "        out = model(data.x[train_idx])\n",
    "    else:\n",
    "        out = model(data.x, data.adj_t)[train_idx]\n",
    "    #因为是softmax 用 nullloss进行反向传播\n",
    "    loss = F.nll_loss(out, data.y[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, no_conv=False):\n",
    "    # data.y is labels of shape (N, )\n",
    "    model.eval()\n",
    "    \n",
    "    if no_conv:\n",
    "        out = model(data.x)\n",
    "    else:\n",
    "        out = model(data.x, data.adj_t)\n",
    "        \n",
    "    y_pred = out.exp()  # (N,num_classes)\n",
    "    \n",
    "    losses = dict()\n",
    "    for key in ['train', 'valid', 'test']:\n",
    "        node_id = split_idx[key]\n",
    "        losses[key] = F.nll_loss(out[node_id], data.y[node_id]).item()\n",
    "            \n",
    "    return losses, y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b063fe37-129d-4e1c-9f58-741cdb5e0ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='gnn_models')\n",
    "parser.add_argument('--device', type=int, default=0)\n",
    "parser.add_argument('--dataset', type=str, default='XYGraphP1')\n",
    "parser.add_argument('--log_steps', type=int, default=10)\n",
    "parser.add_argument('--model', type=str, default='mlp')\n",
    "parser.add_argument('--epochs', type=int, default=200)\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b3d6130-d74c-45a3-b03e-bfa2fbb3220c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ad4038-f02d-4661-bf84-9f1dca0420d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = XYGraphP1(root='./data/', name='xydata', transform=T.ToSparseTensor())\n",
    "nlabels = dataset.num_classes\n",
    "if args.dataset in ['XYGraphP1']: nlabels = 2\n",
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebfead5e-5582-43f9-b80f-8356968a84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset in ['XYGraphP1']:\n",
    "    x = data.x\n",
    "    x = (x-x.mean(0))/x.std(0)\n",
    "    data.x = x\n",
    "if data.y.dim() == 2:\n",
    "    data.y = data.y.squeeze(1)\n",
    "split_idx = {'train': data.train_mask, 'valid': data.valid_mask, 'test': data.test_mask}\n",
    "data = data.to(device)\n",
    "train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5efc4a73-ce3f-4c62-9ae5-9c1cc45d1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_parameters = {'lr':0.01\n",
    "              , 'num_layers':3\n",
    "              , 'hidden_channels':128\n",
    "              , 'dropout':0.15\n",
    "              , 'batchnorm': True\n",
    "              , 'l2':5e-7\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c34c5aaf-7f98-4844-b884-76a7ed0311bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mlp initialized\n",
      "19586\n"
     ]
    }
   ],
   "source": [
    "if args.model == 'mlp':\n",
    "    para_dict = mlp_parameters\n",
    "    model_para = mlp_parameters.copy()\n",
    "    model_para.pop('lr')\n",
    "    model_para.pop('l2')\n",
    "    model = MLP(in_channels = data.x.size(-1), out_channels = nlabels, **model_para).to(device)\n",
    "print(f'Model {args.model} initialized')\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['l2'])\n",
    "min_valid_loss = 1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9e77b0d3-603d-4638-a168-6f0dd8cfac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_conv = False\n",
    "if args.model in ['mlp']: no_conv = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "352961e5-976c-49a1-8470-569a648efec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = prepare_folder(args.dataset, args.model)\n",
    "print('model_dir:', model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "77127a72-f2f7-4a90-89a8-f98d5cb5c52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.0655, Train: 6.797%, Valid: 6.960% Test: 0.000%\n",
      "Epoch: 20, Loss: 0.0627, Train: 6.657%, Valid: 6.850% Test: 0.000%\n",
      "Epoch: 30, Loss: 0.0613, Train: 6.106%, Valid: 6.324% Test: 0.000%\n",
      "Epoch: 40, Loss: 0.0608, Train: 5.985%, Valid: 6.181% Test: 0.000%\n",
      "Epoch: 50, Loss: 0.0606, Train: 5.974%, Valid: 6.169% Test: 0.000%\n",
      "Epoch: 60, Loss: 0.0603, Train: 5.961%, Valid: 6.149% Test: 0.000%\n",
      "Epoch: 70, Loss: 0.0602, Train: 5.951%, Valid: 6.135% Test: 0.000%\n",
      "Epoch: 80, Loss: 0.0600, Train: 5.943%, Valid: 6.124% Test: 0.000%\n",
      "Epoch: 90, Loss: 0.0600, Train: 5.934%, Valid: 6.113% Test: 0.000%\n",
      "Epoch: 100, Loss: 0.0599, Train: 5.926%, Valid: 6.103% Test: 0.000%\n",
      "Epoch: 110, Loss: 0.0597, Train: 5.919%, Valid: 6.094% Test: 0.000%\n",
      "Epoch: 120, Loss: 0.0597, Train: 5.915%, Valid: 6.089% Test: 0.000%\n",
      "Epoch: 130, Loss: 0.0597, Train: 5.908%, Valid: 6.082% Test: 0.000%\n",
      "Epoch: 140, Loss: 0.0596, Train: 5.904%, Valid: 6.078% Test: 0.000%\n",
      "Epoch: 150, Loss: 0.0596, Train: 5.900%, Valid: 6.074% Test: 0.000%\n",
      "Epoch: 160, Loss: 0.0595, Train: 5.898%, Valid: 6.070% Test: 0.000%\n",
      "Epoch: 170, Loss: 0.0595, Train: 5.894%, Valid: 6.068% Test: 0.000%\n",
      "Epoch: 180, Loss: 0.0594, Train: 5.892%, Valid: 6.065% Test: 0.000%\n",
      "Epoch: 190, Loss: 0.0594, Train: 5.891%, Valid: 6.063% Test: 0.000%\n",
      "Epoch: 200, Loss: 0.0594, Train: 5.889%, Valid: 6.062% Test: 0.000%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs+1):\n",
    "    loss = train(model, data, train_idx, optimizer, no_conv)\n",
    "    losses, out = test(model, data, split_idx, no_conv)\n",
    "    train_loss, valid_loss, test_loss = losses['train'], losses['valid'], losses['test']\n",
    "\n",
    "    if valid_loss < min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_dir+'model.pt')\n",
    "\n",
    "    if epoch % args.log_steps == 0:\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "                    f'Loss: {loss:.4f}, '\n",
    "                    f'Train: {100 * train_loss:.3f}%, '\n",
    "                    f'Valid: {100 * valid_loss:.3f}% '\n",
    "                    f'Test: {100 * test_loss:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7adcadfd-1032-415c-a61e-c37e5d6a7d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_file: ./model_files/XYGraphP1/mlp/model.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = './model_files/{}/{}/model.pt'.format(args.dataset, args.model)\n",
    "print('model_file:', model_file)\n",
    "model.load_state_dict(torch.load(model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c93608d5-0ade-42f0-aab2-ae7b098b98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, data, no_conv=False):\n",
    "    # data.y is labels of shape (N, )\n",
    "    model.eval()\n",
    "    \n",
    "    if no_conv:\n",
    "        out = model(data.x)\n",
    "    else:\n",
    "        out = model(data.x, data.adj_t)\n",
    "        \n",
    "    y_pred = out.exp()  # (N,num_classes)\n",
    "                \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5e9cff21-b411-47e6-a5ad-0f3b71c5d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = test(model, data, no_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "21a5ea8d-a073-4612-8509-0490aa980eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train, preds_valid = out[data.train_mask], out[data.valid_mask]\n",
    "y_train, y_valid = data.y[data.train_mask], data.y[data.valid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "70f0255e-0079-4d86-a7cb-74f892c048ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_auc: 0.7373539001379924\n",
      "valid_auc: 0.7363658261568118\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator('auc')\n",
    "train_auc = evaluator.eval(y_train, preds_train)['auc']\n",
    "valid_auc = evaluator.eval(y_valid, preds_valid)['auc']\n",
    "print('train_auc:',train_auc)\n",
    "print('valid_auc:',valid_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df5d7c-d430-47cc-bacd-102edd457d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = out[data.test_mask].cpu().numpy()\n",
    "np.save('./submit/preds.npy', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bcab874-f2d9-4f41-9fed-b53b128d6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index: Union[Tensor, SparseTensor]):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            if self.batchnorm: \n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x.log_softmax(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d431292-d368-408b-bed1-d2e41dc37ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_parameters = {'lr':0.01\n",
    "              , 'num_layers':2\n",
    "              , 'hidden_channels':128\n",
    "              , 'dropout':0.1\n",
    "              , 'batchnorm': False\n",
    "              , 'l2':5e-7\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8b515d4-b70b-4dec-9303-6de45bd58785",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model='sage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c32c496-7320-478e-898d-00b5a61cc76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model == 'sage':        \n",
    "    para_dict = sage_parameters\n",
    "    model_para = sage_parameters.copy()\n",
    "    model_para.pop('lr')\n",
    "    model_para.pop('l2')        \n",
    "    model = SAGE(in_channels = data.x.size(-1), out_channels = nlabels, **model_para).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5df421a7-efed-4fc8-8a18-695245217e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sage initialized\n",
      "4994\n"
     ]
    }
   ],
   "source": [
    "print(f'Model {args.model} initialized')\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['l2'])\n",
    "min_valid_loss = 1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f84fd498-3e7f-44cc-9a3e-86441d245b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_dir: ./model_files/XYGraphP1/sage/\n"
     ]
    }
   ],
   "source": [
    "no_conv = False\n",
    "if args.model in ['mlp']: no_conv = True \n",
    "model_dir = prepare_folder(args.dataset, args.model)\n",
    "print('model_dir:', model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a11c9ec5-f368-4ca2-b453-b08995b85ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.1176, Train: 11.729%, Valid: 12.032% Test: 0.000%\n",
      "Epoch: 20, Loss: 0.0814, Train: 7.728%, Valid: 7.895% Test: 0.000%\n",
      "Epoch: 30, Loss: 0.0668, Train: 6.548%, Valid: 6.673% Test: 0.000%\n",
      "Epoch: 40, Loss: 0.0626, Train: 6.208%, Valid: 6.356% Test: 0.000%\n",
      "Epoch: 50, Loss: 0.0606, Train: 6.022%, Valid: 6.167% Test: 0.000%\n",
      "Epoch: 60, Loss: 0.0599, Train: 5.954%, Valid: 6.114% Test: 0.000%\n",
      "Epoch: 70, Loss: 0.0594, Train: 5.912%, Valid: 6.070% Test: 0.000%\n",
      "Epoch: 80, Loss: 0.0591, Train: 5.882%, Valid: 6.044% Test: 0.000%\n",
      "Epoch: 90, Loss: 0.0589, Train: 5.860%, Valid: 6.021% Test: 0.000%\n",
      "Epoch: 100, Loss: 0.0587, Train: 5.842%, Valid: 6.004% Test: 0.000%\n",
      "Epoch: 110, Loss: 0.0585, Train: 5.828%, Valid: 5.988% Test: 0.000%\n",
      "Epoch: 120, Loss: 0.0585, Train: 5.817%, Valid: 5.977% Test: 0.000%\n",
      "Epoch: 130, Loss: 0.0583, Train: 5.806%, Valid: 5.966% Test: 0.000%\n",
      "Epoch: 140, Loss: 0.0582, Train: 5.798%, Valid: 5.956% Test: 0.000%\n",
      "Epoch: 150, Loss: 0.0581, Train: 5.790%, Valid: 5.948% Test: 0.000%\n",
      "Epoch: 160, Loss: 0.0581, Train: 5.783%, Valid: 5.941% Test: 0.000%\n",
      "Epoch: 170, Loss: 0.0581, Train: 5.777%, Valid: 5.935% Test: 0.000%\n",
      "Epoch: 180, Loss: 0.0580, Train: 5.772%, Valid: 5.930% Test: 0.000%\n",
      "Epoch: 190, Loss: 0.0580, Train: 5.767%, Valid: 5.926% Test: 0.000%\n",
      "Epoch: 200, Loss: 0.0579, Train: 5.763%, Valid: 5.922% Test: 0.000%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs+1):\n",
    "    loss = train(model, data, train_idx, optimizer, no_conv)\n",
    "    losses, out = test(model, data, split_idx, no_conv)\n",
    "    train_loss, valid_loss, test_loss = losses['train'], losses['valid'], losses['test']\n",
    "\n",
    "    if valid_loss < min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_dir+'model.pt')\n",
    "\n",
    "    if epoch % args.log_steps == 0:\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "                    f'Loss: {loss:.4f}, '\n",
    "                    f'Train: {100 * train_loss:.3f}%, '\n",
    "                    f'Valid: {100 * valid_loss:.3f}% '\n",
    "                    f'Test: {100 * test_loss:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57bfbd0d-75e7-4b98-a279-389018d93ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_file: ./model_files/XYGraphP1/sage/model.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = './model_files/{}/{}/model.pt'.format(args.dataset, args.model)\n",
    "print('model_file:', model_file)\n",
    "model.load_state_dict(torch.load(model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b6de3e8-0cf6-4809-98c9-7a8a96d53c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, data, no_conv=False):\n",
    "    # data.y is labels of shape (N, )\n",
    "    model.eval()\n",
    "    \n",
    "    if no_conv:\n",
    "        out = model(data.x)\n",
    "    else:\n",
    "        out = model(data.x, data.adj_t)\n",
    "        \n",
    "    y_pred = out.exp()  # (N,num_classes)\n",
    "                \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "865e7f69-f237-461a-922c-0da7078f5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = test(model, data, no_conv)\n",
    "preds_train, preds_valid = out[data.train_mask], out[data.valid_mask]\n",
    "y_train, y_valid = data.y[data.train_mask], data.y[data.valid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e47e0b28-a9b3-461c-bac0-d2eb85d0f40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_auc: 0.7727542935825387\n",
      "valid_auc: 0.7719490989150097\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator('auc')\n",
    "train_auc = evaluator.eval(y_train, preds_train)['auc']\n",
    "valid_auc = evaluator.eval(y_valid, preds_valid)['auc']\n",
    "print('train_auc:',train_auc)\n",
    "print('valid_auc:',valid_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c360d1-95b9-4c1b-abc4-ce0f4211caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = out[data.test_mask].cpu().numpy()\n",
    "np.save('./submit/preds.npy', preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alas",
   "language": "python",
   "name": "alas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
