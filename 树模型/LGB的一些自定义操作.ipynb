{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00a32dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T03:15:33.927672Z",
     "start_time": "2022-01-19T03:15:31.489680Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('https://cdn.coggle.club/LightGBM/examples/binary_classification/binary.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv('https://cdn.coggle.club/LightGBM/examples/binary_classification/binary.test', header=None, sep='\\t')\n",
    "W_train = pd.read_csv('https://cdn.coggle.club/LightGBM/examples/binary_classification/binary.train.weight', header=None)[0]\n",
    "W_test = pd.read_csv('https://cdn.coggle.club/LightGBM/examples/binary_classification/binary.test.weight', header=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5baab102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T03:15:46.139348Z",
     "start_time": "2022-01-19T03:15:46.126345Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = df_train[0]\n",
    "y_test = df_test[0]\n",
    "X_train = df_train.drop(0, axis=1)\n",
    "X_test = df_test.drop(0, axis=1)\n",
    "num_train, num_feature = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4049a3e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T03:15:55.451869Z",
     "start_time": "2022-01-19T03:15:55.433861Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dataset for lightgbm\n",
    "# if you want to re-use data, remember to set free_raw_data=False\n",
    " \n",
    "lgb_train = lgb.Dataset(X_train, y_train,\n",
    "                        weight=W_train, free_raw_data=False)\n",
    " \n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,\n",
    "                       weight=W_test, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "179bbe52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T03:16:01.473402Z",
     "start_time": "2022-01-19T03:16:01.429393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[1]\ttraining's binary_logloss: 0.682311\n",
      "[2]\ttraining's binary_logloss: 0.674204\n",
      "[3]\ttraining's binary_logloss: 0.664662\n",
      "[4]\ttraining's binary_logloss: 0.655524\n",
      "[5]\ttraining's binary_logloss: 0.648385\n",
      "[6]\ttraining's binary_logloss: 0.64227\n",
      "[7]\ttraining's binary_logloss: 0.63507\n",
      "[8]\ttraining's binary_logloss: 0.628378\n",
      "[9]\ttraining's binary_logloss: 0.621862\n",
      "[10]\ttraining's binary_logloss: 0.615907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [21]\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    " \n",
    "# generate feature names\n",
    "feature_name = ['feature_' + str(col) for col in range(num_feature)]\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                valid_sets=lgb_train,  # eval training data\n",
    "                feature_name=feature_name,\n",
    "                categorical_feature=[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69b55b36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T03:18:31.401115Z",
     "start_time": "2022-01-19T03:18:31.357107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping model to JSON...\n"
     ]
    }
   ],
   "source": [
    "# save model to file\n",
    "gbm.save_model('model.txt')\n",
    " \n",
    "print('Dumping model to JSON...')\n",
    "model_json = gbm.dump_model()\n",
    " \n",
    "with open('model.json', 'w+') as f:\n",
    "    json.dump(model_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "005fe824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T03:52:54.769106Z",
     "start_time": "2022-01-19T03:52:54.761104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27']\n",
      "Feature importances: [7, 1, 1, 21, 5, 30, 2, 1, 1, 18, 7, 0, 1, 8, 2, 1, 0, 7, 3, 3, 0, 0, 36, 5, 32, 52, 28, 28]\n"
     ]
    }
   ],
   "source": [
    "# feature names\n",
    "print('Feature names:', gbm.feature_name())\n",
    " \n",
    "# feature importances\n",
    "print('Feature importances:', list(gbm.feature_importance()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d03e52d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T03:53:09.117811Z",
     "start_time": "2022-01-19T03:53:09.071801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[11]\tvalid_0's binary_logloss: 0.615668\n",
      "[12]\tvalid_0's binary_logloss: 0.61131\n",
      "[13]\tvalid_0's binary_logloss: 0.607092\n",
      "[14]\tvalid_0's binary_logloss: 0.603532\n",
      "[15]\tvalid_0's binary_logloss: 0.600335\n",
      "[16]\tvalid_0's binary_logloss: 0.596209\n",
      "[17]\tvalid_0's binary_logloss: 0.592408\n",
      "[18]\tvalid_0's binary_logloss: 0.588936\n",
      "[19]\tvalid_0's binary_logloss: 0.585849\n",
      "[20]\tvalid_0's binary_logloss: 0.582769\n",
      "Finished 10 - 20 rounds with model file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [21]\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    }
   ],
   "source": [
    "# continue training\n",
    "# init_model accepts:\n",
    "# 1. model file name\n",
    "# 2. Booster()\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                init_model='model.txt',\n",
    "                valid_sets=lgb_eval)\n",
    "print('Finished 10 - 20 rounds with model file...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73ddd081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T03:53:50.907591Z",
     "start_time": "2022-01-19T03:53:50.870583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[41]\tvalid_0's binary_logloss: 0.547133\n",
      "[42]\tvalid_0's binary_logloss: 0.545865\n",
      "[43]\tvalid_0's binary_logloss: 0.545081\n",
      "[44]\tvalid_0's binary_logloss: 0.544072\n",
      "[45]\tvalid_0's binary_logloss: 0.542853\n",
      "[46]\tvalid_0's binary_logloss: 0.541275\n",
      "[47]\tvalid_0's binary_logloss: 0.540361\n",
      "[48]\tvalid_0's binary_logloss: 0.53926\n",
      "[49]\tvalid_0's binary_logloss: 0.538636\n",
      "[50]\tvalid_0's binary_logloss: 0.537447\n",
      "Finished 20 - 30 rounds with decay learning rates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# decay learning rates\n",
    "# learning_rates accepts:\n",
    "# 1. list/tuple with length = num_boost_round\n",
    "# 2. function(curr_iter)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                init_model=gbm,\n",
    "                learning_rates=lambda iter: 0.05 * (0.99 ** iter),\n",
    "                valid_sets=lgb_eval)\n",
    "print('Finished 20 - 30 rounds with decay learning rates...')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25b59735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T03:53:56.198054Z",
     "start_time": "2022-01-19T03:53:56.160046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[51]\tvalid_0's binary_logloss: 0.536715\n",
      "[52]\tvalid_0's binary_logloss: 0.536008\n",
      "[53]\tvalid_0's binary_logloss: 0.535634\n",
      "[54]\tvalid_0's binary_logloss: 0.534715\n",
      "[55]\tvalid_0's binary_logloss: 0.533922\n",
      "[56]\tvalid_0's binary_logloss: 0.533792\n",
      "[57]\tvalid_0's binary_logloss: 0.532749\n",
      "[58]\tvalid_0's binary_logloss: 0.53161\n",
      "[59]\tvalid_0's binary_logloss: 0.530396\n",
      "[60]\tvalid_0's binary_logloss: 0.52909\n",
      "Finished 30 - 40 rounds with changing bagging_fraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "# change other parameters during training\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                init_model=gbm,\n",
    "                valid_sets=lgb_eval,\n",
    "                callbacks=[lgb.reset_parameter(bagging_fraction=[0.7] * 5 + [0.6] * 5)])\n",
    "print('Finished 30 - 40 rounds with changing bagging_fraction...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96333dbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T03:54:14.462319Z",
     "start_time": "2022-01-19T03:54:14.414205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[61]\tvalid_0's binary_logloss: 5.3439\tvalid_0's error: 0.264\n",
      "[62]\tvalid_0's binary_logloss: 5.3365\tvalid_0's error: 0.262\n",
      "[63]\tvalid_0's binary_logloss: 5.33553\tvalid_0's error: 0.26\n",
      "[64]\tvalid_0's binary_logloss: 5.45143\tvalid_0's error: 0.264\n",
      "[65]\tvalid_0's binary_logloss: 5.56931\tvalid_0's error: 0.268\n",
      "[66]\tvalid_0's binary_logloss: 5.57122\tvalid_0's error: 0.264\n",
      "[67]\tvalid_0's binary_logloss: 5.69048\tvalid_0's error: 0.268\n",
      "[68]\tvalid_0's binary_logloss: 5.63137\tvalid_0's error: 0.266\n",
      "[69]\tvalid_0's binary_logloss: 5.68446\tvalid_0's error: 0.268\n",
      "[70]\tvalid_0's binary_logloss: 5.73838\tvalid_0's error: 0.27\n",
      "Finished 40 - 50 rounds with self-defined objective function and eval metric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# self-defined objective function\n",
    "# f(preds: array, train_data: Dataset) -> grad: array, hess: array\n",
    "# log likelihood loss\n",
    "def loglikelihood(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    preds = 1. / (1. + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1. - preds)\n",
    "    return grad, hess\n",
    " \n",
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# binary error\n",
    "# NOTE: when you do customized loss function, the default prediction value is margin\n",
    "# This may make built-in evalution metric calculate wrong results\n",
    "# For example, we are doing log likelihood loss, the prediction is score before logistic transformation\n",
    "# Keep this in mind when you use the customization\n",
    "def binary_error(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    preds = 1. / (1. + np.exp(-preds))\n",
    "    return 'error', np.mean(labels != (preds > 0.5)), False\n",
    " \n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                init_model=gbm,\n",
    "                fobj=loglikelihood,\n",
    "                feval=binary_error,\n",
    "                valid_sets=lgb_eval)\n",
    "print('Finished 40 - 50 rounds with self-defined objective function and eval metric...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10282a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
