{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2006729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T11:07:59.632067Z",
     "iopub.status.busy": "2022-07-14T11:07:59.631092Z",
     "iopub.status.idle": "2022-07-14T11:07:59.641634Z",
     "shell.execute_reply": "2022-07-14T11:07:59.640924Z"
    },
    "papermill": {
     "duration": 0.021102,
     "end_time": "2022-07-14T11:07:59.643745",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.622643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411a3de",
   "metadata": {
    "papermill": {
     "duration": 0.006251,
     "end_time": "2022-07-14T11:07:59.656594",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.650343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pandas groupby - agg\n",
    "\n",
    "The general idea is to use the groupby pandas approach. We can group by customer then apply aggregation functions.\n",
    "\n",
    "There is different way to then perform the aggregation:\n",
    "\n",
    "    - Using base functions\n",
    "    \n",
    "    - Using list of functions with agg\n",
    "    \n",
    "    - Using dictionnary with agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec28273",
   "metadata": {
    "papermill": {
     "duration": 0.006038,
     "end_time": "2022-07-14T11:07:59.668811",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.662773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pandas base function\n",
    "\n",
    "Pandas allows 13 agregation functions to be called by name. Their implementation is optimized, so you might prefer using their name.\n",
    "\n",
    "-    mean(): Compute mean of groups\n",
    "-    sum(): Compute sum of group values\n",
    "-    size(): Compute group sizes\n",
    "-    count(): Compute count of group\n",
    "-    std(): Standard deviation of groups\n",
    "-    var(): Compute variance of groups\n",
    "-    sem(): Standard error of the mean of groups\n",
    "-    describe(): Generates descriptive statistics\n",
    "-    first(): Compute first of group values\n",
    "-    last(): Compute last of group values\n",
    "-    nth() : Take nth value, or a subset if n is a list\n",
    "-    min(): Compute min of group values\n",
    "-    max(): Compute max of group values\n",
    "\n",
    "sum, mean, std, and sem even have a cython optimised implementation.\n",
    "\n",
    "However, the handling of edge case is not always ideal and you might want specific implementation to deal with them.\n",
    "\n",
    "For exemple, depending on the usecase, you could want different result for a mean including a missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24c48a5",
   "metadata": {
    "papermill": {
     "duration": 0.005902,
     "end_time": "2022-07-14T11:07:59.680895",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.674993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "general usage as functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7a6927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T11:07:59.695266Z",
     "iopub.status.busy": "2022-07-14T11:07:59.694612Z",
     "iopub.status.idle": "2022-07-14T11:07:59.714903Z",
     "shell.execute_reply": "2022-07-14T11:07:59.714194Z"
    },
    "papermill": {
     "duration": 0.03003,
     "end_time": "2022-07-14T11:07:59.717129",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.687099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>values</th>\n",
       "      <th>values2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group  values  values2\n",
       "0      1       4        0\n",
       "1      1       1        1\n",
       "2      2       1        1\n",
       "3      2       2        2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'group':[1,1,2,2],'values':[4,1,1,2],'values2':[0,1,1,2]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "214de5fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T11:07:59.732259Z",
     "iopub.status.busy": "2022-07-14T11:07:59.731433Z",
     "iopub.status.idle": "2022-07-14T11:07:59.751809Z",
     "shell.execute_reply": "2022-07-14T11:07:59.751145Z"
    },
    "papermill": {
     "duration": 0.030215,
     "end_time": "2022-07-14T11:07:59.753495",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.723280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>values2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       values  values2\n",
       "group                 \n",
       "1         2.5      0.5\n",
       "2         1.5      1.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('group').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89660a9d",
   "metadata": {
    "papermill": {
     "duration": 0.006605,
     "end_time": "2022-07-14T11:07:59.766867",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.760262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Aggregation with list of function\n",
    "\n",
    "It is possible to aggregate with multiple functions at a time with the agg function.\n",
    "The agg function takke functions as inputs (notice we use np functions here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eded8da1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T11:07:59.782763Z",
     "iopub.status.busy": "2022-07-14T11:07:59.782138Z",
     "iopub.status.idle": "2022-07-14T11:07:59.801094Z",
     "shell.execute_reply": "2022-07-14T11:07:59.800106Z"
    },
    "papermill": {
     "duration": 0.029264,
     "end_time": "2022-07-14T11:07:59.803243",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.773979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">values</th>\n",
       "      <th colspan=\"2\" halign=\"left\">values2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      values           values2          \n",
       "        mean       std    mean       std\n",
       "group                                   \n",
       "1        2.5  2.121320     0.5  0.707107\n",
       "2        1.5  0.707107     1.5  0.707107"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('group').agg([np.mean,np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26042bfe",
   "metadata": {
    "papermill": {
     "duration": 0.006827,
     "end_time": "2022-07-14T11:07:59.817523",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.810696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can get back to pandas function by calling the function by their name (it only works for the 13 functions mentionned above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e987121f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T11:07:59.833807Z",
     "iopub.status.busy": "2022-07-14T11:07:59.832972Z",
     "iopub.status.idle": "2022-07-14T11:07:59.854025Z",
     "shell.execute_reply": "2022-07-14T11:07:59.850530Z"
    },
    "papermill": {
     "duration": 0.031569,
     "end_time": "2022-07-14T11:07:59.856058",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.824489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">values</th>\n",
       "      <th colspan=\"2\" halign=\"left\">values2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      values           values2          \n",
       "        mean       std    mean       std\n",
       "group                                   \n",
       "1        2.5  2.121320     0.5  0.707107\n",
       "2        1.5  0.707107     1.5  0.707107"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('group').agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815e8d2b",
   "metadata": {
    "papermill": {
     "duration": 0.007429,
     "end_time": "2022-07-14T11:07:59.871224",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.863795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Aggregation with dictionnary of functions\n",
    "\n",
    "Applying all fuctions to all features might be a bit over the top. Often you want to apply specific functions to specific columns.\n",
    "Agg allows this by passing a dictionnary:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94b88448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T11:07:59.889386Z",
     "iopub.status.busy": "2022-07-14T11:07:59.888887Z",
     "iopub.status.idle": "2022-07-14T11:07:59.912343Z",
     "shell.execute_reply": "2022-07-14T11:07:59.911677Z"
    },
    "papermill": {
     "duration": 0.035915,
     "end_time": "2022-07-14T11:07:59.914805",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.878890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">values</th>\n",
       "      <th colspan=\"2\" halign=\"left\">values2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      values        values2          \n",
       "        mean median    mean       std\n",
       "group                                \n",
       "1        2.5    2.5     0.5  0.707107\n",
       "2        1.5    1.5     1.5  0.707107"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_FE = {'values':['mean','median'],\n",
    "'values2':['mean','std']}\n",
    "\n",
    "df.groupby('group').agg(dict_FE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ac92ce",
   "metadata": {
    "papermill": {
     "duration": 0.007945,
     "end_time": "2022-07-14T11:07:59.933442",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.925497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, agg usually create a multindexed dataframe... it is often usefull to rename the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d38900c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T11:07:59.950343Z",
     "iopub.status.busy": "2022-07-14T11:07:59.949502Z",
     "iopub.status.idle": "2022-07-14T11:07:59.966631Z",
     "shell.execute_reply": "2022-07-14T11:07:59.965784Z"
    },
    "papermill": {
     "duration": 0.027505,
     "end_time": "2022-07-14T11:07:59.968555",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.941050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values-mean</th>\n",
       "      <th>values-median</th>\n",
       "      <th>values2-mean</th>\n",
       "      <th>values2-std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       values-mean  values-median  values2-mean  values2-std\n",
       "group                                                       \n",
       "1              2.5            2.5           0.5     0.707107\n",
       "2              1.5            1.5           1.5     0.707107"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg = df.groupby('group').agg(dict_FE)\n",
    "df_agg.columns = [c[0]+'-'+c[1] for c in df_agg.columns]\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45caf7b9",
   "metadata": {
    "papermill": {
     "duration": 0.007853,
     "end_time": "2022-07-14T11:07:59.984029",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.976176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11b0f0ef",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-07-14T11:08:00.000746Z",
     "iopub.status.busy": "2022-07-14T11:08:00.000187Z",
     "iopub.status.idle": "2022-07-14T11:08:00.012491Z",
     "shell.execute_reply": "2022-07-14T11:08:00.011878Z"
    },
    "papermill": {
     "duration": 0.022587,
     "end_time": "2022-07-14T11:08:00.014225",
     "exception": false,
     "start_time": "2022-07-14T11:07:59.991638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _roll(a, shift):\n",
    "    \"\"\" Roll 1D array elements. Improves the performance of numpy.roll()\"\"\"\n",
    "\n",
    "\n",
    "    if not isinstance(a, np.ndarray):\n",
    "        a = np.asarray(a)\n",
    "    idx = shift % len(a)\n",
    "    return np.concatenate([a[-idx:], a[:-idx]])\n",
    "\n",
    "\n",
    "def _get_length_sequences_where(x):\n",
    "    \"\"\" This method calculates the length of all sub-sequences where the array x is either True or 1. \"\"\"\n",
    "    if len(x) == 0:\n",
    "        return [0]\n",
    "    else:\n",
    "        res = [len(list(group)) for value, group in itertools.groupby(x) if value == 1]\n",
    "        return res if len(res) > 0 else [0]\n",
    "\n",
    "def _aggregate_on_chunks(x, f_agg, chunk_len):\n",
    "    \"\"\"Takes the time series x and constructs a lower sampled version of it by applying the aggregation function f_agg on\n",
    "    consecutive chunks of length chunk_len\"\"\"\n",
    "    \n",
    "    return [\n",
    "        getattr(x[i * chunk_len : (i + 1) * chunk_len], f_agg)()\n",
    "        for i in range(int(np.ceil(len(x) / chunk_len)))\n",
    "    ]\n",
    "\n",
    "def _into_subchunks(x, subchunk_length, every_n=1):\n",
    "    \"\"\"Split the time series x into subwindows of length \"subchunk_length\", starting every \"every_n\".\"\"\"\n",
    "    len_x = len(x)\n",
    "\n",
    "    assert subchunk_length > 1\n",
    "    assert every_n > 0\n",
    "\n",
    "    # how often can we shift a window of size subchunk_length over the input?\n",
    "    num_shifts = (len_x - subchunk_length) // every_n + 1\n",
    "    shift_starts = every_n * np.arange(num_shifts)\n",
    "    indices = np.arange(subchunk_length)\n",
    "\n",
    "    indexer = np.expand_dims(indices, axis=0) + np.expand_dims(shift_starts, axis=1)\n",
    "    return np.asarray(x)[indexer]\n",
    "\n",
    "\n",
    "def set_property(key, value):\n",
    "    \"\"\"\n",
    "    This method returns a decorator that sets the property key of the function to value\n",
    "    \"\"\"\n",
    "\n",
    "    def decorate_func(func):\n",
    "        setattr(func, key, value)\n",
    "        if func.__doc__ and key == \"fctype\":\n",
    "            func.__doc__ = (\n",
    "                func.__doc__ + \"\\n\\n    *This function is of type: \" + value + \"*\\n\"\n",
    "            )\n",
    "        return func\n",
    "\n",
    "    return decorate_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21824514",
   "metadata": {
    "papermill": {
     "duration": 0.007985,
     "end_time": "2022-07-14T11:08:00.030076",
     "exception": false,
     "start_time": "2022-07-14T11:08:00.022091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Aggregation functions\n",
    "\n",
    "So feature engineering becomes having and choosing features to build from groups. Below is a set of functions that are usefull for time series aggregations. Feel free to comment if you think one is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d44153e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T11:08:00.048116Z",
     "iopub.status.busy": "2022-07-14T11:08:00.047626Z",
     "iopub.status.idle": "2022-07-14T11:08:00.117025Z",
     "shell.execute_reply": "2022-07-14T11:08:00.116275Z"
    },
    "papermill": {
     "duration": 0.0809,
     "end_time": "2022-07-14T11:08:00.119147",
     "exception": false,
     "start_time": "2022-07-14T11:08:00.038247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def median(x):\n",
    "    return np.median(x)\n",
    "\n",
    "def variation_coefficient(x):\n",
    "    mean = np.mean(x)\n",
    "    if mean != 0:\n",
    "        return np.std(x) / mean\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def variance(x):\n",
    "    return np.var(x)\n",
    "\n",
    "def skewness(x):\n",
    "    if not isinstance(x, pd.Series):\n",
    "        x = pd.Series(x)\n",
    "    return pd.Series.skew(x)\n",
    "\n",
    "def kurtosis(x):\n",
    "    if not isinstance(x, pd.Series):\n",
    "        x = pd.Series(x)\n",
    "    return pd.Series.kurtosis(x)\n",
    "\n",
    "def standard_deviation(x):\n",
    "    return np.std(x)\n",
    "\n",
    "def large_standard_deviation(x):\n",
    "    if (np.max(x)-np.min(x)) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.std(x)/(np.max(x)-np.min(x))\n",
    "\n",
    "def variation_coefficient(x):\n",
    "    mean = np.mean(x)\n",
    "    if mean != 0:\n",
    "        return np.std(x) / mean\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def variance_std_ratio(x):\n",
    "    y = np.var(x)\n",
    "    if y != 0:\n",
    "        return y/np.sqrt(y)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def ratio_beyond_r_sigma(x, r):\n",
    "    if x.size == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.sum(np.abs(x - np.mean(x)) > r * np.asarray(np.std(x))) / x.size\n",
    "\n",
    "def range_ratio(x):\n",
    "    mean_median_difference = np.abs(np.mean(x) - np.median(x))\n",
    "    max_min_difference = np.max(x) - np.min(x)\n",
    "    if max_min_difference == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return mean_median_difference / max_min_difference\n",
    "    \n",
    "def has_duplicate_max(x):\n",
    "    return np.sum(x == np.max(x)) >= 2\n",
    "\n",
    "def has_duplicate_min(x):\n",
    "    return np.sum(x == np.min(x)) >= 2\n",
    "\n",
    "def has_duplicate(x):\n",
    "    return x.size != np.unique(x).size\n",
    "\n",
    "def count_duplicate_max(x):\n",
    "    return np.sum(x == np.max(x))\n",
    "\n",
    "def count_duplicate_min(x):\n",
    "    return np.sum(x == np.min(x))\n",
    "\n",
    "def count_duplicate(x):\n",
    "    return x.size - np.unique(x).size\n",
    "\n",
    "def sum_values(x):\n",
    "    if len(x) == 0:\n",
    "        return 0\n",
    "    return np.sum(x)\n",
    "\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff() \n",
    "\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "def realized_abs_skew(series):\n",
    "    return np.power(np.abs(np.sum(series**3)),1/3)\n",
    "\n",
    "def realized_skew(series):\n",
    "    return np.sign(np.sum(series**3))*np.power(np.abs(np.sum(series**3)),1/3)\n",
    "\n",
    "def realized_vol_skew(series):\n",
    "    return np.power(np.abs(np.sum(series**6)),1/6)\n",
    "\n",
    "def realized_quarticity(series):\n",
    "    return np.power(np.sum(series**4),1/4)\n",
    "\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "def count(series):\n",
    "    return series.size\n",
    "\n",
    "#drawdons functions are mine\n",
    "def maximum_drawdown(series):\n",
    "    series = np.asarray(series)\n",
    "    if len(series)<2:\n",
    "        return 0\n",
    "    k = series[np.argmax(np.maximum.accumulate(series) - series)]\n",
    "    i = np.argmax(np.maximum.accumulate(series) - series)\n",
    "    if len(series[:i])<1:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        j = np.max(series[:i])\n",
    "    return j-k\n",
    "\n",
    "def maximum_drawup(series):\n",
    "    series = np.asarray(series)\n",
    "    if len(series)<2:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    series = - series\n",
    "    k = series[np.argmax(np.maximum.accumulate(series) - series)]\n",
    "    i = np.argmax(np.maximum.accumulate(series) - series)\n",
    "    if len(series[:i])<1:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        j = np.max(series[:i])\n",
    "    return j-k\n",
    "\n",
    "def drawdown_duration(series):\n",
    "    series = np.asarray(series)\n",
    "    if len(series)<2:\n",
    "        return 0\n",
    "\n",
    "    k = np.argmax(np.maximum.accumulate(series) - series)\n",
    "    i = np.argmax(np.maximum.accumulate(series) - series)\n",
    "    if len(series[:i]) == 0:\n",
    "        j=k\n",
    "    else:\n",
    "        j = np.argmax(series[:i])\n",
    "    return k-j\n",
    "\n",
    "def drawup_duration(series):\n",
    "    series = np.asarray(series)\n",
    "    if len(series)<2:\n",
    "        return 0\n",
    "\n",
    "    series=-series\n",
    "    k = np.argmax(np.maximum.accumulate(series) - series)\n",
    "    i = np.argmax(np.maximum.accumulate(series) - series)\n",
    "    if len(series[:i]) == 0:\n",
    "        j=k\n",
    "    else:\n",
    "        j = np.argmax(series[:i])\n",
    "    return k-j\n",
    "\n",
    "def max_over_min(series):\n",
    "    if len(series)<2:\n",
    "        return 0\n",
    "    if np.min(series) == 0:\n",
    "        return np.nan\n",
    "    return np.max(series)/np.min(series)\n",
    "\n",
    "def mean_n_absolute_max(x, number_of_maxima = 1):\n",
    "    \"\"\" Calculates the arithmetic mean of the n absolute maximum values of the time series.\"\"\"\n",
    "    assert (\n",
    "        number_of_maxima > 0\n",
    "    ), f\" number_of_maxima={number_of_maxima} which is not greater than 1\"\n",
    "\n",
    "    n_absolute_maximum_values = np.sort(np.absolute(x))[-number_of_maxima:]\n",
    "\n",
    "    return np.mean(n_absolute_maximum_values) if len(x) > number_of_maxima else np.NaN\n",
    "\n",
    "\n",
    "def count_above(x, t):\n",
    "    if len(x)==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.sum(x >= t) / len(x)\n",
    "\n",
    "def count_below(x, t):\n",
    "    if len(x)==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.sum(x <= t) / len(x)\n",
    "\n",
    "#number of valleys = number_peaks(-x, n)\n",
    "def number_peaks(x, n):\n",
    "    \"\"\"\n",
    "    Calculates the number of peaks of at least support n in the time series x. A peak of support n is defined as a\n",
    "    subsequence of x where a value occurs, which is bigger than its n neighbours to the left and to the right.\n",
    "    \"\"\"\n",
    "    x_reduced = x[n:-n]\n",
    "\n",
    "    res = None\n",
    "    for i in range(1, n + 1):\n",
    "        result_first = x_reduced > _roll(x, i)[n:-n]\n",
    "\n",
    "        if res is None:\n",
    "            res = result_first\n",
    "        else:\n",
    "            res &= result_first\n",
    "\n",
    "        res &= x_reduced > _roll(x, -i)[n:-n]\n",
    "    return np.sum(res)\n",
    "\n",
    "def mean_abs_change(x):\n",
    "    return np.mean(np.abs(np.diff(x)))\n",
    "\n",
    "def mean_change(x):\n",
    "    x = np.asarray(x)\n",
    "    return (x[-1] - x[0]) / (len(x) - 1) if len(x) > 1 else np.NaN\n",
    "\n",
    "def mean_second_derivative_central(x):\n",
    "    x = np.asarray(x)\n",
    "    return (x[-1] - x[-2] - x[1] + x[0]) / (2 * (len(x) - 2)) if len(x) > 2 else np.NaN\n",
    "\n",
    "\n",
    "def root_mean_square(x):\n",
    "    return np.sqrt(np.mean(np.square(x))) if len(x) > 0 else np.NaN\n",
    "\n",
    "def absolute_sum_of_changes(x):\n",
    "    return np.sum(np.abs(np.diff(x)))\n",
    "\n",
    "def longest_strike_below_mean(x):\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    return np.max(_get_length_sequences_where(x < np.mean(x))) if x.size > 0 else 0\n",
    "\n",
    "def longest_strike_above_mean(x):\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    return np.max(_get_length_sequences_where(x > np.mean(x))) if x.size > 0 else 0\n",
    "\n",
    "def count_above_mean(x):\n",
    "    m = np.mean(x)\n",
    "    return np.where(x > m)[0].size\n",
    "\n",
    "def count_below_mean(x):\n",
    "    m = np.mean(x)\n",
    "    return np.where(x < m)[0].size\n",
    "\n",
    "def last_location_of_maximum(x):\n",
    "    x = np.asarray(x)\n",
    "    return 1.0 - np.argmax(x[::-1]) / len(x) if len(x) > 0 else np.NaN\n",
    "\n",
    "def first_location_of_maximum(x):\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    return np.argmax(x) / len(x) if len(x) > 0 else np.NaN\n",
    "\n",
    "def last_location_of_minimum(x):\n",
    "    x = np.asarray(x)\n",
    "    return 1.0 - np.argmin(x[::-1]) / len(x) if len(x) > 0 else np.NaN\n",
    "\n",
    "def first_location_of_minimum(x):\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    return np.argmin(x) / len(x) if len(x) > 0 else np.NaN\n",
    "\n",
    "# Test non-consecutive non-reoccuring values ?\n",
    "def percentage_of_reoccurring_values_to_all_values(x):\n",
    "    if len(x) == 0:\n",
    "        return np.nan\n",
    "    unique, counts = np.unique(x, return_counts=True)\n",
    "    if counts.shape[0] == 0:\n",
    "        return 0\n",
    "    return np.sum(counts > 1) / float(counts.shape[0])\n",
    "\n",
    "def percentage_of_reoccurring_datapoints_to_all_datapoints(x):\n",
    "    if len(x) == 0:\n",
    "        return np.nan\n",
    "    if not isinstance(x, pd.Series):\n",
    "        x = pd.Series(x)\n",
    "    value_counts = x.value_counts()\n",
    "    reoccuring_values = value_counts[value_counts > 1].sum()\n",
    "    if np.isnan(reoccuring_values):\n",
    "        return 0\n",
    "\n",
    "    return reoccuring_values / x.size\n",
    "\n",
    "\n",
    "def sum_of_reoccurring_values(x):\n",
    "    unique, counts = np.unique(x, return_counts=True)\n",
    "    counts[counts < 2] = 0\n",
    "    counts[counts > 1] = 1\n",
    "    return np.sum(counts * unique)\n",
    "\n",
    "def sum_of_reoccurring_data_points(x):\n",
    "    unique, counts = np.unique(x, return_counts=True)\n",
    "    counts[counts < 2] = 0\n",
    "    return np.sum(counts * unique)\n",
    "\n",
    "def ratio_value_number_to_time_series_length(x):\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    if x.size == 0:\n",
    "        return np.nan\n",
    "\n",
    "    return np.unique(x).size / x.size\n",
    "\n",
    "def abs_energy(x):\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    return np.dot(x, x)\n",
    "\n",
    "def quantile(x, q):\n",
    "    if len(x) == 0:\n",
    "        return np.NaN\n",
    "    return np.quantile(x, q)\n",
    "\n",
    "# crossing the mean ? other levels ? \n",
    "def number_crossing_m(x, m):\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    # From https://stackoverflow.com/questions/3843017/efficiently-detect-sign-changes-in-python\n",
    "    positive = x > m\n",
    "    return np.where(np.diff(positive))[0].size\n",
    "\n",
    "def absolute_maximum(x):\n",
    "    return np.max(np.absolute(x)) if len(x) > 0 else np.NaN\n",
    "\n",
    "def value_count(x, value):\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    if np.isnan(value):\n",
    "        return np.isnan(x).sum()\n",
    "    else:\n",
    "        return x[x == value].size\n",
    "\n",
    "def range_count(x, min, max):\n",
    "    return np.sum((x >= min) & (x < max))\n",
    "\n",
    "def mean_diff(x):\n",
    "    return np.nanmean(np.diff(x.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2272c7",
   "metadata": {
    "papermill": {
     "duration": 0.00695,
     "end_time": "2022-07-14T11:08:00.133597",
     "exception": false,
     "start_time": "2022-07-14T11:08:00.126647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lambda functions to facilitate application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c262ab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T11:08:00.149872Z",
     "iopub.status.busy": "2022-07-14T11:08:00.149360Z",
     "iopub.status.idle": "2022-07-14T11:08:00.160349Z",
     "shell.execute_reply": "2022-07-14T11:08:00.159693Z"
    },
    "papermill": {
     "duration": 0.021425,
     "end_time": "2022-07-14T11:08:00.162181",
     "exception": false,
     "start_time": "2022-07-14T11:08:00.140756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_above_0 = lambda x: count_above(x,0)\n",
    "count_above_0.__name__ = 'count_above_0'\n",
    "\n",
    "count_below_0 = lambda x: count_below(x,0)\n",
    "count_below_0.__name__ = 'count_below_0'\n",
    "\n",
    "value_count_0 = lambda x: value_count(x,0)\n",
    "value_count_0.__name__ = 'value_count_0'\n",
    "\n",
    "count_near_0 = lambda x: range_count(x,-0.00001,0.00001)\n",
    "count_near_0.__name__ = 'count_near_0_0'\n",
    "\n",
    "ratio_beyond_01_sigma = lambda x: ratio_beyond_r_sigma(x,0.1)\n",
    "ratio_beyond_01_sigma.__name__ = 'ratio_beyond_01_sigma'\n",
    "\n",
    "ratio_beyond_02_sigma = lambda x: ratio_beyond_r_sigma(x,0.2)\n",
    "ratio_beyond_02_sigma.__name__ = 'ratio_beyond_02_sigma'\n",
    "\n",
    "ratio_beyond_03_sigma = lambda x: ratio_beyond_r_sigma(x,0.3)\n",
    "ratio_beyond_03_sigma.__name__ = 'ratio_beyond_03_sigma'\n",
    "\n",
    "number_crossing_0 = lambda x: number_crossing_m(x,0)\n",
    "number_crossing_0.__name__ = 'number_crossing_0'\n",
    "\n",
    "quantile_01 = lambda x: quantile(x,0.1)\n",
    "quantile_01.__name__ = 'quantile_01'\n",
    "\n",
    "quantile_025 = lambda x: quantile(x,0.25)\n",
    "quantile_025.__name__ = 'quantile_025'\n",
    "\n",
    "quantile_075 = lambda x: quantile(x,0.75)\n",
    "quantile_075.__name__ = 'quantile_075'\n",
    "\n",
    "quantile_09 = lambda x: quantile(x,0.9)\n",
    "quantile_09.__name__ = 'quantile_09'\n",
    "\n",
    "number_peaks_2 = lambda x: number_peaks(x,2)\n",
    "number_peaks_2.__name__ = 'number_peaks_2'\n",
    "\n",
    "mean_n_absolute_max_2 = lambda x: mean_n_absolute_max(x,2)\n",
    "mean_n_absolute_max_2.__name__ = 'mean_n_absolute_max_2'\n",
    "\n",
    "number_peaks_5 = lambda x: number_peaks(x,5)\n",
    "number_peaks_5.__name__ = 'number_peaks_5'\n",
    "\n",
    "mean_n_absolute_max_5 = lambda x: mean_n_absolute_max(x,5)\n",
    "mean_n_absolute_max_5.__name__ = 'mean_n_absolute_max_5'\n",
    "\n",
    "number_peaks_10 = lambda x: number_peaks(x,10)\n",
    "number_peaks_10.__name__ = 'number_peaks_10'\n",
    "\n",
    "mean_n_absolute_max_10 = lambda x: mean_n_absolute_max(x,10)\n",
    "mean_n_absolute_max_10.__name__ = 'mean_n_absolute_max_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f84e7792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T11:08:00.178791Z",
     "iopub.status.busy": "2022-07-14T11:08:00.178302Z",
     "iopub.status.idle": "2022-07-14T11:08:00.186169Z",
     "shell.execute_reply": "2022-07-14T11:08:00.185471Z"
    },
    "papermill": {
     "duration": 0.01852,
     "end_time": "2022-07-14T11:08:00.187995",
     "exception": false,
     "start_time": "2022-07-14T11:08:00.169475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_stats = ['mean','sum','size','count','std','first','last','min','max',median,skewness,kurtosis]\n",
    "higher_order_stats = [abs_energy,root_mean_square,sum_values,realized_volatility,realized_abs_skew,realized_skew,realized_vol_skew,realized_quarticity]\n",
    "additional_quantiles = [quantile_01,quantile_025,quantile_075,quantile_09]\n",
    "other_min_max = [absolute_maximum,max_over_min]\n",
    "min_max_positions = [last_location_of_maximum,first_location_of_maximum,last_location_of_minimum,first_location_of_minimum]\n",
    "peaks = [number_peaks_2, mean_n_absolute_max_2, number_peaks_5, mean_n_absolute_max_5, number_peaks_10, mean_n_absolute_max_10]\n",
    "counts = [count_unique,count,count_above_0,count_below_0,value_count_0,count_near_0]\n",
    "reoccuring_values = [count_above_mean,count_below_mean,percentage_of_reoccurring_values_to_all_values,percentage_of_reoccurring_datapoints_to_all_datapoints,sum_of_reoccurring_values,sum_of_reoccurring_data_points,ratio_value_number_to_time_series_length]\n",
    "count_duplicate = [count_duplicate,count_duplicate_min,count_duplicate_max]\n",
    "variations = [mean_diff,mean_abs_change,mean_change,mean_second_derivative_central,absolute_sum_of_changes,number_crossing_0]\n",
    "ranges = [variance_std_ratio,ratio_beyond_01_sigma,ratio_beyond_02_sigma,ratio_beyond_03_sigma,large_standard_deviation,range_ratio]\n",
    "\n",
    "all_functions = base_stats + higher_order_stats + additional_quantiles + other_min_max + min_max_positions + peaks + counts + variations + ranges \n",
    "\n",
    "#+ reoccuring_values + count_duplicate : usually very slow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ad690",
   "metadata": {
    "papermill": {
     "duration": 0.007015,
     "end_time": "2022-07-14T11:08:00.202474",
     "exception": false,
     "start_time": "2022-07-14T11:08:00.195459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After that you can put this features in the first notebook for aggregation :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b941718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T11:08:00.219302Z",
     "iopub.status.busy": "2022-07-14T11:08:00.218783Z",
     "iopub.status.idle": "2022-07-14T11:08:00.227911Z",
     "shell.execute_reply": "2022-07-14T11:08:00.227226Z"
    },
    "papermill": {
     "duration": 0.019825,
     "end_time": "2022-07-14T11:08:00.229835",
     "exception": false,
     "start_time": "2022-07-14T11:08:00.210010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "# https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))\n",
    "\n",
    "#main_features = [f'B_{i}' for i in [11,14,17]]+['D_39','D_131']+[f'S_{i}' for i in [16,23]]+['P_2','P_3']\n",
    "main_features = ['P_2']\n",
    "\n",
    "def prepare_dataset(train_test = 'train'):\n",
    "    \n",
    "    data = pd.read_parquet('../input/amex-data-integer-dtypes-parquet-format/'+train_test+'.parquet')\n",
    "    \n",
    "    if DEBUG:\n",
    "        data = data.iloc[:int((len(data)/60))]\n",
    "    \n",
    "    split_ids = split(data.customer_ID.unique(),10)\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for (i,ids) in enumerate(split_ids):\n",
    "        print(i)\n",
    "        data_ids = data[data.customer_ID.isin(ids)]\n",
    "\n",
    "        data_agg = data_ids[main_features].groupby(data_ids.customer_ID).agg(all_functions)\n",
    "       \n",
    "        data_agg.columns = [c[0]+'-'+c[1] for c in data_agg.columns]\n",
    "\n",
    "        \n",
    "        df_list.append(data_agg)\n",
    "        gc.collect()\n",
    "\n",
    "    pd.concat(df_list,axis=0).astype('float16').to_pickle(train_test+'_data_agg2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20309.529395,
   "end_time": "2022-07-14T16:46:20.079576",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-14T11:07:50.550181",
   "version": "2.3.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
