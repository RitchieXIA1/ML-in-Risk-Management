{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc241f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "class MeanEncoding():\n",
    "    \"\"\"\n",
    "    replacing the label by the mean of the target for that label. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mapping=None, cols=None):\n",
    "        self.cols = cols\n",
    "        self.mapping = mapping\n",
    "        self._dim = None\n",
    "        # self.threshold = threshold\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        \"\"\"Fit encoder according to X and y.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : encoder\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "\n",
    "        self._dim = X.shape[1]\n",
    "\n",
    "        _, categories = self.mean_encoding(\n",
    "            X,\n",
    "            y,\n",
    "            mapping=self.mapping,\n",
    "            cols=self.cols\n",
    "            # threshold=self.threshold\n",
    "        )\n",
    "        self.mapping = categories\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Perform the transformation to new categorical data.\n",
    "        Will use the mapping (if available) and the column list to encode the\n",
    "        data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "        Returns\n",
    "        -------\n",
    "        X : Transformed values with encoding applied.\n",
    "        \"\"\"\n",
    "\n",
    "        if self._dim is None:\n",
    "            raise ValueError('Must train encoder before it can be used to transform data.')\n",
    "\n",
    "        #  make sure that it is the right size\n",
    "        if X.shape[1] != self._dim:\n",
    "            raise ValueError('Unexpected input dimension %d, expected %d' % (X.shape[1], self._dim,))\n",
    "\n",
    "        X, _ = self.mean_encoding(\n",
    "            X,\n",
    "            mapping=self.mapping,\n",
    "            cols=self.cols\n",
    "            # threshold=self.threshold\n",
    "        )\n",
    "\n",
    "        return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9183e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_FE(df1, df2, cols):\n",
    "    for col in cols:\n",
    "        df = pd.concat([df1[col],df2[col]])\n",
    "        vc = df.value_counts(dropna=True, normalize=True).to_dict()\n",
    "        vc[-1] = -1\n",
    "        nm = col+'_FE'\n",
    "        df1[nm] = df1[col].map(vc)\n",
    "        df1[nm] = df1[nm].astype('float32')\n",
    "        df2[nm] = df2[col].map(vc)\n",
    "        df2[nm] = df2[nm].astype('float32')\n",
    "        print(nm,', ',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d503aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL ENCODE\n",
    "def encode_LE(col,train=None,test=None,verbose=True):\n",
    "    df_comb = pd.concat([train[col],test[col]],axis=0)\n",
    "    df_comb,_ = df_comb.factorize(sort=True)\n",
    "    nm = col\n",
    "    if df_comb.max()>32000: \n",
    "        train[nm] = df_comb[:len(train)].astype('int32')\n",
    "        test[nm] = df_comb[len(train):].astype('int32')\n",
    "    else:\n",
    "        train[nm] = df_comb[:len(train)].astype('int16')\n",
    "        test[nm] = df_comb[len(train):].astype('int16')\n",
    "    del df_comb; \n",
    "    gc.collect()\n",
    "    if verbose: print(nm,', ',end='')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a430782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP AGGREGATION MEAN AND STD\n",
    "# https://www.kaggle.com/kyakovlev/ieee-fe-with-some-eda\n",
    "def encode_AG(main_columns, uids, aggregations=['mean'], train_df=None, test_df=None, \n",
    "              fillna=True, usena=False):\n",
    "    # AGGREGATION OF MAIN WITH UID FOR GIVEN STATISTICS\n",
    "    for main_column in main_columns:  \n",
    "        for col in uids:\n",
    "            for agg_type in aggregations:\n",
    "                new_col_name = main_column+'_'+col+'_'+agg_type\n",
    "                if agg_type=='skew':\n",
    "                    agg_type=pd.DataFrame.skew\n",
    "                elif agg_type=='kurt':\n",
    "                    agg_type=pd.DataFrame.kurt\n",
    "                temp_df = pd.concat([train_df[[col, main_column]], test_df[[col,main_column]]])\n",
    "                if usena: temp_df.loc[temp_df[main_column]==-1,main_column] = np.nan\n",
    "                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n",
    "                                                        columns={agg_type: new_col_name})\n",
    "\n",
    "                temp_df.index = list(temp_df[col])\n",
    "                temp_df = temp_df[new_col_name].to_dict()   \n",
    "\n",
    "                train_df[new_col_name] = train_df[col].map(temp_df).astype('float32')\n",
    "                test_df[new_col_name]  = test_df[col].map(temp_df).astype('float32')\n",
    "                \n",
    "                if fillna:\n",
    "                    train_df[new_col_name].fillna(-1,inplace=True)\n",
    "                    test_df[new_col_name].fillna(-1,inplace=True)\n",
    "                \n",
    "                print(\"'\"+new_col_name+\"'\",', ',end='')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f5d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE FEATURES\n",
    "def encode_CB2(col1,col2,df1=None,df2=None):\n",
    "    nm = col1+'_'+col2\n",
    "    df1[nm] = df1[col1].astype(str)+'_'+df1[col2].astype(str)\n",
    "    df2[nm] = df2[col1].astype(str)+'_'+df2[col2].astype(str) \n",
    "    encode_LE(nm,train=df1,test=df2,verbose=False)\n",
    "    print(nm,', ',end='')\n",
    "\n",
    "def encode_CB3(col1,col2,col3,df1=None,df2=None):\n",
    "    nm = col1+'_'+col2+'_'+col3\n",
    "    df1[nm] = df1[col1].astype(str)+'_'+df1[col2].astype(str)+'_'+df1[col3].astype(str)\n",
    "    df2[nm] = df2[col1].astype(str)+'_'+df2[col2].astype(str) +'_'+df2[col3].astype(str)\n",
    "    encode_LE(nm,train=df1,test=df2,verbose=False)\n",
    "    print(nm,', ',end='')\n",
    "#生成二阶、三阶交叉    \n",
    "from itertools import combinations\n",
    "combs2=list(combinations(imp_cat,2))\n",
    "combs3=list(combinations(imp_cat,3))\n",
    "for cross in combs2:\n",
    "    encode_CB2(cross[0],cross[1],X,X_test)\n",
    "for cross in combs3:\n",
    "    encode_CB3(cross[0],cross[1],cross[2],X,X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83df303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP AGGREGATION NUNIQUE\n",
    "def encode_AG2(main_columns, uids, train_df=None, test_df=None):\n",
    "    for main_column in main_columns:  \n",
    "        for col in uids:\n",
    "            comb = pd.concat([train_df[[col]+[main_column]],test_df[[col]+[main_column]]],axis=0)\n",
    "            mp = comb.groupby(col)[main_column].agg(['nunique'])['nunique'].to_dict()\n",
    "            train_df[col+'_'+main_column+'_ct'] = train_df[col].map(mp).astype('float32')\n",
    "            test_df[col+'_'+main_column+'_ct'] = test_df[col].map(mp).astype('float32')\n",
    "            print(col+'_'+main_column+'_ct, ',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca97cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    " # https://www.kaggle.com/shahules/an-overview-of-encoding-techniques \n",
    "            # 周期性特征的编码，这个要注意了~~年月日这类的\n",
    "def cyclic_encoding(cols,train,test):\n",
    "    for col in cols:\n",
    "        train[col+'_sin']=np.sin((2*np.pi*train[col])/max(train[col]))\n",
    "        print(col+'_sin',', ',end='')\n",
    "        train[col+'_cos']=np.cos((2*np.pi*train[col])/max(train[col]))\n",
    "        print(col+'_cos',', ',end='')\n",
    "        \n",
    "#from sklearn.feature_extraction import FeatureHasher\n",
    "#X_train_hash=X.copy()\n",
    "#for c in X.columns:\n",
    "#    X_train_hash[c]=X[c].astype('str')      \n",
    "#hashing=FeatureHasher(input_type='string')\n",
    "#train=hashing.transform(X_train_hash.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cacc9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None, \n",
    "                  tst_series=None, \n",
    "                  target=None, \n",
    "                  min_samples_leaf=1, \n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior  \n",
    "    \"\"\" \n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean \n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)\n",
    "\n",
    "\n",
    " # https://www.kaggle.com/tnarik/likelihood-encoding-of-categorical-features 似然编码 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b83011c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
