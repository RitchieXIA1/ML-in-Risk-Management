{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# 核心代码，设置显示的最大列、宽等参数，消掉打印不完全中间的省略号\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "def read_df(file_name):\n",
    "    file_dir = './'\n",
    "    file_path = os.path.join(file_dir, file_name)\n",
    "    file_path = open(file_path)\n",
    "    df_file = pd.read_csv(file_path)\n",
    "    df_file['DateTime'] = pd.to_datetime(df_file['DateTime'])\n",
    "    df_file = df_file.sort_values(by='DateTime')\n",
    "    return df_file\n",
    "\n",
    "\n",
    "# 对 x 增加特征：date_ymd 年月日、把年月日时分秒转化为秒数utc时间\n",
    "def add_features(df_file):\n",
    "    date_list = []\n",
    "    for date in list(df_file['DateTime']):\n",
    "        date_str = str(date).split(' ')[0]\n",
    "        date_list.append(date_str)\n",
    "    df_file['date_ymd'] = date_list\n",
    "    time_stamp_list = []\n",
    "    for time_stamp in list(df_file['DateTime']):\n",
    "        time_s = time.mktime(time.strptime(str(time_stamp), '%Y-%m-%d %H:%M:%S'))\n",
    "        # time_s = time.mktime(time.strptime(time_stamp, '%Y/%m/%d %H:%M:%S'))\n",
    "        time_stamp_list.append(time_s)\n",
    "    df_file['time_stamp'] = time_stamp_list\n",
    "    # date_ymdh_list = []\n",
    "    # for time_stamp in list(df_file['DateTime']):\n",
    "    #     date_ymdh = str(time_stamp).split(':')[0]\n",
    "    #     date_ymdh_list.append(date_ymdh)\n",
    "    # df_file['date_ymdh'] = date_ymdh_list\n",
    "    return df_file\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对缺失的温度进行插补\n",
    "def repair_tem(df_data_by_date):\n",
    "    # 去除重复列，默认所有列无重复记录\n",
    "    df_data_by_date.duplicated()\n",
    "    df_data_by_date = df_data_by_date.reset_index(drop=True)\n",
    "    term_list_1 = list(df_data_by_date['Temperature'])\n",
    "    term_list_date = list(df_data_by_date['date_ymd'])\n",
    "    n = len(term_list_1)\n",
    "    date_list = []\n",
    "    temp_temp_list = []\n",
    "    # 采样频率\n",
    "    sample_frequency = 10\n",
    "    for i in range(n):\n",
    "        if (i >= 0 and i + 1 <= n - 1):\n",
    "            temp_temp_list.append(term_list_1[i])\n",
    "            date_list.append(term_list_date[i])\n",
    "            # 对中间缺失的温度值进行插补\n",
    "            if (df_data_by_date.loc[i + 1]['time_stamp'] - df_data_by_date.loc[i]['time_stamp'] >= (sample_frequency + 1) * 60):\n",
    "                n_temp = int(np.ceil((df_data_by_date.loc[i + 1]['time_stamp'] - df_data_by_date.loc[i]['time_stamp']) / (sample_frequency * 60.0)))\n",
    "                for j in range(n_temp - 1):\n",
    "                    temp_temp = (df_data_by_date.loc[i + 1]['Temperature'] + df_data_by_date.loc[i]['Temperature']) / 2\n",
    "                    temp_temp_list.append(temp_temp)\n",
    "                    date_list.append(term_list_date[-1])\n",
    "    temp_temp_list.append(term_list_1[-1])\n",
    "    date_list.append(term_list_date[-1])\n",
    "    # 如果开始连续缺失数量少于 5%, 用均值补齐\n",
    "    df_data_by_date = df_data_by_date.reset_index(drop=True)\n",
    "    #date_ = term_list_date[1]\n",
    "    continue_list = []\n",
    "    time_s = time.mktime(time.strptime(str(term_list_date[1]), '%Y-%m-%d'))\n",
    "    if(df_data_by_date.loc[0]['time_stamp'] - time_s > (sample_frequency + 1) * 60):\n",
    "        # 开头缺失\n",
    "        n_temp = int(np.ceil((df_data_by_date.loc[0]['time_stamp'] - time_s) / (sample_frequency * 60.0)))\n",
    "        #for j in range(n_temp - 1):\n",
    "        for j in range(int(24*60/sample_frequency) - len(term_list_1)):\n",
    "            continue_list.append(round(np.mean(term_list_1), 2))\n",
    "            date_list.append(term_list_date[-1])\n",
    "        continue_list.extend(temp_temp_list)\n",
    "        temp_temp_list = continue_list\n",
    "    else:\n",
    "        # 结尾缺失\n",
    "        for j in range(int(24*60/sample_frequency) - len(term_list_1)):\n",
    "            continue_list.append(round(np.mean(term_list_1), 2))\n",
    "            date_list.append(term_list_date[-1])\n",
    "        temp_temp_list.extend(continue_list)\n",
    "    df_repair = pd.DataFrame()\n",
    "    df_repair['date_ymd'] = date_list\n",
    "    df_repair['Temperature'] = temp_temp_list\n",
    "    return df_repair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对温度曲线做分段常数逼近处理，用均值逼近, 1个小时内的温度值取一次均值\n",
    "def constant_appro(df_data_by_date_tem):\n",
    "    df_data_by_date_tem = df_data_by_date_tem.reset_index(drop=True)\n",
    "    combine_date = []\n",
    "    date_list = []\n",
    "    temp = list(df_data_by_date_tem['Temperature'])\n",
    "    for i in range(len(temp)):\n",
    "        # 0 1 2   345   678\n",
    "        # i*2  i*2+1   i*2+2\n",
    "        # 3 个数据取平均 ，半小时\n",
    "        # if(i*2 + i +2<=len(temp)-1):\n",
    "        #     temp_combine = (temp[i*2 + i] + temp[i*2 + i + 1] + temp[i*2 + i + 2])/3.0\n",
    "        #     combine_date.append(round(temp_combine, 2))\n",
    "        # 6 个数取平均，1 小时\n",
    "        if (i * 5 + i + 5 <= len(temp) - 1):\n",
    "            temp_combine = (temp[i*5 + i] + temp[i*5 + i + 1] + temp[i*5 + i + 2] + temp[i*5 + i + 3] + temp[i*5 + i + 4] + temp[i*5 + i + 5])/6.0\n",
    "            # temp_combine = (\n",
    "            # temp[i * 5 + i] + temp[i * 5 + i + 1] + temp[i * 5 + i + 2] + temp[i * 5 + i + 3] + temp[i * 5 + i + 4] +\n",
    "            # temp[i * 5 + i + 5])\n",
    "            combine_date.append(round(temp_combine, 2))\n",
    "            date_list.append(df_data_by_date_tem.loc[0]['date_ymd'])\n",
    "    # 对温度做差分平滑处理\n",
    "    diff_1 = [round(combine_date[i] - combine_date[i + 1], 2)for i in range(len(combine_date) - 1)]\n",
    "    del date_list[1]\n",
    "    df_appro = pd.DataFrame()\n",
    "    df_appro['date_ymd'] = date_list\n",
    "    df_appro['Temperature'] = diff_1\n",
    "    return df_appro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01108bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 x 进行特征提取,\n",
    "from tsfresh import extract_relevant_features\n",
    "from tsfresh import extract_features\n",
    "import tsfresh as tsf\n",
    "def get_features(df_appro):\n",
    "    #extracted_features = extract_features(df_appro, column_id='date_ymd')\n",
    "    #ts = pd.Series(x)  # 数据x假设已经获取\n",
    "    ts = df_appro['Temperature']\n",
    "    # 一阶差分绝对和\n",
    "    abs_sum = tsf.feature_extraction.feature_calculators.absolute_sum_of_changes(ts)\n",
    "    abs_sum = round(abs_sum, 2)\n",
    "    # 各阶自相关系数的聚合统计特征\n",
    "    param_statis = [{'f_agg': 'mean', 'maxlag': 2}]\n",
    "    diff_statis = tsf.feature_extraction.feature_calculators.agg_autocorrelation(ts, param_statis)\n",
    "    diff_statis = diff_statis[0][1]\n",
    "    diff_statis = round(diff_statis, 2)\n",
    "    # ADF 检测统计值\n",
    "    param_adf = [{'attr': 'pvalue'}]\n",
    "    adf = tsf.feature_extraction.feature_calculators.augmented_dickey_fuller(ts, param_adf)\n",
    "    adf = adf[0][1]\n",
    "    adf = round(adf, 2)\n",
    "    # 峰度\n",
    "    peak = tsf.feature_extraction.feature_calculators.kurtosis(ts)\n",
    "    peak = round(peak, 2)\n",
    "    # 时序数据复杂度\n",
    "    complexity = tsf.feature_extraction.feature_calculators.cid_ce(ts, True)\n",
    "    complexity = round(complexity, 2)\n",
    "    # 线性回归分析\n",
    "    param_line = [{'attr': 'pvalue'}]\n",
    "    line = tsf.feature_extraction.feature_calculators.linear_trend(ts, param_line)\n",
    "    line = list(zip(line))[0][0][1]\n",
    "    line = round(line, 2)\n",
    "    # 分组熵\n",
    "    bin_entropy = tsf.feature_extraction.feature_calculators.binned_entropy(ts, 10)\n",
    "    bin_entropy = round(bin_entropy, 2)\n",
    "    # 近似熵\n",
    "    appro_entropy = tsf.feature_extraction.feature_calculators.approximate_entropy(ts, 6, 0.1)\n",
    "    appro_entropy = round(appro_entropy, 2)\n",
    "    # 傅里叶变换频谱统计量\n",
    "    param_fly = [{'aggtype': 'skew'}]\n",
    "    fly = tsf.feature_extraction.feature_calculators.fft_aggregated(ts, param_fly)\n",
    "    fly = list(zip(fly))[0][0][1]\n",
    "    fly = round(fly, 2)\n",
    "    # 傅里叶变换系数\n",
    "    param_fly_change = [{'coeff': 2, 'attr': 'angle'}]\n",
    "    fly_change = tsf.feature_extraction.feature_calculators.fft_coefficient(ts, param_fly_change)\n",
    "    fly_change = list(zip(fly_change))[0][0][1]\n",
    "    fly_change = round(fly_change, 2)\n",
    "    # 小波变换\n",
    "    param_cwt = [{'widths': tuple([2, 2, 2]), 'coeff': 2, 'w': 2}]\n",
    "    cwt = tsf.feature_extraction.feature_calculators.cwt_coefficients(ts, param_cwt)\n",
    "    cwt = list(zip(cwt))[0][0][1]\n",
    "    cwt = round(cwt, 2)\n",
    "\n",
    "    return abs_sum, adf, peak, complexity, line, bin_entropy, appro_entropy, fly, fly_change, cwt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每天的温度进行特征提取\n",
    "def get_features_everday(df_data):\n",
    "    date_ymd_field = df_data['date_ymd']\n",
    "    date_ymds = []\n",
    "    for i in date_ymd_field:\n",
    "        if i not in date_ymds:\n",
    "            date_ymds.append(i)\n",
    "    df_features = pd.DataFrame()\n",
    "    for date_ymd in date_ymds:\n",
    "        #date_ymd = '2019-03-07'\n",
    "        abs_sum_list = []\n",
    "        adf_list = []\n",
    "        peak_list = []\n",
    "        complexity_list = []\n",
    "        line_list = []\n",
    "        bin_entropy_list = []\n",
    "        appro_entropy_list = []\n",
    "        fly_list = []\n",
    "        fly_change_list = []\n",
    "        cwt_list = []\n",
    "        date_ymd_list = []\n",
    "        df_data_by_date = df_data[df_data['date_ymd'] == date_ymd]\n",
    "        # 缺失值大于 5% 的直接舍弃\n",
    "        abondon_thr = int(144 * 0.95)\n",
    "        if (len(df_data_by_date) <= abondon_thr):\n",
    "            continue\n",
    "        # 用插值补全温度值\n",
    "        df_data_by_date_tem = repair_tem(df_data_by_date)\n",
    "        # 如果是连续性缺失，则舍弃\n",
    "        if (len(df_data_by_date_tem) <= abondon_thr):\n",
    "            continue\n",
    "        # 分段常数逼近，温度差分处理\n",
    "        df_appro = constant_appro(df_data_by_date_tem)\n",
    "        temp_array = np.array(list(df_appro['Temperature']))\n",
    "        temp_array = temp_array.reshape(1, 23)\n",
    "        # 分段常数逼近特征列名: 23 个\n",
    "        columns_name = ['t1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10', 't11', 't12', 't13',\n",
    "                        't14', 't15', 't16', 't17', 't18', 't19', 't20', 't21', 't22', 't23']\n",
    "        df_x = pd.DataFrame(temp_array, columns=columns_name)\n",
    "        #used_columns = ['date_ymd', 'Temperature']\n",
    "        #df_data_by_date_tem = df_data_by_date[used_columns]\n",
    "        abs_sum, adf, peak, complexity, line, bin_entropy, appro_entropy, fly, fly_change, cwt = get_features(df_appro)\n",
    "        abs_sum_list.append(abs_sum)\n",
    "        adf_list.append(adf)\n",
    "        peak_list.append(peak)\n",
    "        complexity_list.append(complexity)\n",
    "        line_list.append(line)\n",
    "        bin_entropy_list.append(bin_entropy)\n",
    "        appro_entropy_list.append(appro_entropy)\n",
    "        fly_list.append(fly)\n",
    "        fly_change_list.append(fly_change)\n",
    "        cwt_list.append(cwt)\n",
    "        date_ymd_list.append(date_ymd)\n",
    "        # 统计特征列名： 8\n",
    "        df_x['abs_sum'] = abs_sum_list\n",
    "        df_x['adf'] = adf_list\n",
    "        df_x['peak'] = peak_list\n",
    "        df_x['complexity'] = complexity_list\n",
    "        df_x['line'] = line_list\n",
    "        df_x['fly'] = fly_list\n",
    "        df_x['fly_change'] = fly_change_list\n",
    "        df_x['cwt'] = cwt_list\n",
    "        # 信息熵特征：数据片段相似性  2 个\n",
    "        df_x['bin_entropy'] = bin_entropy_list\n",
    "        df_x['appro_entropy'] = appro_entropy_list\n",
    "        df_x['date_ymd'] = date_ymd_list\n",
    "\n",
    "        df_features = pd.concat([df_features, df_x], axis=0)\n",
    "    return df_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a7c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取目标 y\n",
    "def get_targets(df_file):\n",
    "    df_file['hum_label'] = df_file['hum_label'].astype(str)\n",
    "    df_file_label = df_file[df_file['hum_label']=='1.0']\n",
    "    if 'Unnamed: 5' in df_file_label.columns:\n",
    "        del df_file_label['Unnamed: 5']\n",
    "    label_preprocess_dir = 'label_preprocess/'\n",
    "    label_preprocess_path = os.path.join(label_preprocess_dir, file_name)\n",
    "    #df_file_label.to_csv(label_preprocess_path, index=False)\n",
    "    return df_file_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 给 label y 增加辅助列\n",
    "def add_y_col(df_file):\n",
    "    date_list = []\n",
    "    for date in list(df_file['DateTime']):\n",
    "        date_str = str(date).split(' ')[0]\n",
    "        date_list.append(date_str)\n",
    "    df_file['date_ymd'] = date_list\n",
    "    return df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7bfcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 y 进行补全、筛选处理\n",
    "def complete_targets(file_name_label):\n",
    "    label_dir = './label_preprocess/'\n",
    "    label_path = os.path.join(label_dir, file_name_label)\n",
    "    label_path = open(label_path)\n",
    "    df_label = pd.read_csv(label_path)\n",
    "    df_label['correct'] = df_label['correct'].astype(str)\n",
    "    df_label['across'] = df_label['across'].astype(str)\n",
    "    df_laebl_temp_1 = df_label[df_label['correct']=='1.0']\n",
    "    df_laebl_temp_2 = df_label[df_label['across']=='1.0']\n",
    "    # 对 label y 进行整理\n",
    "    n_cnt = 5  #除霜次数\n",
    "    df_laebl_temp_1 = df_laebl_temp_1.reset_index(drop=True)\n",
    "    df_laebl_temp_2 = df_laebl_temp_2.reset_index(drop=True)\n",
    "    df_laebl_temp_1 = add_y_col(df_laebl_temp_1)\n",
    "    df_laebl_temp_2 = add_y_col(df_laebl_temp_2)\n",
    "    # 保存在 label_process_1 下人工检查日期\n",
    "    save_dir = './label_preprocess_1/'\n",
    "    save_path_1 = os.path.join(save_dir, file_name_label.split('.')[0] + '_1.csv')\n",
    "    #df_laebl_temp_1.to_csv(save_path_1, index=False)\n",
    "    save_path_2 = os.path.join(save_dir, file_name_label.split('.')[0] + '_2.csv')\n",
    "    #df_laebl_temp_2.to_csv(save_path_2, index=False)\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3bf9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把 label y 按日期变成一行\n",
    "def label_to_hor(df_data):\n",
    "    # 除霜次数\n",
    "    cnt = 5\n",
    "    df_data = df_data.reset_index(drop=True)\n",
    "    date_ymd_field = df_data['date_ymd']\n",
    "    date_ymds = []\n",
    "    for i in date_ymd_field:\n",
    "        if i not in date_ymds:\n",
    "            date_ymds.append(i)\n",
    "    df_features = pd.DataFrame()\n",
    "    for date_ymd in date_ymds:\n",
    "        date_list = []\n",
    "        df_data_by_date = df_data[df_data['date_ymd'] == date_ymd]\n",
    "        date_list.append(date_ymd)\n",
    "        temp_array = np.array(list(df_data_by_date['DateTime']))\n",
    "        temp_array = temp_array.reshape(1, cnt*2)\n",
    "        df_y = pd.DataFrame(temp_array)\n",
    "        df_y['date_ymd'] = date_list\n",
    "        df_features = pd.concat([df_features, df_y], axis=0)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed97b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 y 进行合并排序\n",
    "def combine_label():\n",
    "    file_name_label_1 = 'HLK-23F01(-18℃)_label_1.csv'\n",
    "    label_dir = './label_preprocess_1/'\n",
    "    label_path_1 = os.path.join(label_dir, file_name_label_1)\n",
    "    label_path_1 = open(label_path_1)\n",
    "    df_label_1 = pd.read_csv(label_path_1)\n",
    "    file_name_label_2 = 'HLK-23F01(-18℃)_label_2.csv'\n",
    "    label_path_2 = os.path.join(label_dir, file_name_label_2)\n",
    "    label_path_2 = open(label_path_2)\n",
    "    df_label_2 = pd.read_csv(label_path_2)\n",
    "    # 检查日期，人工检查\n",
    "    import collections\n",
    "    a = collections.Counter(df_label_1['date_ymd'])\n",
    "    b = collections.Counter(df_label_2['date_ymd'])\n",
    "    # 把 label y 按照每天日期排列成一行\n",
    "    df_label_y_1 = label_to_hor(df_label_1)\n",
    "    df_label_y_2 = label_to_hor(df_label_2)\n",
    "    df_y = pd.concat([df_label_y_1, df_label_y_2], axis=0)\n",
    "    df_y['date_ymd'] = pd.to_datetime(df_y['date_ymd'])\n",
    "    df_y = df_y.sort_values(by='date_ymd')\n",
    "    #df_y.to_csv(label_dir + file_name_label_1.split('_')[0] + '_y.csv', index=False)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间字符串格式转换\n",
    "def time_format_trans(ser_list):\n",
    "    ser_list = list(ser_list)\n",
    "    ser_new = []\n",
    "    for ser in ser_list:\n",
    "        ser = str(ser).strip()\n",
    "        if('/' in list(str(ser))):\n",
    "            ser = str(ser).replace('/', '-')\n",
    "        ser_new.append(ser)\n",
    "    return ser_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整合 x 和 y, 与匹配的日期对应起来, 对应产出在 label_preprocess_2/ 文件夹下\n",
    "def merge_features_target(file_name):\n",
    "    features_dir = './label_preprocess/'\n",
    "    target_dir = './label_preprocess_1/'\n",
    "    features_path = os.path.join(features_dir, file_name + '_x.csv')\n",
    "    features_path = open(features_path)\n",
    "    target_path = os.path.join(target_dir, file_name + '_y.csv')\n",
    "    target_path = open(target_path)\n",
    "    df_features = pd.read_csv(features_path)\n",
    "    df_target = pd.read_csv(target_path)\n",
    "    # 添加辅助列 date_ymd_1: 为了匹配用昨天的温度预测下一天的时间\n",
    "    df_target['date_ymd'] = pd.to_datetime(df_target['date_ymd'])\n",
    "    df_target = df_target.sort_values(by='date_ymd')\n",
    "    # 获取当前日期前一天日期\n",
    "    before_days = 1\n",
    "    #before_days_date = now_date + datetime.timedelta(days=-before_days)\n",
    "    df_target['date_ymd'] = df_target['date_ymd'].apply(lambda x: x + datetime.timedelta(days=-before_days))\n",
    "\n",
    "    df_target['date_ymd'] = df_target['date_ymd'].astype(str)\n",
    "    # 时间字符串格式转换\n",
    "    df_features['date_ymd'] = pd.to_datetime(df_features['date_ymd'])\n",
    "    df_features = df_features.sort_values(by='date_ymd')\n",
    "    df_features['date_ymd'] = df_features['date_ymd'].astype(str)\n",
    "    # 合并 x 和 y\n",
    "    df_data = pd.merge(df_features, df_target, on='date_ymd')\n",
    "    data_merge_dir = './label_preprocess_2/'\n",
    "    data_merge_path = os.path.join(data_merge_dir, file_name + '_feature_target.csv')\n",
    "    del df_data['date_ymd']\n",
    "    #df_data.to_csv(data_merge_path, index=False)\n",
    "    print ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
